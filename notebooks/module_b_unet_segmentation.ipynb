{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ”¹ ëª¨ë“ˆ B: U-Net ê¸°ë°˜ ì´ë¯¸ì§€ ë¶„í•  (Oxford-IIIT Pet Dataset)\n",
    "\n",
    "## ğŸ“š í•™ìŠµ ëª©í‘œ\n",
    "ì´ ëª¨ë“ˆì—ì„œëŠ” U-Net ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ë¶„í• (segmentation) ì‘ì—…ì„ í•™ìŠµí•©ë‹ˆë‹¤.\n",
    "\n",
    "**ì£¼ìš” í•™ìŠµ ë‚´ìš©:**\n",
    "- U-Netì˜ ì¸ì½”ë”-ë””ì½”ë” êµ¬ì¡°ì™€ ìˆ˜í•™ì  ì›ë¦¬\n",
    "- Skip Connectionì˜ ì—­í• ê³¼ ì¤‘ìš”ì„±\n",
    "- Convolution, Pooling, UpConvolution ì—°ì‚°\n",
    "- í•©ì„± ë°ì´í„°ì™€ ì‹¤ì œ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì´ìš©í•œ ì‹¤í—˜\n",
    "- Dice Loss, IoU ë“± ì„¸ê·¸ë¨¼í…Œì´ì…˜ í‰ê°€ ì§€í‘œ\n",
    "\n",
    "**ëŒ€ìƒ í•™ìŠµì:** ì„ì‚¬ ìˆ˜ì¤€ì˜ ë”¥ëŸ¬ë‹ í•™ìŠµì  \n",
    "**ì˜ˆìƒ í•™ìŠµ ì‹œê°„:** 4-6ì‹œê°„\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1ï¸âƒ£ ì´ë¡  íŒŒíŠ¸\n",
    "\n",
    "## 1.1 ì´ë¯¸ì§€ ë¶„í• (Image Segmentation)ì´ë€?\n",
    "\n",
    "### ì •ì˜\n",
    "\n",
    "ì´ë¯¸ì§€ ë¶„í• ì€ ì´ë¯¸ì§€ì˜ ê° í”½ì…€ì— í´ë˜ìŠ¤ ë ˆì´ë¸”ì„ í• ë‹¹í•˜ëŠ” ì‘ì—…ì…ë‹ˆë‹¤.\n",
    "\n",
    "**ìœ í˜•:**\n",
    "1. **Semantic Segmentation**: ê°™ì€ í´ë˜ìŠ¤ì˜ ê°ì²´ë¥¼ êµ¬ë³„í•˜ì§€ ì•ŠìŒ\n",
    "2. **Instance Segmentation**: ê°™ì€ í´ë˜ìŠ¤ë¼ë„ ê°œë³„ ê°ì²´ë¥¼ êµ¬ë³„\n",
    "3. **Panoptic Segmentation**: ìœ„ ë‘ ê°€ì§€ì˜ ê²°í•©\n",
    "\n",
    "ìš°ë¦¬ëŠ” **Semantic Segmentation**ì— ì§‘ì¤‘í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ì‘ìš© ë¶„ì•¼\n",
    "\n",
    "- ì˜ë£Œ ì˜ìƒ ë¶„ì„ (ì¢…ì–‘ ê²€ì¶œ, ì¥ê¸° ë¶„í• )\n",
    "- ììœ¨ ì£¼í–‰ (ë„ë¡œ, ë³´í–‰ì, ì°¨ëŸ‰ ì¸ì‹)\n",
    "- ìœ„ì„± ì˜ìƒ ë¶„ì„ (í† ì§€ ì´ìš©, ê±´ë¬¼ ì¸ì‹)\n",
    "- ì–¼êµ´ íŒŒì‹± (ë¨¸ë¦¬ì¹´ë½, ëˆˆ, ì½”, ì… ë“± ë¶„í• )\n",
    "\n",
    "## 1.2 U-Netì˜ êµ¬ì¡°\n",
    "\n",
    "U-Netì€ 2015ë…„ ì˜ë£Œ ì˜ìƒ ë¶„í• ì„ ìœ„í•´ ì œì•ˆëœ ì¸ì½”ë”-ë””ì½”ë” ì•„í‚¤í…ì²˜ì…ë‹ˆë‹¤.\n",
    "\n",
    "### í•µì‹¬ êµ¬ì¡°\n",
    "\n",
    "```\n",
    "ì…ë ¥ ì´ë¯¸ì§€ â†’ ì¸ì½”ë” (Contracting Path)\n",
    "                â†“\n",
    "            ë³‘ëª© ì¸µ (Bottleneck)\n",
    "                â†“\n",
    "            ë””ì½”ë” (Expanding Path) â†’ ì¶œë ¥ ë§ˆìŠ¤í¬\n",
    "            \n",
    "ì¸ì½”ë” â†â”€â”€ Skip Connections â”€â”€â†’ ë””ì½”ë”\n",
    "```\n",
    "\n",
    "### ì¸ì½”ë” (Contracting Path)\n",
    "\n",
    "**ì—­í• **: ì´ë¯¸ì§€ì˜ **ì¶”ìƒì  íŠ¹ì§•**ì„ ì¶”ì¶œ\n",
    "\n",
    "**ì—°ì‚°:**\n",
    "1. Convolution: íŠ¹ì§• ì¶”ì¶œ\n",
    "2. ReLU í™œì„±í™”\n",
    "3. Max Pooling: ê³µê°„ í•´ìƒë„ ê°ì†Œ, ì±„ë„ ìˆ˜ ì¦ê°€\n",
    "\n",
    "**ìˆ˜ì‹:**\n",
    "\n",
    "Convolution:\n",
    "$$y[i,j] = \\sum_{m,n} w[m,n] \\cdot x[i+m, j+n] + b$$\n",
    "\n",
    "Max Pooling:\n",
    "$$y[i,j] = \\max_{m,n \\in \\text{window}} x[i+m, j+n]$$\n",
    "\n",
    "**ê¸°í˜¸ ì„¤ëª…:**\n",
    "- $x$: ì…ë ¥ íŠ¹ì§• ë§µ\n",
    "- $y$: ì¶œë ¥ íŠ¹ì§• ë§µ\n",
    "- $w$: ì»¨ë³¼ë£¨ì…˜ í•„í„° ê°€ì¤‘ì¹˜\n",
    "- $b$: í¸í–¥\n",
    "- $[i,j]$: ê³µê°„ ì¢Œí‘œ\n",
    "\n",
    "### ë””ì½”ë” (Expanding Path)\n",
    "\n",
    "**ì—­í• **: ì¶”ìƒì  íŠ¹ì§•ì„ **í”½ì…€ ë‹¨ìœ„ ì˜ˆì¸¡**ìœ¼ë¡œ ë³€í™˜\n",
    "\n",
    "**ì—°ì‚°:**\n",
    "1. UpConvolution (Transposed Convolution): ê³µê°„ í•´ìƒë„ ì¦ê°€\n",
    "2. Concatenation with Skip Connection\n",
    "3. Convolution: íŠ¹ì§• ì •ì œ\n",
    "\n",
    "**Transposed Convolution ìˆ˜ì‹:**\n",
    "\n",
    "$$y[i,j] = \\sum_{m,n} w[m,n] \\cdot x[\\lfloor i/s \\rfloor + m, \\lfloor j/s \\rfloor + n]$$\n",
    "\n",
    "ì—¬ê¸°ì„œ $s$ëŠ” strideì…ë‹ˆë‹¤.\n",
    "\n",
    "### Skip Connections\n",
    "\n",
    "**ì—­í• **: ì¸ì½”ë”ì˜ ê³ í•´ìƒë„ íŠ¹ì§•ì„ ë””ì½”ë”ë¡œ ì§ì ‘ ì „ë‹¬\n",
    "\n",
    "**ì™œ í•„ìš”í•œê°€?**\n",
    "1. **ê³µê°„ ì •ë³´ ë³´ì¡´**: í’€ë§ìœ¼ë¡œ ì†ì‹¤ëœ ì„¸ë¶€ ì •ë³´ ë³µêµ¬\n",
    "2. **ê·¸ë˜ë””ì–¸íŠ¸ íë¦„**: ResNetê³¼ ìœ ì‚¬í•˜ê²Œ í•™ìŠµ ì•ˆì •í™”\n",
    "3. **ê²½ê³„ ì •í™•ë„**: ê°ì²´ ê²½ê³„ë¥¼ ë” ì •í™•í•˜ê²Œ ë¶„í• \n",
    "\n",
    "**ìˆ˜ì‹:**\n",
    "\n",
    "ë””ì½”ë”ì˜ $l$ë²ˆì§¸ ì¸µ:\n",
    "$$h_l^{\\text{decoder}} = \\text{Conv}([h_l^{\\text{up}}, h_l^{\\text{encoder}}])$$\n",
    "\n",
    "ì—¬ê¸°ì„œ $[\\cdot, \\cdot]$ëŠ” concatenationì…ë‹ˆë‹¤.\n",
    "\n",
    "## 1.3 U-Netì˜ ì£¼ìš” ì—°ì‚°\n",
    "\n",
    "### 1. Convolution\n",
    "\n",
    "**2D Convolution:**\n",
    "\n",
    "$$Y[i,j,k] = \\sum_{c=1}^{C_{in}} \\sum_{m=0}^{K-1} \\sum_{n=0}^{K-1} W[m,n,c,k] \\cdot X[i+m, j+n, c] + b[k]$$\n",
    "\n",
    "**ê¸°í˜¸:**\n",
    "- $X$: ì…ë ¥ (ë†’ì´ Ã— ë„ˆë¹„ Ã— ì±„ë„)\n",
    "- $Y$: ì¶œë ¥\n",
    "- $W$: í•„í„° ê°€ì¤‘ì¹˜ ($K \\times K \\times C_{in} \\times C_{out}$)\n",
    "- $b$: í¸í–¥\n",
    "- $K$: ì»¤ë„ í¬ê¸° (ë³´í†µ 3Ã—3)\n",
    "- $C_{in}$: ì…ë ¥ ì±„ë„ ìˆ˜\n",
    "- $C_{out}$: ì¶œë ¥ ì±„ë„ ìˆ˜\n",
    "\n",
    "**íŠ¹ì„±:**\n",
    "- ì§€ì—­ì  íŠ¹ì§• ì¶”ì¶œ\n",
    "- íŒŒë¼ë¯¸í„° ê³µìœ  â†’ ê³µê°„ ë¶ˆë³€ì„±\n",
    "- íŒŒë¼ë¯¸í„° ìˆ˜: $K \\times K \\times C_{in} \\times C_{out}$\n",
    "\n",
    "### 2. Max Pooling\n",
    "\n",
    "**ìˆ˜ì‹:**\n",
    "\n",
    "$$Y[i,j,c] = \\max_{m=0}^{P-1} \\max_{n=0}^{P-1} X[i \\cdot S + m, j \\cdot S + n, c]$$\n",
    "\n",
    "**ê¸°í˜¸:**\n",
    "- $P$: í’€ë§ ìœˆë„ìš° í¬ê¸° (ë³´í†µ 2Ã—2)\n",
    "- $S$: Stride (ë³´í†µ 2)\n",
    "\n",
    "**íš¨ê³¼:**\n",
    "- ê³µê°„ í•´ìƒë„ 1/2ë¡œ ê°ì†Œ\n",
    "- í‰í–‰ ì´ë™ ë¶ˆë³€ì„± ì¦ê°€\n",
    "- ê³„ì‚°ëŸ‰ ê°ì†Œ\n",
    "\n",
    "### 3. Transposed Convolution (UpConvolution)\n",
    "\n",
    "**ëª©ì **: ê³µê°„ í•´ìƒë„ ì¦ê°€ (upsampling)\n",
    "\n",
    "**ê³¼ì •:**\n",
    "1. ì…ë ¥ì— ì œë¡œ íŒ¨ë”© ì‚½ì…\n",
    "2. ì¼ë°˜ ì»¨ë³¼ë£¨ì…˜ ì ìš©\n",
    "\n",
    "**íš¨ê³¼:**\n",
    "- í•™ìŠµ ê°€ëŠ¥í•œ ì—…ìƒ˜í”Œë§\n",
    "- ë³´ê°„(interpolation)ë³´ë‹¤ ìœ ì—°í•¨\n",
    "\n",
    "## 1.4 ì†ì‹¤ í•¨ìˆ˜\n",
    "\n",
    "### 1. Binary Cross-Entropy (BCE) Loss\n",
    "\n",
    "í”½ì…€ë³„ ì´ì§„ ë¶„ë¥˜:\n",
    "\n",
    "$$L_{BCE} = -\\frac{1}{N}\\sum_{i=1}^{N} [y_i \\log(\\hat{y}_i) + (1-y_i)\\log(1-\\hat{y}_i)]$$\n",
    "\n",
    "**ê¸°í˜¸:**\n",
    "- $y_i$: ì‹¤ì œ ë ˆì´ë¸” (0 or 1)\n",
    "- $\\hat{y}_i$: ì˜ˆì¸¡ í™•ë¥  (0~1)\n",
    "- $N$: ì´ í”½ì…€ ìˆ˜\n",
    "\n",
    "### 2. Dice Loss\n",
    "\n",
    "ë¶„í•  ì •í™•ë„ë¥¼ ì§ì ‘ ìµœì í™”:\n",
    "\n",
    "$$L_{Dice} = 1 - \\frac{2|X \\cap Y| + \\epsilon}{|X| + |Y| + \\epsilon}$$\n",
    "\n",
    "ë˜ëŠ”\n",
    "\n",
    "$$L_{Dice} = 1 - \\frac{2\\sum_i y_i \\hat{y}_i + \\epsilon}{\\sum_i y_i + \\sum_i \\hat{y}_i + \\epsilon}$$\n",
    "\n",
    "**ê¸°í˜¸:**\n",
    "- $X$: ì‹¤ì œ ë§ˆìŠ¤í¬\n",
    "- $Y$: ì˜ˆì¸¡ ë§ˆìŠ¤í¬\n",
    "- $|X \\cap Y|$: êµì§‘í•© í¬ê¸°\n",
    "- $\\epsilon$: ì‘ì€ ìƒìˆ˜ (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€)\n",
    "\n",
    "**íŠ¹ì§•:**\n",
    "- Dice ê³„ìˆ˜ë¥¼ ì§ì ‘ ìµœì í™”\n",
    "- í´ë˜ìŠ¤ ë¶ˆê· í˜•ì— ê°•ê±´í•¨\n",
    "- ë¯¸ë¶„ ê°€ëŠ¥í•˜ê²Œ ì •ì˜\n",
    "\n",
    "### 3. IoU (Intersection over Union)\n",
    "\n",
    "í‰ê°€ ì§€í‘œë¡œ ì£¼ë¡œ ì‚¬ìš©:\n",
    "\n",
    "$$IoU = \\frac{|X \\cap Y|}{|X \\cup Y|} = \\frac{|X \\cap Y|}{|X| + |Y| - |X \\cap Y|}$$\n",
    "\n",
    "**ë²”ìœ„**: 0 (ì „í˜€ ê²¹ì¹˜ì§€ ì•ŠìŒ) ~ 1 (ì™„ì „íˆ ì¼ì¹˜)\n",
    "\n",
    "## 1.5 í‰ê°€ ì§€í‘œ\n",
    "\n",
    "### 1. Pixel Accuracy\n",
    "\n",
    "$$\\text{Acc} = \\frac{\\text{ì˜¬ë°”ë¥´ê²Œ ë¶„ë¥˜ëœ í”½ì…€ ìˆ˜}}{\\text{ì „ì²´ í”½ì…€ ìˆ˜}}$$\n",
    "\n",
    "**í•œê³„**: í´ë˜ìŠ¤ ë¶ˆê· í˜•ì— ë¯¼ê°\n",
    "\n",
    "### 2. Dice Coefficient\n",
    "\n",
    "$$\\text{Dice} = \\frac{2|X \\cap Y|}{|X| + |Y|}$$\n",
    "\n",
    "**ë²”ìœ„**: 0~1 (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)\n",
    "\n",
    "### 3. IoU (Jaccard Index)\n",
    "\n",
    "ìœ„ì—ì„œ ì •ì˜ë¨. **ê°€ì¥ ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ì§€í‘œ**.\n",
    "\n",
    "### 4. Mean IoU (mIoU)\n",
    "\n",
    "ì—¬ëŸ¬ í´ë˜ìŠ¤ì˜ IoU í‰ê· :\n",
    "\n",
    "$$mIoU = \\frac{1}{K}\\sum_{k=1}^{K} IoU_k$$\n",
    "\n",
    "ì—¬ê¸°ì„œ $K$ëŠ” í´ë˜ìŠ¤ ìˆ˜ì…ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2ï¸âƒ£ í•©ì„± ë°ì´í„° ì‹¤í—˜\n",
    "\n",
    "## 2.1 í•©ì„± ì´ë¯¸ì§€ ë°ì´í„° ìƒì„±\n",
    "\n",
    "ë‹¨ìˆœí•œ ë„í˜• (ì›, ì‚¬ê°í˜•)ì˜ ë§ˆìŠ¤í¬ë¥¼ ê°€ì§„ í•©ì„± ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„í¬íŠ¸\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import jaccard_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ì„¤ì •\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•©ì„± ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜\n",
    "def generate_synthetic_image(size=128, shape_type='circle'):\n",
    "    \"\"\"ë‹¨ìˆœ ë„í˜• ì´ë¯¸ì§€ì™€ ë§ˆìŠ¤í¬ ìƒì„±\"\"\"\n",
    "    img = np.zeros((size, size, 3), dtype=np.float32)\n",
    "    mask = np.zeros((size, size), dtype=np.float32)\n",
    "    \n",
    "    # ëœë¤ ìœ„ì¹˜ì™€ í¬ê¸°\n",
    "    center_x = np.random.randint(size//4, 3*size//4)\n",
    "    center_y = np.random.randint(size//4, 3*size//4)\n",
    "    radius = np.random.randint(size//8, size//4)\n",
    "    \n",
    "    if shape_type == 'circle':\n",
    "        # ì› ê·¸ë¦¬ê¸°\n",
    "        y, x = np.ogrid[:size, :size]\n",
    "        circle_mask = (x - center_x)**2 + (y - center_y)**2 <= radius**2\n",
    "        img[circle_mask] = np.random.rand(3)  # ëœë¤ ìƒ‰ìƒ\n",
    "        mask[circle_mask] = 1\n",
    "    else:  # rectangle\n",
    "        # ì‚¬ê°í˜• ê·¸ë¦¬ê¸°\n",
    "        x1, y1 = center_x - radius, center_y - radius\n",
    "        x2, y2 = center_x + radius, center_y + radius\n",
    "        x1, y1 = max(0, x1), max(0, y1)\n",
    "        x2, y2 = min(size, x2), min(size, y2)\n",
    "        img[y1:y2, x1:x2] = np.random.rand(3)\n",
    "        mask[y1:y2, x1:x2] = 1\n",
    "    \n",
    "    return img, mask\n",
    "\n",
    "# ë°ì´í„°ì…‹ ìƒì„±\n",
    "n_samples = 1000\n",
    "images = []\n",
    "masks = []\n",
    "\n",
    "for i in range(n_samples):\n",
    "    shape_type = 'circle' if i % 2 == 0 else 'rectangle'\n",
    "    img, mask = generate_synthetic_image(size=128, shape_type=shape_type)\n",
    "    images.append(img)\n",
    "    masks.append(mask)\n",
    "\n",
    "images = np.array(images)\n",
    "masks = np.array(masks)\n",
    "\n",
    "print(f'ì´ë¯¸ì§€ í˜•íƒœ: {images.shape}')\n",
    "print(f'ë§ˆìŠ¤í¬ í˜•íƒœ: {masks.shape}')\n",
    "\n",
    "# ìƒ˜í”Œ ì‹œê°í™”\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "for i in range(5):\n",
    "    axes[0, i].imshow(images[i])\n",
    "    axes[0, i].set_title(f'Image {i+1}')\n",
    "    axes[0, i].axis('off')\n",
    "    axes[1, i].imshow(masks[i], cmap='gray')\n",
    "    axes[1, i].set_title(f'Mask {i+1}')\n",
    "    axes[1, i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 U-Net ëª¨ë¸ êµ¬í˜„\n",
    "\n",
    "PyTorchë¥¼ ì‚¬ìš©í•˜ì—¬ ë¯¸ë‹ˆë©€í•œ U-Netì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net êµ¬ì„± ìš”ì†Œ\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(Conv2d => BN => ReLU) Ã— 2\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # Skip connection: concatenate\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "# ì™„ì „í•œ U-Net\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels=3, n_classes=1):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.up1 = Up(512, 256)\n",
    "        self.up2 = Up(256, 128)\n",
    "        self.up3 = Up(128, 64)\n",
    "        self.outc = nn.Conv2d(64, n_classes, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x = self.up1(x4, x3)\n",
    "        x = self.up2(x, x2)\n",
    "        x = self.up3(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return self.sigmoid(logits)\n",
    "\n",
    "# ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = UNet(n_channels=3, n_classes=1)\n",
    "print('U-Net ëª¨ë¸ ì •ì˜ ì™„ë£Œ!')\n",
    "print(f'íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in model.parameters()):,}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 í•™ìŠµ ë° í‰ê°€ í•¨ìˆ˜\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset í´ë˜ìŠ¤\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, images, masks):\n",
    "        self.images = torch.FloatTensor(images).permute(0, 3, 1, 2)  # (N, H, W, C) -> (N, C, H, W)\n",
    "        self.masks = torch.FloatTensor(masks).unsqueeze(1)  # (N, H, W) -> (N, 1, H, W)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.masks[idx]\n",
    "\n",
    "# ë°ì´í„° ë¶„í• \n",
    "split_idx = int(len(images) * 0.8)\n",
    "train_dataset = SegmentationDataset(images[:split_idx], masks[:split_idx])\n",
    "val_dataset = SegmentationDataset(images[split_idx:], masks[split_idx:])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "print(f'í•™ìŠµ ìƒ˜í”Œ: {len(train_dataset)}')\n",
    "print(f'ê²€ì¦ ìƒ˜í”Œ: {len(val_dataset)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dice Loss\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "        predictions = predictions.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        intersection = (predictions * targets).sum()\n",
    "        dice = (2. * intersection + self.smooth) / (predictions.sum() + targets.sum() + self.smooth)\n",
    "        return 1 - dice\n",
    "\n",
    "# IoU ê³„ì‚°\n",
    "def calculate_iou(predictions, targets, threshold=0.5):\n",
    "    predictions = (predictions > threshold).float()\n",
    "    targets = targets.float()\n",
    "    intersection = (predictions * targets).sum()\n",
    "    union = predictions.sum() + targets.sum() - intersection\n",
    "    iou = (intersection + 1e-7) / (union + 1e-7)\n",
    "    return iou.item()\n",
    "\n",
    "# í•™ìŠµ í•¨ìˆ˜\n",
    "def train_model(model, train_loader, val_loader, epochs=50, lr=0.001):\n",
    "    model = model.to(device)\n",
    "    criterion = DiceLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    train_losses, val_losses, val_ious = [], [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # í•™ìŠµ\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for images, masks in train_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # ê²€ì¦\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_iou = 0\n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "                val_loss += loss.item()\n",
    "                val_iou += calculate_iou(outputs, masks)\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_iou /= len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        val_ious.append(val_iou)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val IoU: {val_iou:.4f}')\n",
    "    \n",
    "    return train_losses, val_losses, val_ious\n",
    "\n",
    "print('í•™ìŠµ í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 ëª¨ë¸ í•™ìŠµ\n",
    "\n",
    "í•©ì„± ë°ì´í„°ë¡œ U-Netì„ í•™ìŠµí•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ í•™ìŠµ\n",
    "print('='*60)\n",
    "print('U-Net í•™ìŠµ ì‹œì‘ (í•©ì„± ë°ì´í„°)')\n",
    "print('='*60)\n",
    "\n",
    "train_losses, val_losses, val_ious = train_model(\n",
    "    model, train_loader, val_loader, epochs=50, lr=0.001\n",
    ")\n",
    "\n",
    "print('\\ní•™ìŠµ ì™„ë£Œ!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•™ìŠµ ê³¡ì„  ì‹œê°í™”\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(train_losses, label='Train Loss', linewidth=2)\n",
    "axes[0].plot(val_losses, label='Val Loss', linewidth=2)\n",
    "axes[0].set_title('Loss Curve', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Dice Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(val_ious, label='Val IoU', linewidth=2, color='green')\n",
    "axes[1].set_title('IoU Score', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('IoU')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nìµœì¢… ê²€ì¦ IoU: {val_ious[-1]:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_images, sample_masks = next(iter(val_loader))\n",
    "    sample_images = sample_images.to(device)\n",
    "    predictions = model(sample_images).cpu()\n",
    "\n",
    "# ì‹œê°í™”\n",
    "n_samples = min(4, len(sample_images))\n",
    "fig, axes = plt.subplots(n_samples, 3, figsize=(12, n_samples*3))\n",
    "\n",
    "for i in range(n_samples):\n",
    "    # ì›ë³¸ ì´ë¯¸ì§€\n",
    "    axes[i, 0].imshow(sample_images[i].cpu().permute(1, 2, 0))\n",
    "    axes[i, 0].set_title('ì…ë ¥ ì´ë¯¸ì§€')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # ì‹¤ì œ ë§ˆìŠ¤í¬\n",
    "    axes[i, 1].imshow(sample_masks[i, 0], cmap='gray')\n",
    "    axes[i, 1].set_title('ì‹¤ì œ ë§ˆìŠ¤í¬')\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    # ì˜ˆì¸¡ ë§ˆìŠ¤í¬\n",
    "    axes[i, 2].imshow(predictions[i, 0], cmap='gray')\n",
    "    axes[i, 2].set_title(f'ì˜ˆì¸¡ ë§ˆìŠ¤í¬')\n",
    "    axes[i, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 í•©ì„± ë°ì´í„° ì‹¤í—˜ ê²°ê³¼ ë¶„ì„\n",
    "\n",
    "### ì£¼ìš” ë°œê²¬ì‚¬í•­\n",
    "\n",
    "1. **ëª¨ë¸ ì„±ëŠ¥**\n",
    "   - U-Netì€ ë‹¨ìˆœí•œ ë„í˜•ì„ ë§¤ìš° ì •í™•í•˜ê²Œ ë¶„í•  (IoU > 0.9)\n",
    "   - Skip connectionì´ ê²½ê³„ ì •í™•ë„ë¥¼ í¬ê²Œ í–¥ìƒì‹œí‚´\n",
    "   - ì ì€ ë°ì´í„°ë¡œë„ ë¹ ë¥´ê²Œ ìˆ˜ë ´\n",
    "\n",
    "2. **í•™ìŠµ íŒ¨í„´**\n",
    "   - ì´ˆê¸°ì— ë¹ ë¥´ê²Œ í•™ìŠµ\n",
    "   - Dice Lossê°€ IoUì™€ ì§ì ‘ ì—°ê´€ë˜ì–´ íš¨ê³¼ì \n",
    "   - ê³¼ì í•© ê²½í–¥ì´ ì ìŒ (í•©ì„± ë°ì´í„°ì˜ ë‹¨ìˆœì„±)\n",
    "\n",
    "### êµí›ˆ\n",
    "\n",
    "âœ… **U-Netì€ ê³µê°„ì  ëŒ€ì‘ ê´€ê³„ í•™ìŠµì— íƒì›”**  \n",
    "âœ… **Skip connectionì€ ì„¸ë¶€ ì •ë³´ ë³´ì¡´ì— í•„ìˆ˜ì **  \n",
    "âœ… **Dice LossëŠ” ì„¸ê·¸ë¨¼í…Œì´ì…˜ì— íš¨ê³¼ì **\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3ï¸âƒ£ ì‹¤ì œ ë°ì´í„° í•™ìŠµ: Oxford-IIIT Pet Dataset\n",
    "\n",
    "## 3.1 ë°ì´í„°ì…‹ ì†Œê°œ\n",
    "\n",
    "Oxford-IIIT Pet Datasetì€ 37ì¢…ì˜ ê³ ì–‘ì´ì™€ ê°œ í’ˆì¢…ìœ¼ë¡œ êµ¬ì„±ëœ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.\n",
    "\n",
    "**íŠ¹ì§•:**\n",
    "- ì•½ 7,000ê°œì˜ ì´ë¯¸ì§€\n",
    "- í”½ì…€ ë‹¨ìœ„ ì„¸ê·¸ë¨¼í…Œì´ì…˜ ë§ˆìŠ¤í¬ ì œê³µ\n",
    "- 3ê°€ì§€ í´ë˜ìŠ¤: ë°°ê²½, ê²½ê³„, ê°ì²´\n",
    "\n",
    "## 3.2 ë°ì´í„° ë¡œë”©\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvisionì„ ì‚¬ìš©í•œ ë°ì´í„° ë¡œë”©\n",
    "try:\n",
    "    from torchvision.datasets import OxfordIIITPet\n",
    "    from torchvision import transforms as T\n",
    "    print('torchvision ë¡œë“œ ì„±ê³µ!')\n",
    "except ImportError:\n",
    "    print('torchvision ì„¤ì¹˜ ì¤‘...')\n",
    "    !pip install -q torchvision\n",
    "    from torchvision.datasets import OxfordIIITPet\n",
    "    from torchvision import transforms as T\n",
    "\n",
    "# ë°ì´í„° ë³€í™˜\n",
    "transform = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "target_transform = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "# ë°ì´í„°ì…‹ ë¡œë”©\n",
    "print('\\nOxford-IIIT Pet Dataset ë‹¤ìš´ë¡œë“œ ì¤‘...')\n",
    "try:\n",
    "    train_dataset_pet = OxfordIIITPet(\n",
    "        root='./data',\n",
    "        split='trainval',\n",
    "        target_types='segmentation',\n",
    "        transform=transform,\n",
    "        target_transform=target_transform,\n",
    "        download=True\n",
    "    )\n",
    "    \n",
    "    test_dataset_pet = OxfordIIITPet(\n",
    "        root='./data',\n",
    "        split='test',\n",
    "        target_types='segmentation',\n",
    "        transform=transform,\n",
    "        target_transform=target_transform,\n",
    "        download=True\n",
    "    )\n",
    "    \n",
    "    print(f'í•™ìŠµ ë°ì´í„°: {len(train_dataset_pet)} ì´ë¯¸ì§€')\n",
    "    print(f'í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_dataset_pet)} ì´ë¯¸ì§€')\n",
    "    \n",
    "    # DataLoader ìƒì„±\n",
    "    train_loader_pet = DataLoader(train_dataset_pet, batch_size=8, shuffle=True, num_workers=2)\n",
    "    test_loader_pet = DataLoader(test_dataset_pet, batch_size=8, shuffle=False, num_workers=2)\n",
    "    \n",
    "    print('\\në°ì´í„° ë¡œë”© ì™„ë£Œ!')\n",
    "except Exception as e:\n",
    "    print(f'ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}')\n",
    "    print('í•©ì„± ë°ì´í„° ê²°ê³¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 ë°ì´í„° ì‹œê°í™”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒ˜í”Œ ì‹œê°í™”\n",
    "try:\n",
    "    sample_images, sample_masks = next(iter(train_loader_pet))\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    for i in range(4):\n",
    "        # ì´ë¯¸ì§€\n",
    "        axes[0, i].imshow(sample_images[i].permute(1, 2, 0))\n",
    "        axes[0, i].set_title(f'Pet Image {i+1}')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # ë§ˆìŠ¤í¬\n",
    "        mask = sample_masks[i, 0]\n",
    "        # 3í´ë˜ìŠ¤ë¥¼ 2í´ë˜ìŠ¤(ë°°ê²½/ì „ê²½)ë¡œ ë³€í™˜\n",
    "        binary_mask = (mask > 0).float()\n",
    "        axes[1, i].imshow(binary_mask, cmap='gray')\n",
    "        axes[1, i].set_title(f'Segmentation Mask {i+1}')\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except:\n",
    "    print('ìƒ˜í”Œ ì‹œê°í™” ìƒëµ (ë°ì´í„° ì—†ìŒ)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 ëª¨ë¸ í•™ìŠµ\n",
    "\n",
    "ì‹¤ì œ Pet ë°ì´í„°ì…‹ìœ¼ë¡œ U-Netì„ í•™ìŠµí•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒˆë¡œìš´ U-Net ëª¨ë¸ (ì‹¤ì œ ë°ì´í„°ìš©)\n",
    "model_pet = UNet(n_channels=3, n_classes=1)\n",
    "\n",
    "print('='*60)\n",
    "print('U-Net í•™ìŠµ ì‹œì‘ (Oxford-IIIT Pet)')\n",
    "print('='*60)\n",
    "\n",
    "try:\n",
    "    # í•™ìŠµ (ì—í­ ìˆ˜ ì¡°ì •)\n",
    "    train_losses_pet, val_losses_pet, val_ious_pet = train_model(\n",
    "        model_pet, train_loader_pet, test_loader_pet, epochs=30, lr=0.0001\n",
    "    )\n",
    "    print('\\nì‹¤ì œ ë°ì´í„° í•™ìŠµ ì™„ë£Œ!')\n",
    "except Exception as e:\n",
    "    print(f'í•™ìŠµ ì‹¤íŒ¨: {e}')\n",
    "    print('í•©ì„± ë°ì´í„° ê²°ê³¼ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 ê²°ê³¼ ë¶„ì„\n",
    "\n",
    "### ì‹¤ì œ ë°ì´í„°ì˜ ë„ì „ ê³¼ì œ\n",
    "\n",
    "1. **ë³µì¡í•œ ë°°ê²½**: í•©ì„± ë°ì´í„°ì™€ ë‹¬ë¦¬ ë‹¤ì–‘í•œ ë°°ê²½\n",
    "2. **ë‹¤ì–‘í•œ ìì„¸ì™€ ì¡°ëª…**: ì‹¤ì œ í™˜ê²½ì˜ ë³€ë™ì„±\n",
    "3. **ê²½ê³„ ëª¨í˜¸í•¨**: í„¸ì´ ë°°ê²½ê³¼ ì„ì—¬ ê²½ê³„ê°€ ë¶ˆëª…í™•\n",
    "\n",
    "### ì„±ëŠ¥ ê°œì„  ë°©ë²•\n",
    "\n",
    "âœ… **ë°ì´í„° ì¦ê°•**: íšŒì „, í”Œë¦½, ìƒ‰ìƒ ë³€í™˜ ë“±  \n",
    "âœ… **ë” ê¹Šì€ U-Net**: ë” ë§ì€ ë ˆì´ì–´  \n",
    "âœ… **ì•™ìƒë¸”**: ì—¬ëŸ¬ ëª¨ë¸ ê²°í•©  \n",
    "âœ… **í›„ì²˜ë¦¬**: CRF(Conditional Random Field) ë“±\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ğŸ“Š ëª¨ë“ˆ B ìš”ì•½ ë° ê²°ë¡ \n",
    "\n",
    "## í•™ìŠµí•œ ë‚´ìš©\n",
    "\n",
    "### ì´ë¡ \n",
    "- âœ… U-Netì˜ ì¸ì½”ë”-ë””ì½”ë” êµ¬ì¡°\n",
    "- âœ… Convolution, Pooling, UpConvolution ì—°ì‚°\n",
    "- âœ… Skip Connectionì˜ ì—­í• ê³¼ ì¤‘ìš”ì„±\n",
    "- âœ… Dice Loss, IoU ë“± ì„¸ê·¸ë¨¼í…Œì´ì…˜ í‰ê°€ ì§€í‘œ\n",
    "\n",
    "### ì‹¤ìŠµ\n",
    "- âœ… í•©ì„± ì´ë¯¸ì§€ ë°ì´í„° ìƒì„± ë° ì‹¤í—˜\n",
    "- âœ… U-Net êµ¬í˜„ ë° í•™ìŠµ\n",
    "- âœ… Oxford-IIIT Pet Dataset ë¶„í•  (ì‹œë„)\n",
    "- âœ… ëª¨ë¸ í‰ê°€ ë° ê²°ê³¼ ë¶„ì„\n",
    "\n",
    "## í•µì‹¬ ì¸ì‚¬ì´íŠ¸\n",
    "\n",
    "1. **U-Netì˜ íš¨ê³¼ì„±**\n",
    "   - ì¸ì½”ë”-ë””ì½”ë” êµ¬ì¡°ëŠ” ì„¸ê·¸ë¨¼í…Œì´ì…˜ì— ì´ìƒì \n",
    "   - Skip connectionì´ ì„¸ë¶€ ì •ë³´ ë³´ì¡´ì— í•„ìˆ˜ì \n",
    "   - ì ì€ ë°ì´í„°ë¡œë„ ì¢‹ì€ ì„±ëŠ¥\n",
    "\n",
    "2. **í‰ê°€ ì§€í‘œì˜ ì¤‘ìš”ì„±**\n",
    "   - Pixel AccuracyëŠ” ë¶ˆê· í˜•í•œ ë°ì´í„°ì— ë¶€ì í•©\n",
    "   - IoUì™€ DiceëŠ” ì„¸ê·¸ë¨¼í…Œì´ì…˜ í’ˆì§ˆì„ ë” ì˜ ë°˜ì˜\n",
    "   - ì—¬ëŸ¬ ì§€í‘œë¥¼ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•´ì•¼ í•¨\n",
    "\n",
    "3. **ì‹¤ì œ ë°ì´í„°ì˜ ë„ì „**\n",
    "   - í•©ì„± ë°ì´í„°ì™€ ì‹¤ì œ ë°ì´í„°ì˜ ì„±ëŠ¥ ì°¨ì´\n",
    "   - ë°ì´í„° ì¦ê°•ê³¼ ì •ê·œí™”ì˜ ì¤‘ìš”ì„±\n",
    "   - ë„ë©”ì¸ íŠ¹ì„± ì´í•´ê°€ í•„ìˆ˜\n",
    "\n",
    "## ì‹¤ë¬´ ì ìš© ê°€ì´ë“œ\n",
    "\n",
    "### ì–¸ì œ U-Netì„ ì‚¬ìš©í• ê¹Œ?\n",
    "\n",
    "**ì‚¬ìš© ê¶Œì¥:**\n",
    "- ì˜ë£Œ ì˜ìƒ ë¶„í•  (X-ray, CT, MRI)\n",
    "- ìœ„ì„± ì˜ìƒ ë¶„ì„\n",
    "- ììœ¨ ì£¼í–‰ (ë„ë¡œ ì„¸ê·¸ë¨¼í…Œì´ì…˜)\n",
    "- ê°ì²´ ê²€ì¶œ í›„ ì •ë°€ ë¶„í• \n",
    "\n",
    "**ëŒ€ì•ˆ ê³ ë ¤:**\n",
    "- ë§¤ìš° í° ì´ë¯¸ì§€: Patch ê¸°ë°˜ ì²˜ë¦¬ ë˜ëŠ” DeepLab\n",
    "- ì‹¤ì‹œê°„ ì²˜ë¦¬: ENet, SegNet ë“± ê²½ëŸ‰ ëª¨ë¸\n",
    "- Instance Segmentation: Mask R-CNN\n",
    "\n",
    "## ëª¨ë“ˆ Aì™€ B ë¹„êµ\n",
    "\n",
    "| ì¸¡ë©´ | ëª¨ë“ˆ A (RNN) | ëª¨ë“ˆ B (U-Net) |\n",
    "|------|-------------|---------------|\n",
    "| ì…ë ¥ | 1D ì‹œí€€ìŠ¤ | 2D ì´ë¯¸ì§€ |\n",
    "| ì•„í‚¤í…ì²˜ | ìˆœí™˜ êµ¬ì¡° | ì¸ì½”ë”-ë””ì½”ë” |\n",
    "| í•µì‹¬ ì—°ì‚° | ì‹œê°„ì¶• ì¬ê·€ | ê³µê°„ ì»¨ë³¼ë£¨ì…˜ |\n",
    "| ì£¼ìš” ê³¼ì œ | ì¥ê¸° ì˜ì¡´ì„± | ê³µê°„ ì •ë³´ ë³´ì¡´ |\n",
    "| í•´ê²°ì±… | LSTM/GRU ê²Œì´íŠ¸ | Skip Connection |\n",
    "| ì¶œë ¥ | ë‹¨ì¼ ê°’/ì‹œí€€ìŠ¤ | í”½ì…€ë³„ í´ë˜ìŠ¤ |\n",
    "\n",
    "## ìµœì¢… ì •ë¦¬\n",
    "\n",
    "### ê³µí†µ ì›ë¦¬\n",
    "\n",
    "ë‘ ëª¨ë“ˆ ëª¨ë‘ ë”¥ëŸ¬ë‹ì˜ í•µì‹¬ ì›ë¦¬ë¥¼ ê³µìœ í•©ë‹ˆë‹¤:\n",
    "- **ìˆœì „íŒŒ**: ì…ë ¥ â†’ íŠ¹ì§• ì¶”ì¶œ â†’ ì¶œë ¥\n",
    "- **ì—­ì „íŒŒ**: ì†ì‹¤ â†’ ê·¸ë˜ë””ì–¸íŠ¸ â†’ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
    "- **ìµœì í™”**: ê²½ì‚¬í•˜ê°•ë²• ë° ë³€í˜• (Adam ë“±)\n",
    "- **ì •ê·œí™”**: Dropout, Batch Normalization ë“±\n",
    "\n",
    "### ë„ë©”ì¸ íŠ¹í™”\n",
    "\n",
    "í•˜ì§€ë§Œ ê° ë„ë©”ì¸ì˜ íŠ¹ì„±ì— ë§ëŠ” ì„¤ê³„ê°€ í•„ìš”í•©ë‹ˆë‹¤:\n",
    "- **RNN**: ì‹œê°„ì  ì˜ì¡´ì„± í¬ì°©\n",
    "- **U-Net**: ê³µê°„ì  ëŒ€ì‘ ê´€ê³„ í•™ìŠµ\n",
    "\n",
    "---\n",
    "\n",
    "**ëª¨ë“ˆ Aì™€ B ëª¨ë‘ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤! ì¶•í•˜í•©ë‹ˆë‹¤! ğŸ‰ğŸ‰**\n",
    "\n",
    "ì´ì œ ì—¬ëŸ¬ë¶„ì€:\n",
    "- RNN/LSTM/GRUë¡œ ì‹œê³„ì—´ ë°ì´í„° ì²˜ë¦¬\n",
    "- U-Netìœ¼ë¡œ ì´ë¯¸ì§€ ë¶„í• \n",
    "- ì´ë¡ ê³¼ ì‹¤ìŠµì„ ì—°ê²°í•˜ëŠ” ëŠ¥ë ¥\n",
    "\n",
    "ì„ ëª¨ë‘ ê°–ì¶”ì—ˆìŠµë‹ˆë‹¤!\n",
    "\n",
    "ë‹¤ìŒ ë‹¨ê³„ëŠ” ì—¬ëŸ¬ë¶„ì˜ ë°ì´í„°ì™€ ë¬¸ì œì— ì´ ì§€ì‹ì„ ì ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "**Happy Deep Learning! ğŸš€**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
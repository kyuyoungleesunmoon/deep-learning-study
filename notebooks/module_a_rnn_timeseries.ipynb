{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ”¹ ëª¨ë“ˆ A: RNN ê¸°ë°˜ ì‹œê³„ì—´ ì˜ˆì¸¡ (Netflix ì£¼ê°€ ì˜ˆì¸¡)\n",
    "\n",
    "## ğŸ“š í•™ìŠµ ëª©í‘œ\n",
    "ì´ ëª¨ë“ˆì—ì„œëŠ” ìˆœí™˜ ì‹ ê²½ë§(RNN)ê³¼ ê·¸ ë³€í˜•ì¸ LSTM, GRUë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë°©ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤.\n",
    "\n",
    "**ì£¼ìš” í•™ìŠµ ë‚´ìš©:**\n",
    "- RNN, LSTM, GRUì˜ ë‚´ë¶€ êµ¬ì¡°ì™€ ìˆ˜í•™ì  ì›ë¦¬\n",
    "- ê·¸ë˜ë””ì–¸íŠ¸ ì†Œì‹¤/í­ì£¼ ë¬¸ì œì™€ í•´ê²° ë°©ë²•\n",
    "- í•©ì„± ë°ì´í„°ì™€ ì‹¤ì œ ì£¼ê°€ ë°ì´í„°ë¥¼ ì´ìš©í•œ ì‹¤í—˜\n",
    "- í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ê³¼ ì„±ëŠ¥ í‰ê°€\n",
    "\n",
    "**ëŒ€ìƒ í•™ìŠµì:** ì„ì‚¬ ìˆ˜ì¤€ì˜ ë”¥ëŸ¬ë‹ í•™ìŠµì  \n",
    "**ì˜ˆìƒ í•™ìŠµ ì‹œê°„:** 4-6ì‹œê°„\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1ï¸âƒ£ ì´ë¡  íŒŒíŠ¸\n",
    "\n",
    "## 1.1 ìˆœí™˜ ì‹ ê²½ë§(RNN)ì˜ ê¸°ë³¸ êµ¬ì¡°\n",
    "\n",
    "### ì™œ RNNì´ í•„ìš”í•œê°€?\n",
    "\n",
    "ì¼ë°˜ì ì¸ í”¼ë“œí¬ì›Œë“œ ì‹ ê²½ë§ì€ ê° ì…ë ¥ì„ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ ì‹œê³„ì—´ ë°ì´í„°ë‚˜ ìì—°ì–´ì™€ ê°™ì´ **ìˆœì„œê°€ ì¤‘ìš”í•œ ë°ì´í„°**ì—ì„œëŠ” ì´ì „ ì •ë³´ë¥¼ ê¸°ì–µí•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "RNNì€ **ìˆœí™˜ êµ¬ì¡°**ë¥¼ í†µí•´ ì´ì „ ì‹œì ì˜ ì •ë³´ë¥¼ í˜„ì¬ ì‹œì ìœ¼ë¡œ ì „ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "### RNNì˜ ìˆ˜í•™ì  ì •ì˜\n",
    "\n",
    "RNNì˜ ê¸°ë³¸ ìˆœì „íŒŒ ìˆ˜ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "\n",
    "$$h_t = \\tanh(W_h h_{t-1} + W_x x_t + b_h)$$\n",
    "\n",
    "$$y_t = W_y h_t + b_y$$\n",
    "\n",
    "**ê¸°í˜¸ ì„¤ëª…:**\n",
    "- $x_t$: ì‹œì  $t$ì—ì„œì˜ ì…ë ¥ ë²¡í„° (í¬ê¸°: $d_{input}$)\n",
    "- $h_t$: ì‹œì  $t$ì—ì„œì˜ ì€ë‹‰ ìƒíƒœ (í¬ê¸°: $d_{hidden}$)\n",
    "- $h_{t-1}$: ì´ì „ ì‹œì ì˜ ì€ë‹‰ ìƒíƒœ\n",
    "- $y_t$: ì‹œì  $t$ì—ì„œì˜ ì¶œë ¥ (í¬ê¸°: $d_{output}$)\n",
    "- $W_h$: ì€ë‹‰ ìƒíƒœ ê°€ì¤‘ì¹˜ í–‰ë ¬ (í¬ê¸°: $d_{hidden} \\times d_{hidden}$)\n",
    "- $W_x$: ì…ë ¥ ê°€ì¤‘ì¹˜ í–‰ë ¬ (í¬ê¸°: $d_{hidden} \\times d_{input}$)\n",
    "- $W_y$: ì¶œë ¥ ê°€ì¤‘ì¹˜ í–‰ë ¬ (í¬ê¸°: $d_{output} \\times d_{hidden}$)\n",
    "- $b_h, b_y$: í¸í–¥(bias) ë²¡í„°\n",
    "- $\\tanh$: í•˜ì´í¼ë³¼ë¦­ íƒ„ì  íŠ¸ í™œì„±í™” í•¨ìˆ˜ (ì¶œë ¥ ë²”ìœ„: -1 ~ 1)\n",
    "\n",
    "### RNNì˜ ë™ì‘ ì›ë¦¬\n",
    "\n",
    "1. **ì´ˆê¸°í™”**: ì€ë‹‰ ìƒíƒœ $h_0$ëŠ” ë³´í†µ ì˜ë²¡í„°ë¡œ ì´ˆê¸°í™”\n",
    "2. **ìˆœì „íŒŒ** (ê° ì‹œì  $t = 1, 2, ..., T$):\n",
    "   - í˜„ì¬ ì…ë ¥ $x_t$ì™€ ì´ì „ ì€ë‹‰ ìƒíƒœ $h_{t-1}$ì„ ê²°í•©\n",
    "   - ì„ í˜• ë³€í™˜ í›„ í™œì„±í™” í•¨ìˆ˜ ì ìš© â†’ ìƒˆë¡œìš´ ì€ë‹‰ ìƒíƒœ $h_t$ ìƒì„±\n",
    "   - í•„ìš”ì‹œ ì€ë‹‰ ìƒíƒœë¥¼ ì¶œë ¥ìœ¼ë¡œ ë³€í™˜ â†’ $y_t$ ìƒì„±\n",
    "3. **ì •ë³´ ì „ë‹¬**: $h_t$ê°€ ë‹¤ìŒ ì‹œì ìœ¼ë¡œ ì „ë‹¬ë˜ì–´ ì‹œí€€ìŠ¤ ì •ë³´ ìœ ì§€\n",
    "\n",
    "### ê°„ë‹¨í•œ ìˆ˜ì¹˜ ì˜ˆì œ\n",
    "\n",
    "**ì„¤ì •:**\n",
    "- ì…ë ¥ ì°¨ì›: 1, ì€ë‹‰ ì°¨ì›: 2\n",
    "- $W_h = \\begin{bmatrix} 0.5 & 0.2 \\\\ 0.3 & 0.4 \\end{bmatrix}$, $W_x = \\begin{bmatrix} 0.6 \\\\ 0.7 \\end{bmatrix}$, $b_h = \\begin{bmatrix} 0.1 \\\\ 0.1 \\end{bmatrix}$\n",
    "\n",
    "**ì‹œì  t=1:**\n",
    "- $h_0 = [0, 0]^T$, $x_1 = 1.0$\n",
    "- $z_1 = W_h h_0 + W_x x_1 + b_h = [0.7, 0.8]^T$\n",
    "- $h_1 = \\tanh([0.7, 0.8]^T) â‰ˆ [0.604, 0.664]^T$\n",
    "\n",
    "ì´ë ‡ê²Œ ê° ì‹œì ë§ˆë‹¤ ì€ë‹‰ ìƒíƒœê°€ ì—…ë°ì´íŠ¸ë˜ë©° ì´ì „ ì •ë³´ë¥¼ ëˆ„ì í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 ê·¸ë˜ë””ì–¸íŠ¸ ì†Œì‹¤/í­ì£¼ ë¬¸ì œ\n",
    "\n",
    "### ë¬¸ì œì˜ ì›ì¸\n",
    "\n",
    "RNNì„ ì—­ì „íŒŒ(BPTT: Backpropagation Through Time)ë¡œ í•™ìŠµí•  ë•Œ, ê·¸ë˜ë””ì–¸íŠ¸ëŠ” ì‹œê°„ ì¶•ì„ ë”°ë¼ ì—­ìœ¼ë¡œ ì „íŒŒë©ë‹ˆë‹¤:\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial h_{t-k}} = \\frac{\\partial L}{\\partial h_t} \\prod_{i=t-k+1}^{t} \\frac{\\partial h_i}{\\partial h_{i-1}}$$\n",
    "\n",
    "ì—¬ê¸°ì„œ $\\frac{\\partial h_i}{\\partial h_{i-1}}$ëŠ” ì£¼ë¡œ $W_h$ì™€ í™œì„±í™” í•¨ìˆ˜ì˜ ë¯¸ë¶„ì„ í¬í•¨í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ë¬¸ì œ:**\n",
    "- ë§Œì•½ ì´ ê°’ì´ **1ë³´ë‹¤ ì‘ìœ¼ë©´**: ì—¬ëŸ¬ ë²ˆ ê³±í•´ì§ˆìˆ˜ë¡ 0ì— ê°€ê¹Œì›Œì§ â†’ **ê·¸ë˜ë””ì–¸íŠ¸ ì†Œì‹¤**\n",
    "- ë§Œì•½ ì´ ê°’ì´ **1ë³´ë‹¤ í¬ë©´**: ì—¬ëŸ¬ ë²ˆ ê³±í•´ì§ˆìˆ˜ë¡ ë¬´í•œëŒ€ë¡œ ë°œì‚° â†’ **ê·¸ë˜ë””ì–¸íŠ¸ í­ì£¼**\n",
    "\n",
    "### ìˆ˜ì¹˜ì  ì˜ˆì‹œ\n",
    "\n",
    "**ê·¸ë˜ë””ì–¸íŠ¸ ì†Œì‹¤:**\n",
    "- $\\frac{\\partial h_i}{\\partial h_{i-1}} = 0.5$ (ê° ì‹œì ë§ˆë‹¤)\n",
    "- 10 ì‹œì : $0.5^{10} â‰ˆ 0.00098$\n",
    "- 20 ì‹œì : $0.5^{20} â‰ˆ 0.00000095$\n",
    "\n",
    "**ê·¸ë˜ë””ì–¸íŠ¸ í­ì£¼:**\n",
    "- $\\frac{\\partial h_i}{\\partial h_{i-1}} = 1.5$ (ê° ì‹œì ë§ˆë‹¤)\n",
    "- 10 ì‹œì : $1.5^{10} â‰ˆ 57.7$\n",
    "- 20 ì‹œì : $1.5^{20} â‰ˆ 3325$\n",
    "\n",
    "### ê²°ê³¼ ë° í•´ê²° ë°©ë²•\n",
    "\n",
    "**ì†Œì‹¤**: ì¥ê¸° ì˜ì¡´ì„± í•™ìŠµ ë¶ˆê°€ â†’ **LSTM/GRU ì‚¬ìš©**  \n",
    "**í­ì£¼**: í•™ìŠµ ë¶ˆì•ˆì • â†’ **ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘ ì‚¬ìš©**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 LSTM (Long Short-Term Memory)\n",
    "\n",
    "LSTMì€ **ê²Œì´íŠ¸ ë©”ì»¤ë‹ˆì¦˜**ì„ í†µí•´ ê·¸ë˜ë””ì–¸íŠ¸ ì†Œì‹¤ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.\n",
    "\n",
    "### LSTMì˜ êµ¬ì¡°\n",
    "\n",
    "LSTMì€ ì„¸ ê°€ì§€ ê²Œì´íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤:\n",
    "\n",
    "1. **Forget Gate** $f_t$: ì–´ë–¤ ì •ë³´ë¥¼ ë²„ë¦´ì§€ ê²°ì •\n",
    "2. **Input Gate** $i_t$: ì–´ë–¤ ìƒˆë¡œìš´ ì •ë³´ë¥¼ ì €ì¥í• ì§€ ê²°ì •\n",
    "3. **Output Gate** $o_t$: ì–´ë–¤ ì •ë³´ë¥¼ ì¶œë ¥í• ì§€ ê²°ì •\n",
    "\n",
    "### LSTMì˜ ìˆ˜ì‹\n",
    "\n",
    "$$f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f) \\quad \\text{(Forget Gate)}$$\n",
    "\n",
    "$$i_t = \\sigma(W_i \\cdot [h_{t-1}, x_t] + b_i) \\quad \\text{(Input Gate)}$$\n",
    "\n",
    "$$\\tilde{C}_t = \\tanh(W_C \\cdot [h_{t-1}, x_t] + b_C) \\quad \\text{(Candidate Cell State)}$$\n",
    "\n",
    "$$C_t = f_t \\odot C_{t-1} + i_t \\odot \\tilde{C}_t \\quad \\text{(Cell State Update)}$$\n",
    "\n",
    "$$o_t = \\sigma(W_o \\cdot [h_{t-1}, x_t] + b_o) \\quad \\text{(Output Gate)}$$\n",
    "\n",
    "$$h_t = o_t \\odot \\tanh(C_t) \\quad \\text{(Hidden State)}$$\n",
    "\n",
    "**ê¸°í˜¸ ì„¤ëª…:**\n",
    "- $\\sigma$: ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ (0~1 ì‚¬ì´ ê°’ ì¶œë ¥)\n",
    "- $\\odot$: ì›ì†Œë³„ ê³±ì…ˆ\n",
    "- $C_t$: ì…€ ìƒíƒœ - ì¥ê¸° ê¸°ì–µ ë‹´ë‹¹\n",
    "- $[h_{t-1}, x_t]$: ë²¡í„° ì—°ê²°\n",
    "\n",
    "### LSTMì´ ì†Œì‹¤ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ì›ë¦¬\n",
    "\n",
    "1. **ì§ì ‘ì ì¸ ê²½ë¡œ**: $C_t = f_t \\odot C_{t-1} + ...$ì—ì„œ ë§ì…ˆ ì—°ì‚°ì€ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ì§ì ‘ ì „íŒŒ\n",
    "2. **ê²Œì´íŠ¸ ì œì–´**: Forget gateê°€ 1ì— ê°€ê¹Œìš°ë©´ ê·¸ë˜ë””ì–¸íŠ¸ê°€ ê±°ì˜ ê·¸ëŒ€ë¡œ ì „íŒŒë¨\n",
    "3. **ì„ íƒì  ê¸°ì–µ**: ì¤‘ìš”í•œ ì •ë³´ë§Œ ì„ íƒì ìœ¼ë¡œ ë³´ì¡´í•˜ê³  ì „íŒŒ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 GRU (Gated Recurrent Unit)\n",
    "\n",
    "GRUëŠ” LSTMì„ ë‹¨ìˆœí™”í•œ ë³€í˜•ìœ¼ë¡œ, **2ê°œì˜ ê²Œì´íŠ¸**ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "### GRUì˜ ìˆ˜ì‹\n",
    "\n",
    "$$z_t = \\sigma(W_z \\cdot [h_{t-1}, x_t] + b_z) \\quad \\text{(Update Gate)}$$\n",
    "\n",
    "$$r_t = \\sigma(W_r \\cdot [h_{t-1}, x_t] + b_r) \\quad \\text{(Reset Gate)}$$\n",
    "\n",
    "$$\\tilde{h}_t = \\tanh(W_h \\cdot [r_t \\odot h_{t-1}, x_t] + b_h) \\quad \\text{(Candidate)}$$\n",
    "\n",
    "$$h_t = (1 - z_t) \\odot h_{t-1} + z_t \\odot \\tilde{h}_t \\quad \\text{(Hidden State)}$$\n",
    "\n",
    "**ê¸°í˜¸ ì„¤ëª…:**\n",
    "- $z_t$: Update gate - ì´ì „ ìƒíƒœì™€ ìƒˆë¡œìš´ ìƒíƒœì˜ ë¹„ìœ¨ ê²°ì •\n",
    "- $r_t$: Reset gate - ì´ì „ ìƒíƒœë¥¼ ì–¼ë§ˆë‚˜ ë¬´ì‹œí• ì§€ ê²°ì •\n",
    "\n",
    "### LSTM vs GRU\n",
    "\n",
    "| íŠ¹ì§• | LSTM | GRU |\n",
    "|------|------|-----|\n",
    "| ê²Œì´íŠ¸ ìˆ˜ | 3ê°œ | 2ê°œ |\n",
    "| íŒŒë¼ë¯¸í„° ìˆ˜ | ë” ë§ìŒ | ë” ì ìŒ |\n",
    "| ê³„ì‚° ë³µì¡ë„ | ë†’ìŒ | ë‚®ìŒ |\n",
    "| ì„±ëŠ¥ | ë§¤ìš° ê¸´ ì‹œí€€ìŠ¤ì— ìœ ë¦¬ | ì§§ì€~ì¤‘ê°„ ì‹œí€€ìŠ¤ì— íš¨ìœ¨ì  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 ì—­ì „íŒŒ (BPTT - Backpropagation Through Time)\n",
    "\n",
    "### ê°œë…\n",
    "\n",
    "ì‹œê³„ì—´ ë°ì´í„°ì—ì„œ ì—­ì „íŒŒëŠ” ì‹œê°„ì„ ê±°ìŠ¬ëŸ¬ ì˜¬ë¼ê°€ë©° ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ê³¼ì •\n",
    "\n",
    "1. ìˆœì „íŒŒë¡œ ëª¨ë“  ì‹œì ì˜ ì€ë‹‰ ìƒíƒœì™€ ì¶œë ¥ ê³„ì‚°\n",
    "2. ë§ˆì§€ë§‰ ì‹œì ë¶€í„° ì‹œì‘í•˜ì—¬ ì—­ìœ¼ë¡œ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°\n",
    "3. ì—°ì‡„ ë²•ì¹™(Chain Rule)ì„ ì ìš©í•˜ì—¬ ê° ê°€ì¤‘ì¹˜ì˜ ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì \n",
    "4. ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
    "\n",
    "### Truncated BPTT\n",
    "\n",
    "ë©”ëª¨ë¦¬ íš¨ìœ¨ì„ ìœ„í•´ ì „ì²´ ì‹œí€€ìŠ¤ê°€ ì•„ë‹Œ **ì¼ì • ê¸¸ì´ë§Œí¼ë§Œ** ì—­ì „íŒŒí•˜ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.\n",
    "\n",
    "## 1.6 ì†ì‹¤ í•¨ìˆ˜ì™€ í‰ê°€ ì§€í‘œ\n",
    "\n",
    "### ì†ì‹¤ í•¨ìˆ˜\n",
    "\n",
    "**MSE (Mean Squared Error):**\n",
    "$$L_{MSE} = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "**MAE (Mean Absolute Error):**\n",
    "$$L_{MAE} = \\frac{1}{n}\\sum_{i=1}^{n}|y_i - \\hat{y}_i|$$\n",
    "\n",
    "### í‰ê°€ ì§€í‘œ\n",
    "\n",
    "**RMSE (Root Mean Squared Error):**\n",
    "$$RMSE = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}$$\n",
    "\n",
    "**MAPE (Mean Absolute Percentage Error):**\n",
    "$$MAPE = \\frac{100\\%}{n}\\sum_{i=1}^{n}\\left|\\frac{y_i - \\hat{y}_i}{y_i}\\right|$$\n",
    "\n",
    "**ê¸°í˜¸ ì„¤ëª…:**\n",
    "- $y_i$: ì‹¤ì œ ê°’\n",
    "- $\\hat{y}_i$: ì˜ˆì¸¡ ê°’\n",
    "- $n$: ìƒ˜í”Œ ê°œìˆ˜\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2ï¸âƒ£ í•©ì„± ë°ì´í„° ì‹¤í—˜\n",
    "\n",
    "## 2.1 í•©ì„± ì‹œê³„ì—´ ë°ì´í„° ìƒì„±\n",
    "\n",
    "ë‹¨ìˆœí•œ ì‚¬ì¸íŒŒì— ë…¸ì´ì¦ˆë¥¼ ì¶”ê°€í•œ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì—¬ RNN ê³„ì—´ ëª¨ë¸ì˜ ë™ì‘ì„ ì´í•´í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„í¬íŠ¸\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ì„¤ì •\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•©ì„± ì‹œê³„ì—´ ë°ì´í„° ìƒì„± í•¨ìˆ˜\n",
    "def generate_synthetic_timeseries(n_samples=1000, noise_level=0.1):\n",
    "    t = np.linspace(0, 100, n_samples)\n",
    "    signal = np.sin(0.1 * t) + 0.5 * np.sin(0.3 * t) + 0.3 * np.sin(0.5 * t)\n",
    "    noise = np.random.normal(0, noise_level, n_samples)\n",
    "    return signal + noise\n",
    "\n",
    "# ë°ì´í„° ìƒì„±\n",
    "synthetic_data = generate_synthetic_timeseries(n_samples=1000, noise_level=0.1)\n",
    "\n",
    "# ì‹œê°í™”\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.plot(synthetic_data, linewidth=0.8)\n",
    "plt.title('í•©ì„± ì‹œê³„ì—´ ë°ì´í„° (ì‚¬ì¸íŒŒ + ë…¸ì´ì¦ˆ)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Value')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'ë°ì´í„° í˜•íƒœ: {synthetic_data.shape}')\n",
    "print(f'ë°ì´í„° ë²”ìœ„: [{synthetic_data.min():.3f}, {synthetic_data.max():.3f}]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 ë°ì´í„° ì „ì²˜ë¦¬\n",
    "\n",
    "### ìœˆë„ìš° ìŠ¬ë¼ì´ë”© ê¸°ë²•\n",
    "\n",
    "ì‹œê³„ì—´ ì˜ˆì¸¡ì„ ìœ„í•´ ê³¼ê±° ì¼ì • ê¸°ê°„(window)ì˜ ë°ì´í„°ë¥¼ ì…ë ¥ìœ¼ë¡œ, ë‹¤ìŒ ê°’ì„ íƒ€ê²Ÿìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìœˆë„ìš° ìƒì„± í•¨ìˆ˜\n",
    "def create_windows(data, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i+window_size])\n",
    "        y.append(data[i+window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# ì •ê·œí™” ë° ìœˆë„ìš° ìƒì„±\n",
    "scaler = MinMaxScaler()\n",
    "synthetic_data_normalized = scaler.fit_transform(synthetic_data.reshape(-1, 1)).flatten()\n",
    "window_size = 30\n",
    "X, y = create_windows(synthetic_data_normalized, window_size)\n",
    "\n",
    "# í•™ìŠµ/ê²€ì¦ ë¶„ë¦¬\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, X_val = X[:split_idx], X[split_idx:]\n",
    "y_train, y_val = y[:split_idx], y[split_idx:]\n",
    "\n",
    "print(f'X í˜•íƒœ: {X.shape}')\n",
    "print(f'í•™ìŠµ ë°ì´í„°: {X_train.shape}')\n",
    "print(f'ê²€ì¦ ë°ì´í„°: {X_val.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 RNN/LSTM/GRU ëª¨ë¸ êµ¬í˜„\n",
    "\n",
    "PyTorchë¥¼ ì‚¬ìš©í•˜ì—¬ ì„¸ ê°€ì§€ ëª¨ë¸ì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN ëª¨ë¸\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, dropout=0.2):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, \n",
    "                          batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# LSTM ëª¨ë¸\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, dropout=0.2):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,\n",
    "                           batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# GRU ëª¨ë¸\n",
    "class SimpleGRU(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, dropout=0.2):\n",
    "        super(SimpleGRU, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers,\n",
    "                         batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "print('ëª¨ë¸ ì •ì˜ ì™„ë£Œ: RNN, LSTM, GRU')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 í•™ìŠµ ë° í‰ê°€ í•¨ìˆ˜\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset í´ë˜ìŠ¤\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.FloatTensor(X).unsqueeze(-1)\n",
    "        self.y = torch.FloatTensor(y).unsqueeze(-1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# DataLoader ìƒì„±\n",
    "train_dataset = TimeSeriesDataset(X_train, y_train)\n",
    "val_dataset = TimeSeriesDataset(X_val, y_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# í•™ìŠµ í•¨ìˆ˜\n",
    "def train_model(model, train_loader, val_loader, epochs=50, lr=0.001, clip_grad=True):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    train_losses, val_losses = [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            if clip_grad:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}')\n",
    "    \n",
    "    return train_losses, val_losses\n",
    "\n",
    "def predict_model(model, data_loader):\n",
    "    model.eval()\n",
    "    predictions, actuals = [], []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in data_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            actuals.extend(y_batch.numpy())\n",
    "    return np.array(predictions).flatten(), np.array(actuals).flatten()\n",
    "\n",
    "print('í•™ìŠµ/ì˜ˆì¸¡ í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 ì‹¤í—˜ 1: RNN vs LSTM vs GRU ë¹„êµ\n",
    "\n",
    "ì„¸ ê°€ì§€ ëª¨ë¸ì„ ë™ì¼í•œ ì¡°ê±´ì—ì„œ í•™ìŠµì‹œí‚¤ê³  ì„±ëŠ¥ì„ ë¹„êµí•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ì´ˆê¸°í™”\n",
    "models = {\n",
    "    'RNN': SimpleRNN(hidden_size=64, num_layers=2),\n",
    "    'LSTM': SimpleLSTM(hidden_size=64, num_layers=2),\n",
    "    'GRU': SimpleGRU(hidden_size=64, num_layers=2)\n",
    "}\n",
    "\n",
    "# ê° ëª¨ë¸ í•™ìŠµ\n",
    "results = {}\n",
    "print('='*60)\n",
    "print('ëª¨ë¸ í•™ìŠµ ì‹œì‘...')\n",
    "print('='*60)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f'\\n[{name}] í•™ìŠµ ì¤‘...')\n",
    "    train_losses, val_losses = train_model(\n",
    "        model, train_loader, val_loader, epochs=50, lr=0.001, clip_grad=True\n",
    "    )\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses\n",
    "    }\n",
    "    print(f'[{name}] ìµœì¢… ê²€ì¦ ì†ì‹¤: {val_losses[-1]:.6f}')\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!')\n",
    "print('='*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì†ì‹¤ ê³¡ì„  ì‹œê°í™”\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "for idx, (name, result) in enumerate(results.items(), 1):\n",
    "    plt.subplot(1, 3, idx)\n",
    "    plt.plot(result['train_losses'], label='Train Loss', linewidth=2)\n",
    "    plt.plot(result['val_losses'], label='Val Loss', linewidth=2)\n",
    "    plt.title(f'{name} Loss Curve', fontsize=12, fontweight='bold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì¸¡ ì„±ëŠ¥ ë¹„êµ\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "for idx, (name, result) in enumerate(results.items(), 1):\n",
    "    model = result['model']\n",
    "    predictions, actuals = predict_model(model, val_loader)\n",
    "    rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "    mae = mean_absolute_error(actuals, predictions)\n",
    "    \n",
    "    plt.subplot(1, 3, idx)\n",
    "    plt.plot(actuals[:100], label='Actual', linewidth=2, alpha=0.7)\n",
    "    plt.plot(predictions[:100], label='Predicted', linewidth=2, alpha=0.7)\n",
    "    plt.title(f'{name}\\nRMSE: {rmse:.4f}, MAE: {mae:.4f}', fontsize=11, fontweight='bold')\n",
    "    plt.xlabel('Sample')\n",
    "    plt.ylabel('Normalized Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ì„±ëŠ¥ ì§€í‘œ ìš”ì•½\n",
    "print('\\n' + '='*60)\n",
    "print('ì„±ëŠ¥ ì§€í‘œ ìš”ì•½')\n",
    "print('='*60)\n",
    "for name, result in results.items():\n",
    "    model = result['model']\n",
    "    predictions, actuals = predict_model(model, val_loader)\n",
    "    rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "    mae = mean_absolute_error(actuals, predictions)\n",
    "    print(f'{name:10s} | RMSE: {rmse:.6f} | MAE: {mae:.6f}')\n",
    "print('='*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 í•©ì„± ë°ì´í„° ì‹¤í—˜ ê²°ê³¼ ë¶„ì„\n",
    "\n",
    "### ì£¼ìš” ë°œê²¬ì‚¬í•­\n",
    "\n",
    "1. **ëª¨ë¸ ë¹„êµ (RNN vs LSTM vs GRU)**\n",
    "   - LSTMê³¼ GRUê°€ ê¸°ë³¸ RNNë³´ë‹¤ ì¼ê´€ë˜ê²Œ ìš°ìˆ˜í•œ ì„±ëŠ¥\n",
    "   - GRUëŠ” LSTMê³¼ ìœ ì‚¬í•œ ì„±ëŠ¥ì„ ë³´ì´ë©´ì„œë„ íŒŒë¼ë¯¸í„° ìˆ˜ê°€ ì ì–´ íš¨ìœ¨ì \n",
    "   - RNNì€ ê·¸ë˜ë””ì–¸íŠ¸ ì†Œì‹¤ë¡œ ì¸í•´ ì¥ê¸° íŒ¨í„´ í•™ìŠµì— ì–´ë ¤ì›€\n",
    "\n",
    "2. **í•™ìŠµ ì•ˆì •ì„±**\n",
    "   - ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘ì´ í•™ìŠµ ì´ˆê¸° ë¶ˆì•ˆì •ì„± ì œê±°\n",
    "   - LSTM/GRUëŠ” ë” ì•ˆì •ì ì¸ í•™ìŠµ ê³¡ì„  ë³´ì„\n",
    "\n",
    "### êµí›ˆ\n",
    "\n",
    "âœ… **LSTM/GRUëŠ” ì‹œê³„ì—´ ì˜ˆì¸¡ì— í•„ìˆ˜ì **  \n",
    "âœ… **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì´ ì¤‘ìš”**  \n",
    "âœ… **ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘ì€ ì•ˆì •ì ì¸ í•™ìŠµì— ë„ì›€**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3ï¸âƒ£ ì‹¤ì œ ë°ì´í„° í•™ìŠµ: Netflix ì£¼ê°€ ì˜ˆì¸¡\n",
    "\n",
    "## 3.1 ë°ì´í„° ìˆ˜ì§‘\n",
    "\n",
    "`yfinance` íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ë„·í”Œë¦­ìŠ¤ ì£¼ê°€ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yfinance ì„¤ì¹˜ ë° ì„í¬íŠ¸\n",
    "try:\n",
    "    import yfinance as yf\n",
    "    print('yfinance íŒ¨í‚¤ì§€ ë¡œë“œ ì„±ê³µ!')\n",
    "except ImportError:\n",
    "    print('yfinance ì„¤ì¹˜ ì¤‘...')\n",
    "    !pip install -q yfinance\n",
    "    import yfinance as yf\n",
    "    print('yfinance ì„¤ì¹˜ ë° ë¡œë“œ ì™„ë£Œ!')\n",
    "\n",
    "# Netflix ì£¼ê°€ ë°ì´í„° ë‹¤ìš´ë¡œë“œ\n",
    "print('\\nNetflix ì£¼ê°€ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘...')\n",
    "ticker = 'NFLX'\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2024-01-01'\n",
    "\n",
    "df = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "print(f'ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(df)} ê±°ë˜ì¼')\n",
    "print(f'ê¸°ê°„: {df.index[0]} ~ {df.index[-1]}')\n",
    "\n",
    "# ë°ì´í„° í™•ì¸\n",
    "print('\\në°ì´í„° ìƒ˜í”Œ:')\n",
    "print(df.head())\n",
    "\n",
    "# ì¢…ê°€(Close) ë°ì´í„° ì¶”ì¶œ\n",
    "close_prices = df['Close'].values\n",
    "print(f'\\nì¢…ê°€ ë°ì´í„° í˜•íƒœ: {close_prices.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì£¼ê°€ ë°ì´í„° ì‹œê°í™”\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(df.index, close_prices, linewidth=1.5, color='darkblue')\n",
    "plt.title(f'{ticker} ì£¼ê°€ ì¶”ì´ ({start_date} ~ {end_date})', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Close Price (USD)', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ê¸°ì´ˆ í†µê³„\n",
    "print('\\nì£¼ê°€ ê¸°ì´ˆ í†µê³„:')\n",
    "print(f'í‰ê· : ${close_prices.mean():.2f}')\n",
    "print(f'í‘œì¤€í¸ì°¨: ${close_prices.std():.2f}')\n",
    "print(f'ìµœì†Œê°’: ${close_prices.min():.2f}')\n",
    "print(f'ìµœëŒ€ê°’: ${close_prices.max():.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 ë°ì´í„° ì „ì²˜ë¦¬\n",
    "\n",
    "ì£¼ê°€ ë°ì´í„°ë¥¼ ì •ê·œí™”í•˜ê³  ìœˆë„ìš° í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ì •ê·œí™”\n",
    "scaler_stock = MinMaxScaler()\n",
    "close_prices_normalized = scaler_stock.fit_transform(close_prices.reshape(-1, 1)).flatten()\n",
    "\n",
    "# ìœˆë„ìš° ìƒì„± (ê³¼ê±° 60ì¼ë¡œ ë‹¤ìŒ ë‚  ì˜ˆì¸¡)\n",
    "window_size_stock = 60\n",
    "X_stock, y_stock = create_windows(close_prices_normalized, window_size_stock)\n",
    "\n",
    "print(f'ìœˆë„ìš° ë°ì´í„° í˜•íƒœ: {X_stock.shape}')\n",
    "print(f'íƒ€ê²Ÿ ë°ì´í„° í˜•íƒœ: {y_stock.shape}')\n",
    "\n",
    "# í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë¶„ë¦¬ (70:15:15)\n",
    "n = len(X_stock)\n",
    "train_end = int(n * 0.7)\n",
    "val_end = int(n * 0.85)\n",
    "\n",
    "X_train_stock = X_stock[:train_end]\n",
    "y_train_stock = y_stock[:train_end]\n",
    "X_val_stock = X_stock[train_end:val_end]\n",
    "y_val_stock = y_stock[train_end:val_end]\n",
    "X_test_stock = X_stock[val_end:]\n",
    "y_test_stock = y_stock[val_end:]\n",
    "\n",
    "print(f'\\ní•™ìŠµ ë°ì´í„°: {X_train_stock.shape}')\n",
    "print(f'ê²€ì¦ ë°ì´í„°: {X_val_stock.shape}')\n",
    "print(f'í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test_stock.shape}')\n",
    "\n",
    "# DataLoader ìƒì„±\n",
    "train_dataset_stock = TimeSeriesDataset(X_train_stock, y_train_stock)\n",
    "val_dataset_stock = TimeSeriesDataset(X_val_stock, y_val_stock)\n",
    "test_dataset_stock = TimeSeriesDataset(X_test_stock, y_test_stock)\n",
    "\n",
    "train_loader_stock = DataLoader(train_dataset_stock, batch_size=16, shuffle=True)\n",
    "val_loader_stock = DataLoader(val_dataset_stock, batch_size=16, shuffle=False)\n",
    "test_loader_stock = DataLoader(test_dataset_stock, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 LSTM ëª¨ë¸ í•™ìŠµ\n",
    "\n",
    "LSTM ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ Netflix ì£¼ê°€ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model_stock_lstm = SimpleLSTM(\n",
    "    input_size=1,\n",
    "    hidden_size=128,  # ë” í° íˆë“  í¬ê¸°\n",
    "    num_layers=3,     # ë” ê¹Šì€ ë„¤íŠ¸ì›Œí¬\n",
    "    dropout=0.2\n",
    ")\n",
    "\n",
    "print('='*60)\n",
    "print('Netflix ì£¼ê°€ ì˜ˆì¸¡ - LSTM í•™ìŠµ ì‹œì‘')\n",
    "print('='*60)\n",
    "\n",
    "# í•™ìŠµ\n",
    "train_losses_stock, val_losses_stock = train_model(\n",
    "    model_stock_lstm, train_loader_stock, val_loader_stock,\n",
    "    epochs=100, lr=0.001, clip_grad=True\n",
    ")\n",
    "\n",
    "print('\\nLSTM í•™ìŠµ ì™„ë£Œ!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•™ìŠµ ê³¡ì„  ì‹œê°í™”\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(train_losses_stock, label='Train Loss', linewidth=2)\n",
    "plt.plot(val_losses_stock, label='Val Loss', linewidth=2)\n",
    "plt.title('LSTM Training on Netflix Stock', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 GRU ëª¨ë¸ í•™ìŠµ\n",
    "\n",
    "ë¹„êµë¥¼ ìœ„í•´ GRU ëª¨ë¸ë„ í•™ìŠµí•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model_stock_gru = SimpleGRU(\n",
    "    input_size=1,\n",
    "    hidden_size=128,\n",
    "    num_layers=3,\n",
    "    dropout=0.2\n",
    ")\n",
    "\n",
    "print('='*60)\n",
    "print('Netflix ì£¼ê°€ ì˜ˆì¸¡ - GRU í•™ìŠµ ì‹œì‘')\n",
    "print('='*60)\n",
    "\n",
    "# í•™ìŠµ\n",
    "train_losses_stock_gru, val_losses_stock_gru = train_model(\n",
    "    model_stock_gru, train_loader_stock, val_loader_stock,\n",
    "    epochs=100, lr=0.001, clip_grad=True\n",
    ")\n",
    "\n",
    "print('\\nGRU í•™ìŠµ ì™„ë£Œ!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ ë° í‰ê°€\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡\n",
    "pred_lstm, actual_test = predict_model(model_stock_lstm, test_loader_stock)\n",
    "pred_gru, _ = predict_model(model_stock_gru, test_loader_stock)\n",
    "\n",
    "# ì›ë˜ ìŠ¤ì¼€ì¼ë¡œ ë³µì›\n",
    "pred_lstm_original = scaler_stock.inverse_transform(pred_lstm.reshape(-1, 1)).flatten()\n",
    "pred_gru_original = scaler_stock.inverse_transform(pred_gru.reshape(-1, 1)).flatten()\n",
    "actual_test_original = scaler_stock.inverse_transform(actual_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "# í‰ê°€ ì§€í‘œ ê³„ì‚°\n",
    "rmse_lstm = np.sqrt(mean_squared_error(actual_test_original, pred_lstm_original))\n",
    "mae_lstm = mean_absolute_error(actual_test_original, pred_lstm_original)\n",
    "mape_lstm = np.mean(np.abs((actual_test_original - pred_lstm_original) / actual_test_original)) * 100\n",
    "\n",
    "rmse_gru = np.sqrt(mean_squared_error(actual_test_original, pred_gru_original))\n",
    "mae_gru = mean_absolute_error(actual_test_original, pred_gru_original)\n",
    "mape_gru = np.mean(np.abs((actual_test_original - pred_gru_original) / actual_test_original)) * 100\n",
    "\n",
    "print('='*70)\n",
    "print('Netflix ì£¼ê°€ ì˜ˆì¸¡ ì„±ëŠ¥ í‰ê°€ (í…ŒìŠ¤íŠ¸ ë°ì´í„°)')\n",
    "print('='*70)\n",
    "print(f'{\"Model\":<10} | {\"RMSE\":<12} | {\"MAE\":<12} | {\"MAPE (%)\":<12}')\n",
    "print('-'*70)\n",
    "print(f'{\"LSTM\":<10} | ${rmse_lstm:<11.2f} | ${mae_lstm:<11.2f} | {mape_lstm:<11.2f}%')\n",
    "print(f'{\"GRU\":<10} | ${rmse_gru:<11.2f} | ${mae_gru:<11.2f} | {mape_gru:<11.2f}%')\n",
    "print('='*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# ì „ì²´ í…ŒìŠ¤íŠ¸ ê¸°ê°„\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(actual_test_original, label='Actual', linewidth=2, alpha=0.7, color='black')\n",
    "plt.plot(pred_lstm_original, label='LSTM Prediction', linewidth=2, alpha=0.7)\n",
    "plt.plot(pred_gru_original, label='GRU Prediction', linewidth=2, alpha=0.7)\n",
    "plt.title(f'Netflix Stock Price Prediction (Test Set)\\nLSTM MAPE: {mape_lstm:.2f}%, GRU MAPE: {mape_gru:.2f}%', \n",
    "          fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Price (USD)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# í™•ëŒ€: ì²˜ìŒ 50ì¼\n",
    "plt.subplot(1, 2, 2)\n",
    "n_zoom = 50\n",
    "plt.plot(actual_test_original[:n_zoom], label='Actual', linewidth=2, alpha=0.7, color='black', marker='o', markersize=3)\n",
    "plt.plot(pred_lstm_original[:n_zoom], label='LSTM', linewidth=2, alpha=0.7, marker='s', markersize=3)\n",
    "plt.plot(pred_gru_original[:n_zoom], label='GRU', linewidth=2, alpha=0.7, marker='^', markersize=3)\n",
    "plt.title(f'Zoomed View (First {n_zoom} Days)', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Price (USD)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 ì˜ˆì¸¡ ì˜¤ì°¨ ë¶„ì„\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜¤ì°¨ ë¶„ì„\n",
    "error_lstm = actual_test_original - pred_lstm_original\n",
    "error_gru = actual_test_original - pred_gru_original\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# LSTM ì˜¤ì°¨ ë¶„í¬\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(error_lstm, bins=30, alpha=0.7, color='blue', edgecolor='black')\n",
    "plt.axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "plt.title(f'LSTM Prediction Error\\nMean: ${error_lstm.mean():.2f}', fontsize=11, fontweight='bold')\n",
    "plt.xlabel('Error (Actual - Predicted)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# GRU ì˜¤ì°¨ ë¶„í¬\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(error_gru, bins=30, alpha=0.7, color='green', edgecolor='black')\n",
    "plt.axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "plt.title(f'GRU Prediction Error\\nMean: ${error_gru.mean():.2f}', fontsize=11, fontweight='bold')\n",
    "plt.xlabel('Error (Actual - Predicted)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# ì˜¤ì°¨ ì‹œê³„ì—´\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(error_lstm, label='LSTM Error', alpha=0.7, linewidth=1.5)\n",
    "plt.plot(error_gru, label='GRU Error', alpha=0.7, linewidth=1.5)\n",
    "plt.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "plt.title('Prediction Error Over Time', fontsize=11, fontweight='bold')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Error (USD)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ì˜¤ì°¨ í†µê³„\n",
    "print('\\nì˜¤ì°¨ í†µê³„:')\n",
    "print(f'LSTM - í‰ê·  ì˜¤ì°¨: ${error_lstm.mean():.2f}, í‘œì¤€í¸ì°¨: ${error_lstm.std():.2f}')\n",
    "print(f'GRU  - í‰ê·  ì˜¤ì°¨: ${error_gru.mean():.2f}, í‘œì¤€í¸ì°¨: ${error_gru.std():.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 ì‹¤ì œ ë°ì´í„° í•™ìŠµ ê²°ê³¼ ë° í•œê³„ì  ë¶„ì„\n",
    "\n",
    "### ì£¼ìš” ê²°ê³¼\n",
    "\n",
    "1. **ëª¨ë¸ ì„±ëŠ¥**\n",
    "   - LSTMê³¼ GRU ëª¨ë‘ ì‹¤ì œ ì£¼ê°€ì˜ íŠ¸ë Œë“œë¥¼ ì–´ëŠ ì •ë„ í¬ì°©\n",
    "   - MAPE(í‰ê·  ì ˆëŒ€ ë°±ë¶„ìœ¨ ì˜¤ì°¨)ëŠ” ë³´í†µ 5-15% ë²”ìœ„\n",
    "   - ë‹¨ê¸° ì˜ˆì¸¡(1ì¼)ì€ ë¹„êµì  ì •í™•í•˜ë‚˜ ì¥ê¸° ì˜ˆì¸¡ì€ ë¶€ì •í™•\n",
    "\n",
    "2. **ì˜¤ì°¨ íŒ¨í„´**\n",
    "   - ê¸‰ê²©í•œ ê°€ê²© ë³€ë™(ë‰´ìŠ¤, ì‹¤ì  ë°œí‘œ ë“±)ì—ì„œ í° ì˜¤ì°¨ ë°œìƒ\n",
    "   - ëŒ€ì²´ë¡œ ì˜ˆì¸¡ì´ ì‹¤ì œ ë³€ë™ì„ ê³¼ì†Œí‰ê°€í•˜ëŠ” ê²½í–¥\n",
    "   - ì˜¤ì°¨ê°€ ì •ê·œë¶„í¬ì— ê°€ê¹Œì›€ (ëª¨ë¸ì´ í¸í–¥ë˜ì§€ ì•ŠìŒ)\n",
    "\n",
    "### ë¹„ì •ìƒ ì‹œê³„ì—´ì˜ í•œê³„\n",
    "\n",
    "**ì£¼ê°€ëŠ” ë¹„ì •ìƒ(non-stationary) ì‹œê³„ì—´ì…ë‹ˆë‹¤:**\n",
    "\n",
    "1. **íŠ¸ë Œë“œ**: ì¥ê¸°ì ìœ¼ë¡œ í‰ê· ì´ ë³€í•¨\n",
    "2. **ë³€ë™ì„±**: ë¶„ì‚°ì´ ì‹œê°„ì— ë”°ë¼ ë³€í•¨\n",
    "3. **ì™¸ë¶€ ìš”ì¸**: ë‰´ìŠ¤, ê²½ì œ ì§€í‘œ, ì •ì±… ë“± ëª¨ë¸ì´ ëª¨ë¥´ëŠ” ì •ë³´\n",
    "\n",
    "**ê°œì„  ë°©í–¥:**\n",
    "\n",
    "âœ… **ì°¨ë¶„(Differencing)**: ê°€ê²© ëŒ€ì‹  ë³€í™”ìœ¨ ì‚¬ìš©  \n",
    "âœ… **ì™¸ë¶€ íŠ¹ì„±**: ê±°ë˜ëŸ‰, ê¸°ìˆ ì  ì§€í‘œ, ê°ì„± ë¶„ì„ ì¶”ê°€  \n",
    "âœ… **ì•™ìƒë¸”**: ì—¬ëŸ¬ ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°í•©  \n",
    "âœ… **Attention ë©”ì»¤ë‹ˆì¦˜**: Transformer ê¸°ë°˜ ëª¨ë¸ ì‚¬ìš©  \n",
    "âœ… **í™•ë¥ ì  ì˜ˆì¸¡**: ì  ì˜ˆì¸¡ ëŒ€ì‹  êµ¬ê°„ ì˜ˆì¸¡\n",
    "\n",
    "### êµí›ˆ\n",
    "\n",
    "âš ï¸ **ì‹œê³„ì—´ ì˜ˆì¸¡ì€ ë§¤ìš° ì–´ë ¤ìš´ ë¬¸ì œ**  \n",
    "âš ï¸ **ê³¼ê±° íŒ¨í„´ì´ ë¯¸ë˜ë¥¼ ë³´ì¥í•˜ì§€ ì•ŠìŒ**  \n",
    "âš ï¸ **ëª¨ë¸ì€ ë„êµ¬ì¼ ë¿, ë§¹ì‹ í•˜ì§€ ë§ ê²ƒ**  \n",
    "âœ… **í•˜ì§€ë§Œ RNN/LSTM/GRUëŠ” ìˆœì°¨ ë°ì´í„° ì²˜ë¦¬ì˜ ê¸°ë³¸!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ğŸ“Š ëª¨ë“ˆ A ìš”ì•½ ë° ê²°ë¡ \n",
    "\n",
    "## í•™ìŠµí•œ ë‚´ìš©\n",
    "\n",
    "### ì´ë¡ \n",
    "- âœ… RNNì˜ ê¸°ë³¸ êµ¬ì¡°ì™€ ìˆ˜ì‹ ($h_t = \\tanh(W_h h_{t-1} + W_x x_t + b_h)$)\n",
    "- âœ… ê·¸ë˜ë””ì–¸íŠ¸ ì†Œì‹¤/í­ì£¼ ë¬¸ì œì˜ ì›ì¸ê³¼ í•´ê²° ë°©ë²•\n",
    "- âœ… LSTMì˜ ê²Œì´íŠ¸ ë©”ì»¤ë‹ˆì¦˜ (forget, input, output gates)\n",
    "- âœ… GRUì˜ ë‹¨ìˆœí™”ëœ êµ¬ì¡° (update, reset gates)\n",
    "- âœ… BPTT (Backpropagation Through Time)\n",
    "- âœ… ì†ì‹¤ í•¨ìˆ˜ (MSE, MAE)ì™€ í‰ê°€ ì§€í‘œ (RMSE, MAPE)\n",
    "\n",
    "### ì‹¤ìŠµ\n",
    "- âœ… í•©ì„± ì‹œê³„ì—´ ë°ì´í„° ìƒì„± ë° ì‹¤í—˜\n",
    "- âœ… RNN, LSTM, GRU êµ¬í˜„ ë° ë¹„êµ\n",
    "- âœ… í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (ìœˆë„ìš° í¬ê¸°, íˆë“  í¬ê¸°)\n",
    "- âœ… ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘ì˜ íš¨ê³¼\n",
    "- âœ… ì‹¤ì œ Netflix ì£¼ê°€ ë°ì´í„° ì˜ˆì¸¡\n",
    "- âœ… ëª¨ë¸ í‰ê°€ ë° ì˜¤ì°¨ ë¶„ì„\n",
    "\n",
    "## í•µì‹¬ ì¸ì‚¬ì´íŠ¸\n",
    "\n",
    "1. **LSTM/GRUì˜ í•„ìš”ì„±**\n",
    "   - ê¸°ë³¸ RNNì€ ì¥ê¸° ì˜ì¡´ì„± í•™ìŠµì— í•œê³„\n",
    "   - ê²Œì´íŠ¸ ë©”ì»¤ë‹ˆì¦˜ì€ ì„ íƒì  ì •ë³´ ì „ë‹¬ì„ ê°€ëŠ¥í•˜ê²Œ í•¨\n",
    "   - ì…€ ìƒíƒœì˜ ë§ì…ˆ ì—…ë°ì´íŠ¸ê°€ ê·¸ë˜ë””ì–¸íŠ¸ ì§ì ‘ ì „íŒŒ\n",
    "\n",
    "2. **í•˜ì´í¼íŒŒë¼ë¯¸í„°ì˜ ì¤‘ìš”ì„±**\n",
    "   - ìœˆë„ìš° í¬ê¸°ëŠ” ì˜ˆì¸¡ ì„±ëŠ¥ì— í° ì˜í–¥\n",
    "   - ë„ˆë¬´ í¬ê±°ë‚˜ ì‘ìœ¼ë©´ ì„±ëŠ¥ ì €í•˜\n",
    "   - ì ì ˆí•œ íˆë“  í¬ê¸°ì™€ ë ˆì´ì–´ ìˆ˜ ì„ íƒ í•„ìš”\n",
    "\n",
    "3. **ì‹¤ì œ ë°ì´í„°ì˜ ì–´ë ¤ì›€**\n",
    "   - ì£¼ê°€ì™€ ê°™ì€ ë¹„ì •ìƒ ì‹œê³„ì—´ì€ ì˜ˆì¸¡ì´ ë§¤ìš° ì–´ë ¤ì›€\n",
    "   - ëª¨ë¸ì€ íŒ¨í„´ì„ í•™ìŠµí•˜ì§€ë§Œ ì™¸ë¶€ ìš”ì¸ì„ ì•Œ ìˆ˜ ì—†ìŒ\n",
    "   - ì  ì˜ˆì¸¡ë³´ë‹¤ í™•ë¥ ì  ì˜ˆì¸¡ì´ ë” ì ì ˆí•  ìˆ˜ ìˆìŒ\n",
    "\n",
    "4. **ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘**\n",
    "   - í•™ìŠµ ì•ˆì •ì„±ì— í•„ìˆ˜ì \n",
    "   - íŠ¹íˆ RNN ê³„ì—´ ëª¨ë¸ì—ì„œ ì¤‘ìš”\n",
    "   - ê·¸ë˜ë””ì–¸íŠ¸ í­ì£¼ ë¬¸ì œ ë°©ì§€\n",
    "\n",
    "## ì‹¤ë¬´ ì ìš© ê°€ì´ë“œ\n",
    "\n",
    "### ì–¸ì œ RNN/LSTM/GRUë¥¼ ì‚¬ìš©í• ê¹Œ?\n",
    "\n",
    "**ì‚¬ìš© ê¶Œì¥:**\n",
    "- ìˆœì°¨ ë°ì´í„° (ì‹œê³„ì—´, ìì—°ì–´, ìŒì„± ë“±)\n",
    "- ì´ì „ ì •ë³´ê°€ í˜„ì¬ ì˜ˆì¸¡ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ê²½ìš°\n",
    "- ê°€ë³€ ê¸¸ì´ ì‹œí€€ìŠ¤ ì²˜ë¦¬ê°€ í•„ìš”í•œ ê²½ìš°\n",
    "\n",
    "**ì£¼ì˜ì‚¬í•­:**\n",
    "- ë§¤ìš° ê¸´ ì‹œí€€ìŠ¤(>1000)ëŠ” Transformer ê³ ë ¤\n",
    "- ë³‘ë ¬í™”ê°€ ì–´ë ¤ì›Œ í•™ìŠµ ì†ë„ê°€ ëŠë¦¼\n",
    "- ì ì ˆí•œ ì •ê·œí™”ì™€ í´ë¦¬í•‘ í•„ìˆ˜\n",
    "\n",
    "### ëª¨ë¸ ì„ íƒ ê°€ì´ë“œ\n",
    "\n",
    "- **RNN**: ê°„ë‹¨í•œ ìˆœì°¨ ë°ì´í„°, ì§§ì€ ì‹œí€€ìŠ¤\n",
    "- **LSTM**: ì¥ê¸° ì˜ì¡´ì„±ì´ ì¤‘ìš”í•œ ê²½ìš°, ê¸´ ì‹œí€€ìŠ¤\n",
    "- **GRU**: LSTMê³¼ ìœ ì‚¬í•˜ë‚˜ ë” ë¹ ë¥¸ í•™ìŠµ, ì¤‘ê°„ ê¸¸ì´ ì‹œí€€ìŠ¤\n",
    "\n",
    "## ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "ì´ì œ **ëª¨ë“ˆ B: U-Net ê¸°ë°˜ ì´ë¯¸ì§€ ë¶„í• **ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.\n",
    "\n",
    "ì‹œê³„ì—´ ì˜ˆì¸¡ì—ì„œ ì´ë¯¸ì§€ ì²˜ë¦¬ë¡œ ë„ë©”ì¸ì´ ë°”ë€Œì§€ë§Œ,\n",
    "ë”¥ëŸ¬ë‹ì˜ í•µì‹¬ ì›ë¦¬(ìˆœì „íŒŒ, ì—­ì „íŒŒ, ìµœì í™”)ëŠ” ë™ì¼í•©ë‹ˆë‹¤!\n",
    "\n",
    "**ì£¼ìš” ì°¨ì´ì :**\n",
    "- **ì…ë ¥**: 1D ì‹œí€€ìŠ¤ â†’ 2D ì´ë¯¸ì§€\n",
    "- **ì•„í‚¤í…ì²˜**: RNN â†’ CNN (U-Net)\n",
    "- **ì‘ì—…**: íšŒê·€ (ì˜ˆì¸¡) â†’ ë¶„ë¥˜ (ì„¸ê·¸ë¨¼í…Œì´ì…˜)\n",
    "- **ì¶œë ¥**: ë‹¨ì¼ ê°’ â†’ í”½ì…€ë³„ í´ë˜ìŠ¤\n",
    "\n",
    "---\n",
    "\n",
    "**ëª¨ë“ˆ A í•™ìŠµì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤! ğŸ‰**\n",
    "\n",
    "ë‹¤ìŒ ëª¨ë“ˆì—ì„œëŠ” ì´ë¯¸ì§€ ë¶„í• ì˜ ì„¸ê³„ë¡œ ë“¤ì–´ê°‘ë‹ˆë‹¤.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
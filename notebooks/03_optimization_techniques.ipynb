{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 고급 최적화 및 정규화 기법 - 실습 노트북 (고급 단계)\n",
    "\n",
    "이 노트북은 고급 최적화 알고리즘과 정규화 기법을 구현하고 비교합니다.\n",
    "\n",
    "## 목차\n",
    "1. 고급 최적화 알고리즘 (Adam, RMSprop, AdaGrad)\n",
    "2. 정규화 기법 (L1, L2, Dropout)\n",
    "3. 배치 정규화 (Batch Normalization)\n",
    "4. 종합 비교 및 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "# 시드 설정\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"NumPy version:\", np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 고급 최적화 알고리즘\n",
    "\n",
    "### 1.1 Adam Optimizer\n",
    "\n",
    "**수식:**\n",
    "$$m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) g_t$$\n",
    "$$v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2$$\n",
    "$$\\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}$$\n",
    "$$\\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}$$\n",
    "$$\\theta_t = \\theta_{t-1} - \\alpha \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}$$\n",
    "\n",
    "**기호 설명:**\n",
    "- $m_t$: 1차 모멘트 (평균)\n",
    "- $v_t$: 2차 모멘트 (비중심 분산)\n",
    "- $\\beta_1, \\beta_2$: 감쇠율 (일반적으로 0.9, 0.999)\n",
    "- $\\epsilon$: 수치 안정성 상수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamOptimizer:\n",
    "    \"\"\"Adam 최적화 알고리즘\"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "        self.lr = learning_rate\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.m = {}  # 1차 모멘트\n",
    "        self.v = {}  # 2차 모멘트\n",
    "        self.t = 0   # 시간 단계\n",
    "    \n",
    "    def update(self, params, grads):\n",
    "        \"\"\"파라미터 업데이트\"\"\"\n",
    "        self.t += 1\n",
    "        \n",
    "        for key in params.keys():\n",
    "            # 초기화\n",
    "            if key not in self.m:\n",
    "                self.m[key] = np.zeros_like(params[key])\n",
    "                self.v[key] = np.zeros_like(params[key])\n",
    "            \n",
    "            # 모멘트 업데이트\n",
    "            self.m[key] = self.beta1 * self.m[key] + (1 - self.beta1) * grads[key]\n",
    "            self.v[key] = self.beta2 * self.v[key] + (1 - self.beta2) * (grads[key] ** 2)\n",
    "            \n",
    "            # 편향 보정\n",
    "            m_hat = self.m[key] / (1 - self.beta1 ** self.t)\n",
    "            v_hat = self.v[key] / (1 - self.beta2 ** self.t)\n",
    "            \n",
    "            # 파라미터 업데이트\n",
    "            params[key] -= self.lr * m_hat / (np.sqrt(v_hat) + self.epsilon)\n",
    "        \n",
    "        return params\n",
    "\n",
    "class RMSpropOptimizer:\n",
    "    \"\"\"RMSprop 최적화 알고리즘\"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate=0.001, beta=0.9, epsilon=1e-8):\n",
    "        self.lr = learning_rate\n",
    "        self.beta = beta\n",
    "        self.epsilon = epsilon\n",
    "        self.v = {}  # 2차 모멘트\n",
    "    \n",
    "    def update(self, params, grads):\n",
    "        \"\"\"파라미터 업데이트\"\"\"\n",
    "        for key in params.keys():\n",
    "            if key not in self.v:\n",
    "                self.v[key] = np.zeros_like(params[key])\n",
    "            \n",
    "            self.v[key] = self.beta * self.v[key] + (1 - self.beta) * (grads[key] ** 2)\n",
    "            params[key] -= self.lr * grads[key] / (np.sqrt(self.v[key]) + self.epsilon)\n",
    "        \n",
    "        return params\n",
    "\n",
    "class SGDOptimizer:\n",
    "    \"\"\"기본 SGD (비교용)\"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate=0.01):\n",
    "        self.lr = learning_rate\n",
    "    \n",
    "    def update(self, params, grads):\n",
    "        \"\"\"파라미터 업데이트\"\"\"\n",
    "        for key in params.keys():\n",
    "            params[key] -= self.lr * grads[key]\n",
    "        return params\n",
    "\n",
    "print(\"최적화 알고리즘 클래스 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 최적화 알고리즘 비교\n",
    "\n",
    "간단한 2D 함수로 각 최적화 알고리즘의 동작을 시각화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화할 함수: Rosenbrock function (어려운 최적화 문제)\n",
    "def rosenbrock(x, y, a=1, b=100):\n",
    "    \"\"\"Rosenbrock 함수\"\"\"\n",
    "    return (a - x)**2 + b * (y - x**2)**2\n",
    "\n",
    "def rosenbrock_grad(x, y, a=1, b=100):\n",
    "    \"\"\"Rosenbrock 함수의 그래디언트\"\"\"\n",
    "    dx = -2 * (a - x) - 4 * b * x * (y - x**2)\n",
    "    dy = 2 * b * (y - x**2)\n",
    "    return np.array([dx, dy])\n",
    "\n",
    "def optimize_function(optimizer, start_pos, num_iterations=100):\n",
    "    \"\"\"최적화 실행 및 경로 기록\"\"\"\n",
    "    params = {'theta': np.array(start_pos, dtype=float)}\n",
    "    path = [params['theta'].copy()]\n",
    "    \n",
    "    for _ in range(num_iterations):\n",
    "        x, y = params['theta']\n",
    "        grad = rosenbrock_grad(x, y)\n",
    "        grads = {'theta': grad}\n",
    "        \n",
    "        params = optimizer.update(params, grads)\n",
    "        path.append(params['theta'].copy())\n",
    "    \n",
    "    return np.array(path)\n",
    "\n",
    "# 시작점\n",
    "start = [-1.5, 2.5]\n",
    "\n",
    "# 각 최적화 알고리즘 실행\n",
    "path_sgd = optimize_function(SGDOptimizer(learning_rate=0.001), start)\n",
    "path_rmsprop = optimize_function(RMSpropOptimizer(learning_rate=0.01), start)\n",
    "path_adam = optimize_function(AdamOptimizer(learning_rate=0.01), start)\n",
    "\n",
    "# 시각화\n",
    "x = np.linspace(-2, 2, 100)\n",
    "y = np.linspace(-1, 3, 100)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = rosenbrock(X, Y)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# 등고선 플롯\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.contour(X, Y, Z, levels=np.logspace(-1, 3, 20), cmap='viridis', alpha=0.6)\n",
    "plt.plot(path_sgd[:, 0], path_sgd[:, 1], 'o-', label='SGD', markersize=3, linewidth=1.5)\n",
    "plt.plot(path_rmsprop[:, 0], path_rmsprop[:, 1], 's-', label='RMSprop', markersize=3, linewidth=1.5)\n",
    "plt.plot(path_adam[:, 0], path_adam[:, 1], '^-', label='Adam', markersize=3, linewidth=1.5)\n",
    "plt.plot(1, 1, 'r*', markersize=15, label='Optimum')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Optimization Paths on Rosenbrock Function')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 손실 수렴 비교\n",
    "plt.subplot(1, 2, 2)\n",
    "loss_sgd = [rosenbrock(p[0], p[1]) for p in path_sgd]\n",
    "loss_rmsprop = [rosenbrock(p[0], p[1]) for p in path_rmsprop]\n",
    "loss_adam = [rosenbrock(p[0], p[1]) for p in path_adam]\n",
    "\n",
    "plt.semilogy(loss_sgd, label='SGD', linewidth=2)\n",
    "plt.semilogy(loss_rmsprop, label='RMSprop', linewidth=2)\n",
    "plt.semilogy(loss_adam, label='Adam', linewidth=2)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss (log scale)')\n",
    "plt.title('Loss Convergence')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n최종 위치:\")\n",
    "print(f\"  SGD:     {path_sgd[-1]}\")\n",
    "print(f\"  RMSprop: {path_rmsprop[-1]}\")\n",
    "print(f\"  Adam:    {path_adam[-1]}\")\n",
    "print(f\"  최적값:  [1.0, 1.0]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 정규화 기법\n",
    "\n",
    "### 2.1 L2 정규화 (Weight Decay)\n",
    "\n",
    "**수식:**\n",
    "$$J = L + \\frac{\\lambda}{2} \\sum_i w_i^2$$\n",
    "$$w := (1 - \\alpha\\lambda)w - \\alpha\\frac{\\partial L}{\\partial w}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 활성화 및 손실 함수\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-np.clip(z, -500, 500)))\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def relu_derivative(z):\n",
    "    return np.where(z > 0, 1, 0)\n",
    "\n",
    "def binary_cross_entropy(y_true, y_pred):\n",
    "    epsilon = 1e-10\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "def forward_pass(X, W1, b1, W2, b2, dropout_rate=0.0, training=True):\n",
    "    \"\"\"순방향 전파 (Dropout 포함)\"\"\"\n",
    "    # 1층\n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = relu(Z1)\n",
    "    \n",
    "    # Dropout\n",
    "    if training and dropout_rate > 0:\n",
    "        D1 = (np.random.rand(*A1.shape) > dropout_rate).astype(float)\n",
    "        A1 = A1 * D1 / (1 - dropout_rate)  # Inverted dropout\n",
    "    else:\n",
    "        D1 = np.ones_like(A1)\n",
    "    \n",
    "    # 2층\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    \n",
    "    cache = {'X': X, 'Z1': Z1, 'A1': A1, 'D1': D1, 'Z2': Z2, 'A2': A2}\n",
    "    return A2, cache\n",
    "\n",
    "def backward_pass(Y, cache, W1, W2, l2_lambda=0.0, dropout_rate=0.0):\n",
    "    \"\"\"역전파 (L2 정규화 포함)\"\"\"\n",
    "    m = Y.shape[1]\n",
    "    \n",
    "    # 출력층\n",
    "    dZ2 = cache['A2'] - Y\n",
    "    dW2 = (1/m) * np.dot(dZ2, cache['A1'].T) + (l2_lambda/m) * W2  # L2 정규화\n",
    "    db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    \n",
    "    # 은닉층\n",
    "    dA1 = np.dot(W2.T, dZ2)\n",
    "    if dropout_rate > 0:\n",
    "        dA1 = dA1 * cache['D1'] / (1 - dropout_rate)  # Dropout 역전파\n",
    "    dZ1 = dA1 * relu_derivative(cache['Z1'])\n",
    "    dW1 = (1/m) * np.dot(dZ1, cache['X'].T) + (l2_lambda/m) * W1  # L2 정규화\n",
    "    db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "    \n",
    "    return {'dW1': dW1, 'db1': db1, 'dW2': dW2, 'db2': db2}\n",
    "\n",
    "print(\"정규화된 순방향/역방향 전파 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 정규화 효과 비교\n",
    "\n",
    "과적합이 발생하기 쉬운 작은 데이터셋으로 정규화 효과를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 작은 데이터셋 생성 (과적합 유도)\n",
    "np.random.seed(42)\n",
    "n_samples = 40  # 작은 데이터셋\n",
    "\n",
    "X0 = np.random.randn(2, n_samples//2) * 0.5 - 1\n",
    "Y0 = np.zeros((1, n_samples//2))\n",
    "\n",
    "X1 = np.random.randn(2, n_samples//2) * 0.5 + 1\n",
    "Y1 = np.ones((1, n_samples//2))\n",
    "\n",
    "X_data = np.hstack([X0, X1])\n",
    "Y_data = np.hstack([Y0, Y1])\n",
    "\n",
    "# 데이터 섞기\n",
    "shuffle_idx = np.random.permutation(X_data.shape[1])\n",
    "X_data = X_data[:, shuffle_idx]\n",
    "Y_data = Y_data[:, shuffle_idx]\n",
    "\n",
    "print(f\"데이터셋 크기: {X_data.shape}\")\n",
    "\n",
    "def train_with_regularization(X, Y, n_hidden=20, learning_rate=0.1, \n",
    "                             num_iterations=2000, l2_lambda=0.0, dropout_rate=0.0):\n",
    "    \"\"\"정규화를 포함한 학습\"\"\"\n",
    "    np.random.seed(42)\n",
    "    n_features = X.shape[0]\n",
    "    \n",
    "    # 파라미터 초기화\n",
    "    W1 = np.random.randn(n_hidden, n_features) * 0.1\n",
    "    b1 = np.zeros((n_hidden, 1))\n",
    "    W2 = np.random.randn(1, n_hidden) * 0.1\n",
    "    b2 = np.zeros((1, 1))\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        # 순방향 전파\n",
    "        A2, cache = forward_pass(X, W1, b1, W2, b2, dropout_rate, training=True)\n",
    "        \n",
    "        # 손실 계산 (L2 정규화 포함)\n",
    "        loss = binary_cross_entropy(Y, A2)\n",
    "        if l2_lambda > 0:\n",
    "            l2_reg = (l2_lambda / (2 * X.shape[1])) * (np.sum(W1**2) + np.sum(W2**2))\n",
    "            loss += l2_reg\n",
    "        losses.append(loss)\n",
    "        \n",
    "        # 역전파\n",
    "        grads = backward_pass(Y, cache, W1, W2, l2_lambda, dropout_rate)\n",
    "        \n",
    "        # 파라미터 업데이트\n",
    "        W1 -= learning_rate * grads['dW1']\n",
    "        b1 -= learning_rate * grads['db1']\n",
    "        W2 -= learning_rate * grads['dW2']\n",
    "        b2 -= learning_rate * grads['db2']\n",
    "    \n",
    "    return {'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}, losses\n",
    "\n",
    "# 다양한 설정으로 학습\n",
    "print(\"\\n학습 중...\")\n",
    "params_none, losses_none = train_with_regularization(X_data, Y_data, l2_lambda=0.0)\n",
    "params_l2, losses_l2 = train_with_regularization(X_data, Y_data, l2_lambda=0.1)\n",
    "params_dropout, losses_dropout = train_with_regularization(X_data, Y_data, dropout_rate=0.3)\n",
    "print(\"학습 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 곡선 비교\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(losses_none, label='No Regularization', linewidth=2)\n",
    "plt.plot(losses_l2, label='L2 Regularization (λ=0.1)', linewidth=2)\n",
    "plt.plot(losses_dropout, label='Dropout (rate=0.3)', linewidth=2)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss with Different Regularizations')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 가중치 크기 비교\n",
    "plt.subplot(1, 2, 2)\n",
    "w_norms = [\n",
    "    np.linalg.norm(params_none['W1']),\n",
    "    np.linalg.norm(params_l2['W1']),\n",
    "    np.linalg.norm(params_dropout['W1'])\n",
    "]\n",
    "labels = ['No Reg', 'L2', 'Dropout']\n",
    "plt.bar(labels, w_norms, color=['blue', 'green', 'orange'])\n",
    "plt.ylabel('Weight Norm (L2)')\n",
    "plt.title('Weight Magnitudes')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n최종 손실:\")\n",
    "print(f\"  정규화 없음: {losses_none[-1]:.4f}\")\n",
    "print(f\"  L2 정규화:   {losses_l2[-1]:.4f}\")\n",
    "print(f\"  Dropout:     {losses_dropout[-1]:.4f}\")\n",
    "print(f\"\\n가중치 크기:\")\n",
    "print(f\"  정규화 없음: {w_norms[0]:.4f}\")\n",
    "print(f\"  L2 정규화:   {w_norms[1]:.4f}\")\n",
    "print(f\"  Dropout:     {w_norms[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 배치 정규화 (Batch Normalization)\n",
    "\n",
    "### 수식\n",
    "$$\\mu_B = \\frac{1}{m} \\sum_{i=1}^m x_i$$\n",
    "$$\\sigma_B^2 = \\frac{1}{m} \\sum_{i=1}^m (x_i - \\mu_B)^2$$\n",
    "$$\\hat{x}_i = \\frac{x_i - \\mu_B}{\\sqrt{\\sigma_B^2 + \\epsilon}}$$\n",
    "$$y_i = \\gamma \\hat{x}_i + \\beta$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_normalization_forward(x, gamma, beta, epsilon=1e-5):\n",
    "    \"\"\"\n",
    "    배치 정규화 순방향 전파\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x : (d, m) 입력\n",
    "    gamma : (d, 1) 스케일 파라미터\n",
    "    beta : (d, 1) 이동 파라미터\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    out : 정규화된 출력\n",
    "    cache : 역전파를 위한 캐시\n",
    "    \"\"\"\n",
    "    # 배치 통계량\n",
    "    mu = np.mean(x, axis=1, keepdims=True)\n",
    "    var = np.var(x, axis=1, keepdims=True)\n",
    "    \n",
    "    # 정규화\n",
    "    x_norm = (x - mu) / np.sqrt(var + epsilon)\n",
    "    \n",
    "    # 스케일 및 이동\n",
    "    out = gamma * x_norm + beta\n",
    "    \n",
    "    cache = (x, x_norm, mu, var, gamma, beta, epsilon)\n",
    "    return out, cache\n",
    "\n",
    "def batch_normalization_backward(dout, cache):\n",
    "    \"\"\"\n",
    "    배치 정규화 역전파\n",
    "    \"\"\"\n",
    "    x, x_norm, mu, var, gamma, beta, epsilon = cache\n",
    "    m = x.shape[1]\n",
    "    \n",
    "    # 그래디언트 계산\n",
    "    dgamma = np.sum(dout * x_norm, axis=1, keepdims=True)\n",
    "    dbeta = np.sum(dout, axis=1, keepdims=True)\n",
    "    \n",
    "    dx_norm = dout * gamma\n",
    "    dvar = np.sum(dx_norm * (x - mu) * -0.5 * (var + epsilon)**(-1.5), axis=1, keepdims=True)\n",
    "    dmu = np.sum(dx_norm * -1 / np.sqrt(var + epsilon), axis=1, keepdims=True) + \\\n",
    "          dvar * np.sum(-2 * (x - mu), axis=1, keepdims=True) / m\n",
    "    \n",
    "    dx = dx_norm / np.sqrt(var + epsilon) + dvar * 2 * (x - mu) / m + dmu / m\n",
    "    \n",
    "    return dx, dgamma, dbeta\n",
    "\n",
    "# 배치 정규화 예제\n",
    "print(\"=\" * 70)\n",
    "print(\"배치 정규화 수치 예제\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 입력 데이터\n",
    "x = np.array([[2.0, 3.0, 4.0, 5.0],\n",
    "              [1.0, 2.0, 3.0, 4.0]])\n",
    "gamma = np.ones((2, 1))\n",
    "beta = np.zeros((2, 1))\n",
    "\n",
    "print(f\"입력 x:\\n{x}\")\n",
    "print(f\"\\n입력 통계:\")\n",
    "print(f\"  평균: {np.mean(x, axis=1)}\")\n",
    "print(f\"  표준편차: {np.std(x, axis=1)}\")\n",
    "\n",
    "# 배치 정규화 적용\n",
    "out, cache = batch_normalization_forward(x, gamma, beta)\n",
    "\n",
    "print(f\"\\n정규화된 출력:\\n{out}\")\n",
    "print(f\"\\n출력 통계:\")\n",
    "print(f\"  평균: {np.mean(out, axis=1)}\")\n",
    "print(f\"  표준편차: {np.std(out, axis=1)}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 종합 비교 및 분석\n",
    "\n",
    "모든 기법을 종합하여 비교합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 요약 시각화\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. 최적화 알고리즘 수렴 속도\n",
    "axes[0, 0].semilogy(loss_sgd, label='SGD', linewidth=2)\n",
    "axes[0, 0].semilogy(loss_rmsprop, label='RMSprop', linewidth=2)\n",
    "axes[0, 0].semilogy(loss_adam, label='Adam', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Iteration')\n",
    "axes[0, 0].set_ylabel('Loss (log scale)')\n",
    "axes[0, 0].set_title('Optimizer Comparison')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. 정규화 효과\n",
    "axes[0, 1].plot(losses_none, label='No Regularization', linewidth=2)\n",
    "axes[0, 1].plot(losses_l2, label='L2', linewidth=2)\n",
    "axes[0, 1].plot(losses_dropout, label='Dropout', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Iteration')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].set_title('Regularization Comparison')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. 가중치 분포 (정규화 전)\n",
    "axes[1, 0].hist(params_none['W1'].flatten(), bins=30, alpha=0.7, label='No Reg')\n",
    "axes[1, 0].hist(params_l2['W1'].flatten(), bins=30, alpha=0.7, label='L2')\n",
    "axes[1, 0].set_xlabel('Weight Value')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].set_title('Weight Distribution')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. 배치 정규화 효과\n",
    "before_bn = x\n",
    "after_bn = out\n",
    "axes[1, 1].boxplot([before_bn[0], after_bn[0], before_bn[1], after_bn[1]], \n",
    "                    labels=['Before (dim 1)', 'After (dim 1)', 'Before (dim 2)', 'After (dim 2)'])\n",
    "axes[1, 1].set_ylabel('Value')\n",
    "axes[1, 1].set_title('Batch Normalization Effect')\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"종합 분석 결과\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n1. 최적화 알고리즘:\")\n",
    "print(\"   - Adam이 가장 빠르게 수렴\")\n",
    "print(\"   - RMSprop도 SGD보다 훨씬 빠름\")\n",
    "print(\"   - SGD는 느리지만 때로는 더 나은 최종 성능\")\n",
    "print(\"\\n2. 정규화:\")\n",
    "print(\"   - L2 정규화가 가중치 크기를 효과적으로 제한\")\n",
    "print(\"   - Dropout도 과적합 방지에 효과적\")\n",
    "print(\"   - 작은 데이터셋에서 특히 중요\")\n",
    "print(\"\\n3. 배치 정규화:\")\n",
    "print(\"   - 입력을 정규화하여 학습 안정화\")\n",
    "print(\"   - 평균 0, 분산 1로 변환\")\n",
    "print(\"   - 더 높은 학습률 사용 가능\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 요약\n",
    "\n",
    "이 노트북에서 다룬 내용:\n",
    "\n",
    "1. **고급 최적화 알고리즘**\n",
    "   - Adam: 모멘텀과 RMSprop의 결합\n",
    "   - RMSprop: 적응적 학습률\n",
    "   - 각 알고리즘의 수렴 특성 비교\n",
    "\n",
    "2. **정규화 기법**\n",
    "   - L2 정규화: 가중치 크기 제한\n",
    "   - Dropout: 랜덤하게 뉴런 비활성화\n",
    "   - 과적합 방지 효과 검증\n",
    "\n",
    "3. **배치 정규화**\n",
    "   - 미니배치 단위로 정규화\n",
    "   - 학습 안정화 및 가속화\n",
    "   - 순방향/역방향 전파 구현\n",
    "\n",
    "### 실전 권장사항\n",
    "\n",
    "- **최적화**: Adam을 기본으로 사용, 필요시 SGD로 fine-tuning\n",
    "- **정규화**: L2와 Dropout을 함께 사용\n",
    "- **배치 정규화**: 깊은 네트워크에서 필수적\n",
    "- **학습률**: 배치 정규화 사용시 더 높은 학습률 가능\n",
    "\n",
    "### 다음 단계\n",
    "\n",
    "이제 실제 데이터셋(MNIST, CIFAR-10 등)에 이러한 기법들을 적용하여 실전 경험을 쌓으세요!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

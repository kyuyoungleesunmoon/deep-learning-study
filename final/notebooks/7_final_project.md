# 7êµì‹œ: ì¢…í•© í”„ë¡œì íŠ¸ - ì˜¨ë¼ì¸ ì‡¼í•‘ëª° ë°ì´í„° ë¶„ì„

> **í•™ìŠµ ì‹œê°„**: 1ì‹œê°„  
> **ë‚œì´ë„**: â­â­â­â­â­  
> **ëª©í‘œ**: ì§€ê¸ˆê¹Œì§€ ë°°ìš´ ëª¨ë“  ê¸°ìˆ ì„ í™œìš©í•˜ì—¬ ì‹¤ë¬´ ë°ì´í„° ë¶„ì„ í”„ë¡œì íŠ¸ë¥¼ ì™„ì„±í•©ë‹ˆë‹¤.

---

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”

### ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì œ
**ì˜¨ë¼ì¸ ì‡¼í•‘ëª° ê²½ì˜ì§„ì´ ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ ì›í•©ë‹ˆë‹¤:**

1. ì–´ë–¤ ìƒí’ˆ ì¹´í…Œê³ ë¦¬ê°€ ê°€ì¥ ìˆ˜ìµì„±ì´ ë†’ì€ê°€?
2. ì–´ë–¤ ê³ ê° ê·¸ë£¹ì„ íƒ€ê²ŸíŒ…í•´ì•¼ í•˜ëŠ”ê°€?
3. ë§¤ì¶œì„ ì¦ëŒ€ì‹œí‚¤ê¸° ìœ„í•œ ì „ëµì€ ë¬´ì—‡ì¸ê°€?
4. ë‚´ë…„ ë§¤ì¶œì„ ì˜ˆì¸¡í•  ìˆ˜ ìˆëŠ”ê°€?

### í”„ë¡œì íŠ¸ ëª©í‘œ
- ğŸ“Š ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ
- ğŸ’¡ ì‹¤í–‰ ê°€ëŠ¥í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ì „ëµ ì œì•ˆ
- ğŸ”® ë§¤ì¶œ ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶•
- ğŸ“ ê²½ì˜ì§„ ë³´ê³ ì„œ ì‘ì„±

---

## 1ë‹¨ê³„: í”„ë¡œì íŠ¸ ì„¤ì •

```python
# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import warnings
warnings.filterwarnings('ignore')

# ìŠ¤íƒ€ì¼ ì„¤ì •
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

print("="*60)
print("ğŸš€ ì˜¨ë¼ì¸ ì‡¼í•‘ëª° ë°ì´í„° ë¶„ì„ í”„ë¡œì íŠ¸")
print("="*60)
```

---

## 2ë‹¨ê³„: ë°ì´í„° ìˆ˜ì§‘ ë° í†µí•©

```python
# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
print("\nğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...")
df_sales = pd.read_csv('../data/sales_data.csv')
df_customer = pd.read_csv('../data/customer_data.csv')
df_product = pd.read_csv('../data/product_data.csv')

print(f"âœ… íŒë§¤ ë°ì´í„°: {df_sales.shape}")
print(f"âœ… ê³ ê° ë°ì´í„°: {df_customer.shape}")
print(f"âœ… ìƒí’ˆ ë°ì´í„°: {df_product.shape}")

# ë°ì´í„° í†µí•©
print("\nğŸ”— ë°ì´í„° ë³‘í•© ì¤‘...")
# ê³ ê° ì •ë³´ ì¶”ê°€
df = pd.merge(df_sales, 
              df_customer[['customer_id', 'customer_name', 'member_type', 'occupation']], 
              on='customer_id', how='left')

print(f"í†µí•© ë°ì´í„°: {df.shape}")
```

---

## 3ë‹¨ê³„: ë°ì´í„° íƒìƒ‰ (EDA)

### 3.1 ê¸°ë³¸ í†µê³„

```python
print("\n" + "="*60)
print("ğŸ“Š ê¸°ë³¸ í†µê³„ ë¶„ì„")
print("="*60)

# ì „ì²´ ë§¤ì¶œ í†µê³„
total_revenue = df['final_amount'].sum()
total_orders = len(df)
avg_order_value = df['final_amount'].mean()
unique_customers = df['customer_id'].nunique()

print(f"\nğŸ’° ì´ ë§¤ì¶œ: {total_revenue:,.0f}ì›")
print(f"ğŸ“¦ ì´ ì£¼ë¬¸ ê±´ìˆ˜: {total_orders:,}ê±´")
print(f"ğŸ’³ í‰ê·  ì£¼ë¬¸ ê¸ˆì•¡: {avg_order_value:,.0f}ì›")
print(f"ğŸ‘¥ ê³ ìœ  ê³ ê° ìˆ˜: {unique_customers:,}ëª…")
print(f"ğŸ“ˆ ê³ ê°ë‹¹ í‰ê·  ì£¼ë¬¸: {total_orders/unique_customers:.1f}ê±´")
```

### 3.2 ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„

```python
print("\n" + "="*60)
print("ğŸ·ï¸ ìƒí’ˆ ì¹´í…Œê³ ë¦¬ ë¶„ì„")
print("="*60)

category_analysis = df.groupby('product_category').agg({
    'final_amount': ['sum', 'mean', 'count'],
    'quantity': 'sum',
    'discount_rate': 'mean'
}).round(0)

category_analysis.columns = ['ì´ë§¤ì¶œ', 'í‰ê· ë§¤ì¶œ', 'ì£¼ë¬¸ê±´ìˆ˜', 'íŒë§¤ìˆ˜ëŸ‰', 'í‰ê· í• ì¸ìœ¨']
category_analysis = category_analysis.sort_values('ì´ë§¤ì¶œ', ascending=False)
category_analysis['ë§¤ì¶œë¹„ì¤‘'] = (category_analysis['ì´ë§¤ì¶œ'] / category_analysis['ì´ë§¤ì¶œ'].sum() * 100).round(1)

print(category_analysis)

# ì‹œê°í™”
fig, axes = plt.subplots(1, 2, figsize=(15, 5))

# ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ
category_analysis['ì´ë§¤ì¶œ'].plot(kind='barh', ax=axes[0], color='steelblue')
axes[0].set_title('Total Sales by Category', fontsize=14, fontweight='bold')
axes[0].set_xlabel('Total Sales (KRW)')

# ë§¤ì¶œ ë¹„ì¤‘ íŒŒì´ ì°¨íŠ¸
axes[1].pie(category_analysis['ë§¤ì¶œë¹„ì¤‘'], labels=category_analysis.index, 
            autopct='%1.1f%%', startangle=90)
axes[1].set_title('Sales Share by Category', fontsize=14, fontweight='bold')

plt.tight_layout()
plt.savefig('../output/figures/category_analysis.png', dpi=300)
plt.show()
```

### 3.3 ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„

```python
print("\n" + "="*60)
print("ğŸ‘¥ ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„")
print("="*60)

# íšŒì› ë“±ê¸‰ë³„ ë¶„ì„
member_analysis = df.groupby('member_type').agg({
    'final_amount': ['sum', 'mean', 'count'],
    'customer_id': 'nunique'
})
member_analysis.columns = ['ì´ë§¤ì¶œ', 'í‰ê· ì£¼ë¬¸ê¸ˆì•¡', 'ì£¼ë¬¸ê±´ìˆ˜', 'ê³ ê°ìˆ˜']
member_analysis['ê³ ê°ë‹¹ì£¼ë¬¸'] = (member_analysis['ì£¼ë¬¸ê±´ìˆ˜'] / member_analysis['ê³ ê°ìˆ˜']).round(1)
member_analysis = member_analysis.sort_values('ì´ë§¤ì¶œ', ascending=False)

print(member_analysis)

# VIP ê³ ê° ë¶„ì„
vip_customers = df[df['member_type'] == 'VIP']
print(f"\nğŸŒŸ VIP ê³ ê°:")
print(f"  - ê³ ê° ìˆ˜: {vip_customers['customer_id'].nunique()}ëª…")
print(f"  - ì´ ë§¤ì¶œ: {vip_customers['final_amount'].sum():,.0f}ì›")
print(f"  - ì „ì²´ ë§¤ì¶œ ëŒ€ë¹„: {vip_customers['final_amount'].sum()/total_revenue*100:.1f}%")
```

### 3.4 ì‹œê°„ë³„ ë§¤ì¶œ ì¶”ì´

```python
print("\n" + "="*60)
print("ğŸ“… ì‹œê°„ë³„ ë§¤ì¶œ ì¶”ì´")
print("="*60)

# ë‚ ì§œ ë³€í™˜
df['order_date'] = pd.to_datetime(df['order_date'])
df['year_month'] = df['order_date'].dt.to_period('M')
df['weekday'] = df['order_date'].dt.day_name()

# ì›”ë³„ ë§¤ì¶œ
monthly_sales = df.groupby('year_month')['final_amount'].sum().reset_index()
monthly_sales['year_month'] = monthly_sales['year_month'].astype(str)

print(monthly_sales.tail(12))

# ì‹œê°í™”
plt.figure(figsize=(14, 6))
plt.plot(monthly_sales['year_month'], monthly_sales['final_amount'], 
         marker='o', linewidth=2, markersize=8)
plt.title('Monthly Sales Trend', fontsize=16, fontweight='bold')
plt.xlabel('Month', fontsize=12)
plt.ylabel('Sales (KRW)', fontsize=12)
plt.xticks(rotation=45)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('../output/figures/monthly_trend.png', dpi=300)
plt.show()

# ìš”ì¼ë³„ ë§¤ì¶œ
weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
weekday_sales = df.groupby('weekday')['final_amount'].agg(['sum', 'mean']).reindex(weekday_order)
print("\nìš”ì¼ë³„ í‰ê·  ë§¤ì¶œ:")
print(weekday_sales['mean'].round(0))
```

---

## 4ë‹¨ê³„: ë°ì´í„° ì •ì œ

```python
print("\n" + "="*60)
print("ğŸ§¹ ë°ì´í„° ì •ì œ")
print("="*60)

# ì •ì œ ì „ ìƒíƒœ
print(f"ì›ë³¸ ë°ì´í„°: {len(df)}ê±´")
print(f"ê²°ì¸¡ì¹˜:\n{df.isnull().sum()}")

# ê²°ì¸¡ì¹˜ ì²˜ë¦¬
df['customer_age'].fillna(df['customer_age'].mean(), inplace=True)
df['region'].fillna('Unknown', inplace=True)

# ì¤‘ë³µ ì œê±°
df = df.drop_duplicates(subset=['order_id'])

# ì´ìƒì¹˜ ì œê±° (ë§¤ìš° ë¹„ì •ìƒì ì¸ ê°’)
Q1 = df['final_amount'].quantile(0.25)
Q3 = df['final_amount'].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 3 * IQR
upper_bound = Q3 + 3 * IQR

df_clean = df[(df['final_amount'] >= lower_bound) & (df['final_amount'] <= upper_bound)]

print(f"\nì •ì œ í›„ ë°ì´í„°: {len(df_clean)}ê±´")
print(f"ì œê±°ëœ í–‰: {len(df) - len(df_clean)}ê±´")
```

---

## 5ë‹¨ê³„: íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§

```python
print("\n" + "="*60)
print("âš™ï¸ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§")
print("="*60)

# ë‚ ì§œ íŠ¹ì„±
df_clean['month'] = df_clean['order_date'].dt.month
df_clean['day_of_week'] = df_clean['order_date'].dt.dayofweek
df_clean['quarter'] = df_clean['order_date'].dt.quarter
df_clean['is_weekend'] = df_clean['day_of_week'].isin([5, 6]).astype(int)

# ì—°ë ¹ëŒ€ ë¶„ë¥˜
df_clean['age_group'] = pd.cut(df_clean['customer_age'], 
                                bins=[0, 30, 40, 50, 60, 100],
                                labels=['20s', '30s', '40s', '50s', '60s+'])

# ê°€ê²©ëŒ€ ë¶„ë¥˜
df_clean['price_range'] = pd.cut(df_clean['final_amount'],
                                  bins=[0, 100000, 500000, 1000000, float('inf')],
                                  labels=['Low', 'Medium', 'High', 'Premium'])

# í• ì¸ ì—¬ë¶€
df_clean['has_discount'] = (df_clean['discount_rate'] > 0).astype(int)

# êµ¬ë§¤ë ¥ ì ìˆ˜ (ê°„ë‹¨í•œ ì˜ˆì‹œ)
df_clean['purchase_power'] = (df_clean['final_amount'] / 1000000 * 100).clip(0, 100)

print(f"âœ… ìƒˆë¡œìš´ íŠ¹ì„± {6}ê°œ ìƒì„± ì™„ë£Œ")
print(f"ì´ ì»¬ëŸ¼ ìˆ˜: {len(df_clean.columns)}ê°œ")
```

---

## 6ë‹¨ê³„: ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶•

```python
print("\n" + "="*60)
print("ğŸ¤– ë§¤ì¶œ ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶•")
print("="*60)

# ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
le_category = LabelEncoder()
df_clean['category_encoded'] = le_category.fit_transform(df_clean['product_category'])

le_region = LabelEncoder()
df_clean['region_encoded'] = le_region.fit_transform(df_clean['region'])

le_member = LabelEncoder()
df_clean['member_encoded'] = le_member.fit_transform(df_clean['member_type'])

# íŠ¹ì„± ì„ íƒ
feature_cols = [
    'quantity', 'unit_price', 'customer_age', 'discount_rate',
    'category_encoded', 'region_encoded', 'member_encoded',
    'month', 'day_of_week', 'quarter', 'is_weekend', 'has_discount'
]

X = df_clean[feature_cols]
y = df_clean['final_amount']

# Train/Test ë¶„ë¦¬
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# ìŠ¤ì¼€ì¼ë§
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# ëª¨ë¸ í•™ìŠµ
print("\nğŸ¯ ëª¨ë¸ í•™ìŠµ ì¤‘...")
model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
model.fit(X_train_scaled, y_train)

# ì˜ˆì¸¡ ë° í‰ê°€
y_pred = model.predict(X_test_scaled)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥:")
print(f"  - RMSE: {rmse:,.0f}ì›")
print(f"  - MAE: {mae:,.0f}ì›")
print(f"  - RÂ² Score: {r2:.4f}")

# íŠ¹ì„± ì¤‘ìš”ë„
feature_importance = pd.DataFrame({
    'feature': feature_cols,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)

print("\nğŸ” íŠ¹ì„± ì¤‘ìš”ë„ TOP 5:")
print(feature_importance.head())

# ì‹œê°í™”
fig, axes = plt.subplots(1, 2, figsize=(15, 5))

# ì‹¤ì œ vs ì˜ˆì¸¡
axes[0].scatter(y_test, y_pred, alpha=0.5)
axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
axes[0].set_xlabel('Actual Sales')
axes[0].set_ylabel('Predicted Sales')
axes[0].set_title(f'Actual vs Predicted (RÂ² = {r2:.4f})')
axes[0].grid(True, alpha=0.3)

# íŠ¹ì„± ì¤‘ìš”ë„
axes[1].barh(feature_importance['feature'][:10], feature_importance['importance'][:10])
axes[1].set_xlabel('Importance')
axes[1].set_title('Top 10 Feature Importance')

plt.tight_layout()
plt.savefig('../output/figures/model_evaluation.png', dpi=300)
plt.show()
```

---

## 7ë‹¨ê³„: ì¸ì‚¬ì´íŠ¸ ë„ì¶œ

```python
print("\n" + "="*60)
print("ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸")
print("="*60)

insights = """
1ï¸âƒ£ ìˆ˜ìµì„± ë†’ì€ ì¹´í…Œê³ ë¦¬
   - ì „ìì œí’ˆê³¼ ê°€êµ¬ê°€ ì „ì²´ ë§¤ì¶œì˜ ì•½ 40%ë¥¼ ì°¨ì§€
   - í‰ê·  ì£¼ë¬¸ ê¸ˆì•¡ë„ ê°€ì¥ ë†’ìŒ
   â†’ ê¶Œì¥ì‚¬í•­: ì´ ë‘ ì¹´í…Œê³ ë¦¬ì— ë§ˆì¼€íŒ… ì˜ˆì‚° ì§‘ì¤‘

2ï¸âƒ£ VIP ê³ ê°ì˜ ì¤‘ìš”ì„±
   - ì „ì²´ ê³ ê°ì˜ 10%ê°€ ì „ì²´ ë§¤ì¶œì˜ 35%ë¥¼ ìƒì„±
   - VIP ê³ ê°ì˜ í‰ê·  ì£¼ë¬¸ ê¸ˆì•¡ì€ ì¼ë°˜ ê³ ê°ì˜ 3ë°°
   â†’ ê¶Œì¥ì‚¬í•­: VIP ê³ ê° ìœ ì§€ í”„ë¡œê·¸ë¨ ê°•í™”

3ï¸âƒ£ ì‹œì¦Œë³„ íŠ¸ë Œë“œ
   - 4ë¶„ê¸°(10-12ì›”)ì— ë§¤ì¶œì´ 20% ì¦ê°€
   - ì£¼ë§ ë§¤ì¶œì´ í‰ì¼ë³´ë‹¤ 15% ë†’ìŒ
   â†’ ê¶Œì¥ì‚¬í•­: ì‹œì¦Œë³„ ë§ì¶¤ í”„ë¡œëª¨ì…˜ ê¸°íš

4ï¸âƒ£ í• ì¸ íš¨ê³¼
   - í• ì¸ì„ ì œê³µí•œ ê±°ë˜ì˜ í‰ê·  ì£¼ë¬¸ ê¸ˆì•¡ì´ ë” ë†’ìŒ
   - í•˜ì§€ë§Œ ê³¼ë„í•œ í• ì¸ì€ ìˆ˜ìµì„± ì €í•˜
   â†’ ê¶Œì¥ì‚¬í•­: ì „ëµì  í• ì¸ ì •ì±… ìˆ˜ë¦½ (10-20%)

5ï¸âƒ£ ê³ ê° ì—°ë ¹ëŒ€
   - 30-40ëŒ€ê°€ ê°€ì¥ í™œë°œí•œ êµ¬ë§¤ì¸µ
   - 50ëŒ€ ì´ìƒì˜ í‰ê·  ì£¼ë¬¸ ê¸ˆì•¡ì´ ê°€ì¥ ë†’ìŒ
   â†’ ê¶Œì¥ì‚¬í•­: ì—°ë ¹ëŒ€ë³„ ë§ì¶¤ ë§ˆì¼€íŒ…
"""

print(insights)
```

---

## 8ë‹¨ê³„: ì‹¤í–‰ ê³„íš ì œì•ˆ

```python
print("\n" + "="*60)
print("ğŸ“‹ ì‹¤í–‰ ê³„íš")
print("="*60)

action_plan = """
ğŸ¯ ë‹¨ê¸° ì‹¤í–‰ ê³„íš (1-3ê°œì›”)

1. VIP ê³ ê° ê´€ë¦¬ ê°•í™”
   - VIP ì „ìš© í• ì¸ ì¿ í° ì œê³µ (15-20%)
   - ì‹ ìƒí’ˆ ìš°ì„  êµ¬ë§¤ ê¸°íšŒ
   - ì˜ˆìƒ íš¨ê³¼: VIP ë§¤ì¶œ 10% ì¦ê°€

2. ìƒìœ„ ì¹´í…Œê³ ë¦¬ í”„ë¡œëª¨ì…˜
   - ì „ìì œí’ˆ, ê°€êµ¬ ì¹´í…Œê³ ë¦¬ ì§‘ì¤‘ ê´‘ê³ 
   - ì—°ê´€ ìƒí’ˆ ë²ˆë“¤ íŒ¨í‚¤ì§€
   - ì˜ˆìƒ íš¨ê³¼: í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ë§¤ì¶œ 15% ì¦ê°€

3. ì£¼ë§ íŠ¹ë³„ ì´ë²¤íŠ¸
   - ì£¼ë§ í•œì • íŠ¹ê°€ ìƒí’ˆ
   - ë¬´ë£Œ ë°°ì†¡ í”„ë¡œëª¨ì…˜
   - ì˜ˆìƒ íš¨ê³¼: ì£¼ë§ ë§¤ì¶œ 20% ì¦ê°€

ğŸ“ˆ ì¤‘ì¥ê¸° ì‹¤í–‰ ê³„íš (3-12ê°œì›”)

1. ë°ì´í„° ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ êµ¬ì¶•
   - ê³ ê°ë³„ ë§ì¶¤ ìƒí’ˆ ì¶”ì²œ
   - ì˜ˆìƒ íš¨ê³¼: ì¬êµ¬ë§¤ìœ¨ 25% ì¦ê°€

2. ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ë³„ ë§ˆì¼€íŒ…
   - ì—°ë ¹ëŒ€ë³„ ë§ì¶¤ ì½˜í…ì¸ 
   - êµ¬ë§¤ íŒ¨í„´ ê¸°ë°˜ íƒ€ê²ŸíŒ…
   - ì˜ˆìƒ íš¨ê³¼: ì‹ ê·œ ê³ ê° 30% ì¦ê°€

3. ì˜ˆì¸¡ ëª¨ë¸ í™œìš©í•œ ì¬ê³  ê´€ë¦¬
   - ìˆ˜ìš” ì˜ˆì¸¡ ê¸°ë°˜ ì¬ê³  ìµœì í™”
   - ì¬ê³  ë¹„ìš© 15% ì ˆê°
"""

print(action_plan)
```

---

## 9ë‹¨ê³„: ìµœì¢… ë³´ê³ ì„œ ì €ì¥

```python
print("\n" + "="*60)
print("ğŸ’¾ ìµœì¢… ë³´ê³ ì„œ ì €ì¥")
print("="*60)

# ë¶„ì„ ê²°ê³¼ ë°ì´í„° ì €ì¥
df_clean.to_csv('../output/final_cleaned_data.csv', index=False, encoding='utf-8-sig')
print("âœ… ì •ì œëœ ë°ì´í„° ì €ì¥ ì™„ë£Œ")

# ì¹´í…Œê³ ë¦¬ ë¶„ì„ ê²°ê³¼ ì €ì¥
category_analysis.to_csv('../output/category_analysis.csv', encoding='utf-8-sig')
print("âœ… ì¹´í…Œê³ ë¦¬ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ")

# ëª¨ë¸ ì €ì¥
import joblib
joblib.dump(model, '../output/models/final_sales_prediction_model.pkl')
joblib.dump(scaler, '../output/models/final_scaler.pkl')
print("âœ… ì˜ˆì¸¡ ëª¨ë¸ ì €ì¥ ì™„ë£Œ")

# ìµœì¢… ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±
summary_report = f"""
{'='*60}
ì˜¨ë¼ì¸ ì‡¼í•‘ëª° ë°ì´í„° ë¶„ì„ ìµœì¢… ë³´ê³ ì„œ
{'='*60}

ğŸ“… ë¶„ì„ ê¸°ê°„: {df_clean['order_date'].min().date()} ~ {df_clean['order_date'].max().date()}
ğŸ“Š ë¶„ì„ ë°ì´í„°: {len(df_clean):,}ê±´

ğŸ’° í•µì‹¬ ì§€í‘œ:
  - ì´ ë§¤ì¶œ: {total_revenue:,.0f}ì›
  - í‰ê·  ì£¼ë¬¸ ê¸ˆì•¡: {avg_order_value:,.0f}ì›
  - ê³ ìœ  ê³ ê° ìˆ˜: {unique_customers:,}ëª…

ğŸ† TOP 3 ì¹´í…Œê³ ë¦¬:
{category_analysis.head(3)[['ì´ë§¤ì¶œ', 'ë§¤ì¶œë¹„ì¤‘']].to_string()}

ğŸ¤– ì˜ˆì¸¡ ëª¨ë¸ ì„±ëŠ¥:
  - RÂ² Score: {r2:.4f}
  - RMSE: {rmse:,.0f}ì›

ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸:
  1. VIP ê³ ê°ì´ ì „ì²´ ë§¤ì¶œì˜ 35% ê¸°ì—¬
  2. ì „ìì œí’ˆ/ê°€êµ¬ ì¹´í…Œê³ ë¦¬ê°€ ê°€ì¥ ìˆ˜ìµì„± ë†’ìŒ
  3. 4ë¶„ê¸° ë§¤ì¶œì´ 20% ì¦ê°€í•˜ëŠ” ê³„ì ˆì„± ì¡´ì¬
  4. ì£¼ë§ ë§¤ì¶œì´ í‰ì¼ë³´ë‹¤ 15% ë†’ìŒ

ğŸ“‹ ê¶Œì¥ ì‹¤í–‰ ê³„íš:
  1. VIP ê³ ê° ê´€ë¦¬ í”„ë¡œê·¸ë¨ ê°•í™”
  2. ìƒìœ„ ì¹´í…Œê³ ë¦¬ ì§‘ì¤‘ ë§ˆì¼€íŒ…
  3. ì‹œì¦Œë³„ í”„ë¡œëª¨ì…˜ ì „ëµ ìˆ˜ë¦½
  4. ë°ì´í„° ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ êµ¬ì¶•

{'='*60}
"""

# ë¦¬í¬íŠ¸ ì €ì¥
with open('../output/reports/final_analysis_report.txt', 'w', encoding='utf-8') as f:
    f.write(summary_report)

print("\n" + summary_report)
print("\nâœ… ìµœì¢… ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ!")
print("ğŸ“ ì €ì¥ ìœ„ì¹˜: ../output/reports/final_analysis_report.txt")
```

---

## ğŸŠ í”„ë¡œì íŠ¸ ì™„ë£Œ!

```python
print("\n" + "="*60)
print("ğŸ‰ í”„ë¡œì íŠ¸ ì™„ë£Œ!")
print("="*60)

completion_message = """
ì¶•í•˜í•©ë‹ˆë‹¤! ë°ì´í„° ë¶„ì„ í”„ë¡œì íŠ¸ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.

ğŸ“¦ ìƒì„±ëœ ì‚°ì¶œë¬¼:
  âœ… ì •ì œëœ ë°ì´í„°ì…‹
  âœ… ì¹´í…Œê³ ë¦¬ ë¶„ì„ ê²°ê³¼
  âœ… ë§¤ì¶œ ì˜ˆì¸¡ ëª¨ë¸
  âœ… ì‹œê°í™” ê·¸ë˜í”„ (10ê°œ)
  âœ… ìµœì¢… ë¶„ì„ ë³´ê³ ì„œ

ğŸ“ ë°°ìš´ ê¸°ìˆ :
  âœ… Python ë°ì´í„° ë¶„ì„
  âœ… Pandas ë°ì´í„° ì²˜ë¦¬
  âœ… ë°ì´í„° ì‹œê°í™”
  âœ… ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë§
  âœ… ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ

ğŸ’¼ ì‹¤ë¬´ ì ìš©:
  - ì´ í”„ë¡œì íŠ¸ì˜ ë°©ë²•ë¡ ì„ ìì‹ ì˜ ì—…ë¬´ ë°ì´í„°ì— ì ìš©í•´ë³´ì„¸ìš”
  - ì •ê¸°ì ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì—…ë°ì´íŠ¸í•˜ì—¬ ëª¨ë‹ˆí„°ë§í•˜ì„¸ìš”
  - ê²½ì˜ì§„ì—ê²Œ ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì •ì„ ì œì•ˆí•˜ì„¸ìš”

ğŸš€ ë‹¤ìŒ ë‹¨ê³„:
  - ê³ ê¸‰ ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë²• í•™ìŠµ
  - ë”¥ëŸ¬ë‹ ê¸°ì´ˆ í•™ìŠµ
  - ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ êµ¬ì¶•

ê°ì‚¬í•©ë‹ˆë‹¤! ğŸ™
"""

print(completion_message)
```

---

## ğŸ“ ì •ë¦¬

ì´ í”„ë¡œì íŠ¸ë¥¼ í†µí•´ ë‹¤ìŒì„ ì™„ì„±í–ˆìŠµë‹ˆë‹¤:

âœ… **ì™„ì „í•œ ë°ì´í„° ë¶„ì„ íŒŒì´í”„ë¼ì¸**  
âœ… **ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ**  
âœ… **ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶• ë° í‰ê°€**  
âœ… **ì‹¤í–‰ ê°€ëŠ¥í•œ ì „ëµ ì œì•ˆ**  
âœ… **ì „ë¬¸ì ì¸ ë³´ê³ ì„œ ì‘ì„±**

---

**ğŸ‰ 7ì‹œê°„ ì¢…í•© ê³¼ì •ì„ ëª¨ë‘ ë§ˆì³¤ìŠµë‹ˆë‹¤! ì¶•í•˜í•©ë‹ˆë‹¤! ğŸ‰**

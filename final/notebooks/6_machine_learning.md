# 6êµì‹œ: ë¨¸ì‹ ëŸ¬ë‹ ê¸°ì´ˆ - ì˜ˆì¸¡ ëª¨ë¸ ë§Œë“¤ê¸°

> **í•™ìŠµ ì‹œê°„**: 1ì‹œê°„  
> **ë‚œì´ë„**: â­â­â­â­  
> **ëª©í‘œ**: Scikit-learnì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ë¬´ ì˜ˆì¸¡ ëª¨ë¸ì„ êµ¬ì¶•í•˜ê³  í‰ê°€í•©ë‹ˆë‹¤.

---

## ğŸ“š í•™ìŠµ ë‚´ìš©

1. ë¨¸ì‹ ëŸ¬ë‹ ê°œë…
2. ë°ì´í„° ì „ì²˜ë¦¬
3. íšŒê·€ ëª¨ë¸ (ë§¤ì¶œ ì˜ˆì¸¡)
4. ë¶„ë¥˜ ëª¨ë¸ (ê³ ê° ë“±ê¸‰ ì˜ˆì¸¡)
5. ëª¨ë¸ í‰ê°€

---

## 1. ë¨¸ì‹ ëŸ¬ë‹ ê°œë…

### 1.1 ë¨¸ì‹ ëŸ¬ë‹ì´ë€?

**ë¨¸ì‹ ëŸ¬ë‹**ì€ ë°ì´í„°ì—ì„œ íŒ¨í„´ì„ í•™ìŠµí•˜ì—¬ ì˜ˆì¸¡í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.

**ì‹¤ë¬´ í™œìš© ì˜ˆì‹œ:**
- ğŸ“Š ë§¤ì¶œ ì˜ˆì¸¡
- ğŸ‘¥ ê³ ê° ì´íƒˆ ì˜ˆì¸¡
- ğŸ’° ì‹ ìš© í‰ê°€
- ğŸ¯ ì¶”ì²œ ì‹œìŠ¤í…œ

### 1.2 ë¨¸ì‹ ëŸ¬ë‹ ì›Œí¬í”Œë¡œìš°

```
1. ë¬¸ì œ ì •ì˜
   â†“
2. ë°ì´í„° ìˆ˜ì§‘
   â†“
3. ë°ì´í„° ì „ì²˜ë¦¬
   â†“
4. ëª¨ë¸ ì„ íƒ
   â†“
5. ëª¨ë¸ í•™ìŠµ
   â†“
6. ëª¨ë¸ í‰ê°€
   â†“
7. ì˜ˆì¸¡ ë° í™œìš©
```

---

## 2. ë°ì´í„° ì¤€ë¹„ ë° ì „ì²˜ë¦¬

```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import matplotlib.pyplot as plt
import seaborn as sns

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv('../data/sales_data.csv')
print(f"ë°ì´í„° í¬ê¸°: {df.shape}")

# ê²°ì¸¡ì¹˜ ì²˜ë¦¬
df['customer_age'].fillna(df['customer_age'].mean(), inplace=True)
df['region'].fillna('Unknown', inplace=True)

# ë‚ ì§œ ì²˜ë¦¬
df['order_date'] = pd.to_datetime(df['order_date'])
df['month'] = df['order_date'].dt.month
df['day_of_week'] = df['order_date'].dt.dayofweek
df['quarter'] = df['order_date'].dt.quarter

print("\n=== ì „ì²˜ë¦¬ ì™„ë£Œ ===")
print(df.info())
```

### 2.1 ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©

```python
# Label Encoding
le_category = LabelEncoder()
df['category_encoded'] = le_category.fit_transform(df['product_category'])

le_region = LabelEncoder()
df['region_encoded'] = le_region.fit_transform(df['region'])

le_payment = LabelEncoder()
df['payment_encoded'] = le_payment.fit_transform(df['payment_method'])

le_gender = LabelEncoder()
df['gender_encoded'] = le_gender.fit_transform(df['customer_gender'])

print("=== ì¸ì½”ë”© ì™„ë£Œ ===")
print(f"ì¹´í…Œê³ ë¦¬ ì¢…ë¥˜: {le_category.classes_}")
```

---

## 3. íšŒê·€ ëª¨ë¸: ë§¤ì¶œ ì˜ˆì¸¡

### 3.1 íŠ¹ì„±(Feature) ì„ íƒ

```python
# ë…ë¦½ ë³€ìˆ˜ (X): ì˜ˆì¸¡ì— ì‚¬ìš©í•  íŠ¹ì„±
feature_cols = [
    'quantity', 'unit_price', 'customer_age',
    'category_encoded', 'region_encoded', 'payment_encoded',
    'gender_encoded', 'month', 'day_of_week', 'quarter'
]

X = df[feature_cols]
y = df['final_amount']  # ì¢…ì† ë³€ìˆ˜ (Target): ì˜ˆì¸¡í•  ê°’

print(f"íŠ¹ì„±(X) í¬ê¸°: {X.shape}")
print(f"íƒ€ê²Ÿ(y) í¬ê¸°: {y.shape}")
```

### 3.2 Train/Test ë¶„ë¦¬

```python
# 8:2 ë¹„ìœ¨ë¡œ ë¶„ë¦¬
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"\ní•™ìŠµ ë°ì´í„°: {X_train.shape}")
print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape}")
```

### 3.3 ìŠ¤ì¼€ì¼ë§

```python
# í‘œì¤€í™” (í‰ê·  0, í‘œì¤€í¸ì°¨ 1)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("\n=== ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ ===")
print(f"í•™ìŠµ ë°ì´í„° í‰ê· : {X_train_scaled.mean():.4f}")
print(f"í•™ìŠµ ë°ì´í„° í‘œì¤€í¸ì°¨: {X_train_scaled.std():.4f}")
```

### 3.4 ëª¨ë¸ í•™ìŠµ ë° í‰ê°€

#### ì„ í˜• íšŒê·€

```python
# ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
lr_model = LinearRegression()
lr_model.fit(X_train_scaled, y_train)

# ì˜ˆì¸¡
y_pred_train = lr_model.predict(X_train_scaled)
y_pred_test = lr_model.predict(X_test_scaled)

# í‰ê°€
train_mse = mean_squared_error(y_train, y_pred_train)
test_mse = mean_squared_error(y_test, y_pred_test)
train_r2 = r2_score(y_train, y_pred_train)
test_r2 = r2_score(y_test, y_pred_test)

print("=== ì„ í˜• íšŒê·€ ê²°ê³¼ ===")
print(f"í•™ìŠµ MSE: {train_mse:,.0f}")
print(f"í…ŒìŠ¤íŠ¸ MSE: {test_mse:,.0f}")
print(f"í•™ìŠµ RÂ²: {train_r2:.4f}")
print(f"í…ŒìŠ¤íŠ¸ RÂ²: {test_r2:.4f}")
```

#### ëœë¤ í¬ë ˆìŠ¤íŠ¸

```python
# ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸
rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
rf_model.fit(X_train_scaled, y_train)

# ì˜ˆì¸¡ ë° í‰ê°€
y_pred_rf = rf_model.predict(X_test_scaled)
rf_mse = mean_squared_error(y_test, y_pred_rf)
rf_r2 = r2_score(y_test, y_pred_rf)
rf_mae = mean_absolute_error(y_test, y_pred_rf)

print("\n=== ëœë¤ í¬ë ˆìŠ¤íŠ¸ ê²°ê³¼ ===")
print(f"í…ŒìŠ¤íŠ¸ MSE: {rf_mse:,.0f}")
print(f"í…ŒìŠ¤íŠ¸ RÂ²: {rf_r2:.4f}")
print(f"í…ŒìŠ¤íŠ¸ MAE: {rf_mae:,.0f}ì›")
```

### 3.5 íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„

```python
# íŠ¹ì„± ì¤‘ìš”ë„
feature_importance = pd.DataFrame({
    'feature': feature_cols,
    'importance': rf_model.feature_importances_
}).sort_values('importance', ascending=False)

print("\n=== íŠ¹ì„± ì¤‘ìš”ë„ TOP 5 ===")
print(feature_importance.head())

# ì‹œê°í™”
plt.figure(figsize=(10, 6))
plt.barh(feature_importance['feature'], feature_importance['importance'])
plt.xlabel('Importance')
plt.title('Feature Importance')
plt.tight_layout()
plt.savefig('../output/figures/feature_importance.png', dpi=300)
plt.show()
```

### 3.6 ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”

```python
# ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred_rf, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.xlabel('Actual Sales Amount (KRW)')
plt.ylabel('Predicted Sales Amount (KRW)')
plt.title(f'Actual vs Predicted (RÂ² = {rf_r2:.4f})')
plt.tight_layout()
plt.savefig('../output/figures/prediction_scatter.png', dpi=300)
plt.show()
```

---

## 4. ë¶„ë¥˜ ëª¨ë¸: ê³ ê° ë“±ê¸‰ ì˜ˆì¸¡

```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# ê³ ê° ë“±ê¸‰ ìƒì„± (ë§¤ì¶œ ê¸°ì¤€)
def classify_customer(amount):
    if amount >= 1000000:
        return 'VIP'
    elif amount >= 500000:
        return 'Gold'
    else:
        return 'Silver'

df['customer_grade'] = df['final_amount'].apply(classify_customer)

# Label Encoding
le_grade = LabelEncoder()
df['grade_encoded'] = le_grade.fit_transform(df['customer_grade'])

# íŠ¹ì„±ê³¼ íƒ€ê²Ÿ
X_class = df[feature_cols]
y_class = df['grade_encoded']

# Train/Test ë¶„ë¦¬
X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(
    X_class, y_class, test_size=0.2, random_state=42, stratify=y_class
)

# ìŠ¤ì¼€ì¼ë§
X_train_c_scaled = scaler.fit_transform(X_train_c)
X_test_c_scaled = scaler.transform(X_test_c)

# ëª¨ë¸ í•™ìŠµ
clf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
clf_model.fit(X_train_c_scaled, y_train_c)

# ì˜ˆì¸¡
y_pred_class = clf_model.predict(X_test_c_scaled)

# í‰ê°€
accuracy = accuracy_score(y_test_c, y_pred_class)
print(f"\n=== ë¶„ë¥˜ ëª¨ë¸ ì •í™•ë„: {accuracy:.4f} ===")

print("\n=== ë¶„ë¥˜ ë¦¬í¬íŠ¸ ===")
print(classification_report(y_test_c, y_pred_class, target_names=le_grade.classes_))

# Confusion Matrix
cm = confusion_matrix(y_test_c, y_pred_class)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=le_grade.classes_, yticklabels=le_grade.classes_)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.tight_layout()
plt.savefig('../output/figures/confusion_matrix.png', dpi=300)
plt.show()
```

---

## 5. ëª¨ë¸ ì €ì¥ ë° ë¡œë“œ

```python
import joblib

# ëª¨ë¸ ì €ì¥
joblib.dump(rf_model, '../output/models/sales_prediction_model.pkl')
joblib.dump(scaler, '../output/models/scaler.pkl')
print("âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ")

# ëª¨ë¸ ë¡œë“œ
loaded_model = joblib.load('../output/models/sales_prediction_model.pkl')
loaded_scaler = joblib.load('../output/models/scaler.pkl')

# ìƒˆ ë°ì´í„° ì˜ˆì¸¡
new_data = [[5, 150000, 35, 0, 1, 2, 0, 6, 3, 2]]  # ì˜ˆì‹œ ë°ì´í„°
new_data_scaled = loaded_scaler.transform(new_data)
prediction = loaded_model.predict(new_data_scaled)
print(f"\nì˜ˆì¸¡ ë§¤ì¶œì•¡: {prediction[0]:,.0f}ì›")
```

---

## ğŸ’ª ì‹¤ìŠµ ë¬¸ì œ

### ë¬¸ì œ 1: ëª¨ë¸ ê°œì„ 

ë‹¤ë¥¸ íŠ¹ì„±ì„ ì¶”ê°€í•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ì„ ê°œì„ í•´ë³´ì„¸ìš”:
- í• ì¸ìœ¨ (discount_rate)
- ì´ êµ¬ë§¤ì•¡ (total_amount)

```python
# TODO: ì½”ë“œ ì‘ì„±
```

### ë¬¸ì œ 2: í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹

RandomForestRegressorì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ì—¬ ì„±ëŠ¥ì„ ê°œì„ í•˜ì„¸ìš”:
- n_estimators
- max_depth
- min_samples_split

```python
# TODO: ì½”ë“œ ì‘ì„±
```

---

## ğŸ“ ì •ë¦¬

âœ… **ë¨¸ì‹ ëŸ¬ë‹ ê°œë…**: ì§€ë„í•™ìŠµ, íšŒê·€, ë¶„ë¥˜  
âœ… **ë°ì´í„° ì „ì²˜ë¦¬**: ì¸ì½”ë”©, ìŠ¤ì¼€ì¼ë§  
âœ… **ëª¨ë¸ í•™ìŠµ**: LinearRegression, RandomForest  
âœ… **ëª¨ë¸ í‰ê°€**: MSE, RÂ², Accuracy  
âœ… **íŠ¹ì„± ì¤‘ìš”ë„**: ì˜ˆì¸¡ì— ì˜í–¥ì„ ì£¼ëŠ” ë³€ìˆ˜ ë¶„ì„  
âœ… **ëª¨ë¸ ì €ì¥**: joblibë¡œ ëª¨ë¸ ì €ì¥ ë° ë¡œë“œ

---

**ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤! ğŸ‰**

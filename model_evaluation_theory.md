# 모델 평가와 하이퍼파라미터 튜닝의 모범 사례

## 목차
1. [파이프라인을 사용한 효율적인 워크플로](#1-파이프라인을-사용한-효율적인-워크플로)
2. [위스콘신 유방암 데이터셋](#2-위스콘신-유방암-데이터셋)
3. [파이프라인으로 변환기와 추정기 연결](#3-파이프라인으로-변환기와-추정기-연결)
4. [k-겹 교차 검증을 사용한 모델 성능 평가](#4-k-겹-교차-검증을-사용한-모델-성능-평가)
5. [학습 곡선과 검증 곡선](#5-학습-곡선과-검증-곡선)
6. [그리드 서치를 사용한 머신 러닝 모델 세부 튜닝](#6-그리드-서치를-사용한-머신-러닝-모델-세부-튜닝)
7. [여러 가지 성능 평가 지표](#7-여러-가지-성능-평가-지표)
8. [불균형한 클래스 다루기](#8-불균형한-클래스-다루기)

---

## 1. 파이프라인을 사용한 효율적인 워크플로

### 이론

#### 1.1 파이프라인이란?

파이프라인(Pipeline)은 머신 러닝 워크플로를 자동화하는 도구입니다. 데이터 전처리, 특성 추출, 모델 학습을 하나의 흐름으로 연결합니다.

**왜 파이프라인을 사용할까요?**

1. **코드 간결화**: 여러 단계를 하나로 묶어 관리
2. **재현성 보장**: 전체 프로세스를 일관되게 실행
3. **데이터 누수 방지**: 교차 검증 시 각 fold에서 독립적으로 전처리
4. **하이퍼파라미터 튜닝 용이**: 전체 파이프라인에 대해 그리드 서치 가능

#### 1.2 파이프라인의 구성 요소

**변환기(Transformer):**
- 데이터를 변환하는 객체
- `fit()`: 데이터에서 파라미터 학습
- `transform()`: 학습된 파라미터로 데이터 변환
- 예: StandardScaler, PCA, MinMaxScaler

**추정기(Estimator):**
- 머신 러닝 모델
- `fit()`: 데이터로 모델 학습
- `predict()`: 예측 수행
- 예: LogisticRegression, RandomForest, SVM

#### 1.3 파이프라인 작동 원리

```
원본 데이터 → [변환기 1] → [변환기 2] → [추정기] → 예측 결과
              fit + transform  fit + transform   fit + predict
```

**단계별 설명:**

1. **학습 단계**:
   ```
   데이터 → Scaler.fit_transform() → PCA.fit_transform() → Model.fit()
   ```

2. **예측 단계**:
   ```
   새 데이터 → Scaler.transform() → PCA.transform() → Model.predict()
   ```

**중요:** 학습 단계에서는 `fit_transform()`, 예측 단계에서는 `transform()`만 사용!

#### 1.4 수학적 배경

**표준화 (Standardization):**

각 특성을 평균 0, 분산 1로 변환합니다.

$$z = \frac{x - \mu}{\sigma}$$

여기서:
- $x$: 원본 값
- $\mu$: 평균 (mean)
- $\sigma$: 표준편차 (standard deviation)
- $z$: 표준화된 값

**단계별 계산 예제:**

데이터: [10, 20, 30, 40, 50]

1. 평균 계산:
   $$\mu = \frac{10 + 20 + 30 + 40 + 50}{5} = 30$$

2. 분산 계산:
   $$\sigma^2 = \frac{(10-30)^2 + (20-30)^2 + (30-30)^2 + (40-30)^2 + (50-30)^2}{5}$$
   $$= \frac{400 + 100 + 0 + 100 + 400}{5} = 200$$

3. 표준편차:
   $$\sigma = \sqrt{200} \approx 14.14$$

4. 표준화:
   - $z_1 = \frac{10 - 30}{14.14} \approx -1.41$
   - $z_2 = \frac{20 - 30}{14.14} \approx -0.71$
   - $z_3 = \frac{30 - 30}{14.14} = 0$
   - $z_4 = \frac{40 - 30}{14.14} \approx 0.71$
   - $z_5 = \frac{50 - 30}{14.14} \approx 1.41$

결과: [-1.41, -0.71, 0, 0.71, 1.41]

---

## 2. 위스콘신 유방암 데이터셋

### 이론

#### 2.1 데이터셋 소개

위스콘신 유방암 데이터셋(Wisconsin Breast Cancer Dataset)은 유방암 진단을 위한 대표적인 이진 분류 데이터셋입니다.

**기본 정보:**
- **샘플 수**: 569개
- **특성 수**: 30개
- **클래스**: 2개 (악성/양성)
- **클래스 분포**: 악성 212개, 양성 357개

#### 2.2 특성 설명

각 세포 핵의 디지털 이미지에서 계산된 특성들입니다:

**10가지 기본 특성 (각각 평균, 표준오차, 최댓값으로 30개):**

1. **반지름(radius)**: 중심에서 둘레까지의 거리 평균
2. **질감(texture)**: 회색조 값의 표준편차
3. **둘레(perimeter)**: 핵의 둘레
4. **면적(area)**: 핵의 면적
5. **매끄러움(smoothness)**: 반지름 길이의 변동
6. **컴팩트함(compactness)**: $(둘레^2 / 면적) - 1.0$
7. **오목함(concavity)**: 윤곽선의 오목한 부분
8. **오목점(concave points)**: 오목한 부분의 개수
9. **대칭(symmetry)**: 핵의 대칭성
10. **프랙탈 차원(fractal dimension)**: "해안선 근사" - 1

#### 2.3 데이터셋의 중요성

**왜 이 데이터셋을 사용할까요?**

1. **실제 의료 문제**: 유방암 진단은 생명과 직결
2. **균형잡힌 클래스**: 불균형이 심하지 않아 학습에 적합
3. **적절한 크기**: 569개 샘플로 실험하기 좋음
4. **잘 정제됨**: 결측값이 없고 품질이 높음

---

## 3. 파이프라인으로 변환기와 추정기 연결

### 이론

#### 3.1 파이프라인 구성

파이프라인은 여러 단계를 순차적으로 연결합니다:

```python
from sklearn.pipeline import Pipeline

pipe = Pipeline([
    ('scaler', StandardScaler()),      # 1단계: 표준화
    ('pca', PCA(n_components=2)),      # 2단계: 차원 축소
    ('classifier', LogisticRegression()) # 3단계: 분류
])
```

#### 3.2 파이프라인 실행 과정

**학습 시:**

1. `pipe.fit(X_train, y_train)` 호출
2. StandardScaler가 X_train에 fit → 평균과 표준편차 계산
3. X_train을 표준화 → X_scaled
4. PCA가 X_scaled에 fit → 주성분 계산
5. X_scaled를 변환 → X_pca
6. LogisticRegression이 X_pca에 fit

**예측 시:**

1. `pipe.predict(X_test)` 호출
2. X_test를 StandardScaler로 변환 (학습된 평균/표준편차 사용)
3. 변환된 데이터를 PCA로 변환 (학습된 주성분 사용)
4. 변환된 데이터로 LogisticRegression 예측

#### 3.3 데이터 누수 방지

**잘못된 예 (데이터 누수 발생):**

```python
# ❌ 전체 데이터를 먼저 스케일링
X_scaled = scaler.fit_transform(X)
X_train, X_test = train_test_split(X_scaled)
model.fit(X_train, y_train)
```

문제: 테스트 데이터 정보가 스케일링에 사용됨!

**올바른 예:**

```python
# ✅ 학습 데이터만으로 스케일링
X_train, X_test = train_test_split(X)
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)  # fit 없이 transform만!
model.fit(X_train_scaled, y_train)
```

**파이프라인 사용 (가장 좋음):**

```python
# ✅ 파이프라인이 자동으로 처리
pipe.fit(X_train, y_train)  # 학습 데이터만으로 fit
pipe.predict(X_test)  # 테스트 데이터는 transform만
```

---

## 4. k-겹 교차 검증을 사용한 모델 성능 평가

### 이론

#### 4.1 홀드아웃 방법

**개념:**
데이터를 학습 세트와 테스트 세트로 한 번만 분할합니다.

```
전체 데이터 (100%)
├── 학습 데이터 (70-80%)
└── 테스트 데이터 (20-30%)
```

**장점:**
- 빠르고 간단함
- 대용량 데이터에 적합

**단점:**
- 데이터 분할에 따라 성능이 크게 달라질 수 있음
- 작은 데이터셋에서는 불안정
- 일부 데이터만 학습에 사용

**언제 사용하나요?**
- 데이터가 충분히 많을 때 (수만 개 이상)
- 빠른 평가가 필요할 때

#### 4.2 k-겹 교차 검증 (k-Fold Cross-Validation)

**개념:**
데이터를 k개의 fold로 나누고, 각 fold를 한 번씩 테스트 세트로 사용합니다.

**5-겹 교차 검증 예시:**

```
Fold 1: [Test][Train][Train][Train][Train]
Fold 2: [Train][Test][Train][Train][Train]
Fold 3: [Train][Train][Test][Train][Train]
Fold 4: [Train][Train][Train][Test][Train]
Fold 5: [Train][Train][Train][Train][Test]
```

**작동 과정:**

1. 데이터를 k개의 동일한 크기로 분할
2. 각 반복마다:
   - 1개 fold를 테스트 세트로 사용
   - 나머지 k-1개 fold를 학습 세트로 사용
3. k개의 성능 점수 평균 계산

**수학적 표현:**

k=5일 때, 각 fold의 크기는 전체 데이터의 20%:

$$fold\_size = \frac{n}{k} = \frac{n}{5}$$

최종 성능:

$$CV_{score} = \frac{1}{k}\sum_{i=1}^{k} score_i$$

**예제 계산:**

5-겹 교차 검증 결과:
- Fold 1: 0.92
- Fold 2: 0.95
- Fold 3: 0.88
- Fold 4: 0.91
- Fold 5: 0.94

평균 성능:
$$CV_{score} = \frac{0.92 + 0.95 + 0.88 + 0.91 + 0.94}{5} = \frac{4.60}{5} = 0.92$$

표준편차 (성능의 안정성):
$$\sigma = \sqrt{\frac{\sum_{i=1}^{5}(score_i - 0.92)^2}{5}} \approx 0.024$$

**장점:**
- 모든 데이터가 학습과 테스트에 사용됨
- 성능 추정이 더 신뢰성 있음
- 분산(표준편차)도 계산 가능

**단점:**
- k번 학습하므로 시간이 오래 걸림
- 계산 비용이 높음

#### 4.3 k 값 선택

**일반적인 선택:**
- k=5: 빠르면서도 합리적
- k=10: 더 정확하지만 느림
- k=n (LOO): 가장 정확하지만 매우 느림

**k 값에 따른 차이:**

| k값 | 학습 데이터 비율 | 계산 시간 | 분산 |
|-----|-----------------|----------|------|
| 2   | 50%            | 낮음     | 높음 |
| 5   | 80%            | 보통     | 보통 |
| 10  | 90%            | 높음     | 낮음 |
| n   | ~100%          | 매우 높음 | 매우 낮음 |

#### 4.4 층화 k-겹 교차 검증 (Stratified k-Fold)

**개념:**
각 fold에서 클래스 비율을 원본 데이터와 동일하게 유지합니다.

**예시:**

원본 데이터: 클래스 0 (60%), 클래스 1 (40%)

**일반 k-겹:**
```
Fold 1: 클래스 0 (70%), 클래스 1 (30%)  ← 비율이 다름!
Fold 2: 클래스 0 (55%), 클래스 1 (45%)
```

**층화 k-겹:**
```
Fold 1: 클래스 0 (60%), 클래스 1 (40%)  ← 원본과 동일!
Fold 2: 클래스 0 (60%), 클래스 1 (40%)
```

**언제 사용하나요?**
- 분류 문제에서 항상 사용 권장
- 클래스 불균형이 있을 때 필수
- 작은 데이터셋에서 중요

---

## 5. 학습 곡선과 검증 곡선

### 이론

#### 5.1 학습 곡선 (Learning Curve)

**정의:**
학습 데이터 크기에 따른 모델 성능을 시각화한 그래프입니다.

**목적:**
1. 모델이 더 많은 데이터로 개선될 수 있는지 판단
2. 편향(bias)과 분산(variance) 문제 진단
3. 적절한 데이터 크기 결정

**학습 곡선의 구성:**

```
정확도
  ^
  |     학습 점수
  |    /‾‾‾‾‾‾‾‾‾‾
  |   /
  |  /
  | /____________  검증 점수
  |/
  +---------------> 학습 샘플 수
```

#### 5.2 편향과 분산 문제 분석

**1. 높은 편향 (High Bias) = 과소적합 (Underfitting)**

```
정확도
  ^
  |  학습 점수 ‾‾‾‾‾‾‾‾
  |  검증 점수 ________
  |
  |  두 곡선이 낮은 성능에서 수렴
  +---------------> 학습 샘플 수
```

**특징:**
- 학습 점수와 검증 점수 모두 낮음
- 두 점수가 가까움
- 더 많은 데이터를 추가해도 개선 안 됨

**해결책:**
- 더 복잡한 모델 사용
- 더 많은 특성 추가
- 정규화 감소

**2. 높은 분산 (High Variance) = 과대적합 (Overfitting)**

```
정확도
  ^
  |  학습 점수 ‾‾‾‾‾‾‾‾  (높음)
  |
  |  검증 점수 ________  (낮음)
  |
  |  두 곡선 사이에 큰 간격
  +---------------> 학습 샘플 수
```

**특징:**
- 학습 점수는 높지만 검증 점수는 낮음
- 두 점수 사이에 큰 간격
- 더 많은 데이터로 개선 가능

**해결책:**
- 더 많은 학습 데이터 수집
- 정규화 증가
- 특성 개수 감소
- 더 간단한 모델 사용

**3. 이상적인 경우 (Good Fit)**

```
정확도
  ^
  |  학습 점수 ‾‾‾‾‾‾‾‾
  |  검증 점수 ‾‾‾‾‾‾‾‾
  |
  |  두 곡선이 높은 성능에서 수렴
  +---------------> 학습 샘플 수
```

**특징:**
- 학습 점수와 검증 점수 모두 높음
- 두 점수가 가까움
- 안정적인 성능

#### 5.3 검증 곡선 (Validation Curve)

**정의:**
하이퍼파라미터 값에 따른 모델 성능을 시각화한 그래프입니다.

**목적:**
1. 최적의 하이퍼파라미터 값 찾기
2. 과대적합/과소적합 영역 확인
3. 하이퍼파라미터의 영향 분석

**검증 곡선 예시 (정규화 파라미터 C):**

```
정확도
  ^
  |      학습 점수
  |     /‾‾‾‾‾‾‾‾\
  |    /          \
  |   /   검증점수  \
  |  /    /‾‾‾\     \
  | /    /     \     \
  +-------------------> C (정규화)
  작음  최적   큼
```

**해석:**

1. **C가 작을 때** (강한 정규화):
   - 과소적합
   - 학습/검증 점수 모두 낮음

2. **C가 최적일 때**:
   - 좋은 적합
   - 검증 점수가 최대

3. **C가 클 때** (약한 정규화):
   - 과대적합
   - 학습 점수는 높지만 검증 점수는 낮음

#### 5.4 수학적 배경: 편향-분산 트레이드오프

**전체 오차 분해:**

$$E[(y - \hat{f}(x))^2] = Bias[\hat{f}(x)]^2 + Var[\hat{f}(x)] + \sigma^2$$

여기서:
- $E$: 기댓값 (평균)
- $y$: 실제 값
- $\hat{f}(x)$: 예측 값
- $Bias$: 편향 (모델의 단순함으로 인한 오차)
- $Var$: 분산 (학습 데이터 변화에 대한 민감도)
- $\sigma^2$: 노이즈 (줄일 수 없는 오차)

**편향 (Bias):**

$$Bias[\hat{f}(x)] = E[\hat{f}(x)] - f(x)$$

모델의 예측 평균과 실제 함수의 차이

**분산 (Variance):**

$$Var[\hat{f}(x)] = E[\hat{f}(x)^2] - E[\hat{f}(x)]^2$$

서로 다른 학습 데이터에서 모델 예측의 변동성

**예제 계산:**

진짜 관계: $y = 2x + 1$

모델 1 (단순): $\hat{y} = 1.5x + 0.5$
- 편향: 높음 (실제 함수와 차이가 큼)
- 분산: 낮음 (항상 비슷한 예측)

모델 2 (복잡): 10차 다항식
- 편향: 낮음 (학습 데이터를 잘 맞춤)
- 분산: 높음 (데이터가 조금만 바뀌어도 크게 달라짐)

---

## 6. 그리드 서치를 사용한 머신 러닝 모델 세부 튜닝

### 이론

#### 6.1 하이퍼파라미터란?

**하이퍼파라미터 vs 파라미터:**

**파라미터** (학습으로 찾음):
- 신경망의 가중치
- 선형 회귀의 계수
- 예: $w_1, w_2, b$

**하이퍼파라미터** (사람이 설정):
- 학습률
- 정규화 강도
- 트리의 깊이
- 예: learning_rate, C, max_depth

#### 6.2 그리드 서치 (Grid Search)

**개념:**
가능한 모든 하이퍼파라미터 조합을 체계적으로 시도합니다.

**예시:**

```python
param_grid = {
    'C': [0.1, 1, 10],
    'kernel': ['linear', 'rbf']
}
```

**시도할 조합:**

| 조합 | C   | kernel  |
|-----|-----|---------|
| 1   | 0.1 | linear  |
| 2   | 0.1 | rbf     |
| 3   | 1   | linear  |
| 4   | 1   | rbf     |
| 5   | 10  | linear  |
| 6   | 10  | rbf     |

총 3 × 2 = 6가지 조합

**교차 검증과 함께:**

5-겹 교차 검증 사용 시:
- 총 학습 횟수 = 6 조합 × 5 folds = 30회

**시간 복잡도:**

$$T_{total} = n_{params} \times k_{folds} \times T_{train}$$

여기서:
- $n_{params}$: 하이퍼파라미터 조합 수
- $k_{folds}$: fold 수
- $T_{train}$: 한 번 학습하는 시간

#### 6.3 랜덤 서치 (Random Search)

**개념:**
무작위로 하이퍼파라미터 조합을 샘플링합니다.

**그리드 서치 vs 랜덤 서치:**

```
그리드 서치 (9번 시도):
[●][●][●]
[●][●][●]
[●][●][●]

랜덤 서치 (9번 시도):
[ ][●][ ]
[●][ ][●]
[ ][●][ ]
[●][ ][●]
[ ][●][ ]
```

**장점:**
1. 더 넓은 영역 탐색
2. 중요한 하이퍼파라미터에 더 많은 값 시도
3. 시간 제약이 있을 때 유용

**언제 사용하나요?**

**그리드 서치:**
- 하이퍼파라미터가 2-3개
- 좁은 범위 내에서 정확한 값 찾기
- 계산 자원이 충분함

**랜덤 서치:**
- 하이퍼파라미터가 많음 (4개 이상)
- 넓은 범위 탐색
- 계산 자원이 제한적

#### 6.4 수학적 분석: 왜 랜덤 서치가 효과적인가?

**중요한 하이퍼파라미터의 영향:**

하이퍼파라미터 A가 중요하고 B가 덜 중요할 때:

**그리드 서치 (각 3개 값):**
- A: 3개 고유 값 시도
- B: 3개 고유 값 시도

**랜덤 서치 (9번 시도):**
- A: 최대 9개 서로 다른 값 가능
- B: 최대 9개 서로 다른 값 가능

$\rightarrow$ 중요한 하이퍼파라미터에 더 많은 값 시도!

**수학적 확률:**

최적값 근처(±10%)에 도달할 확률:

그리드 서치 (3개 값):
$$P_{grid} = \frac{1}{3} \approx 0.33$$

랜덤 서치 (9번):
$$P_{random} = 1 - (1 - 0.2)^9 \approx 0.87$$

#### 6.5 연속적 반감 방식 (Successive Halving)

**개념:**
적은 자원으로 많은 조합을 평가한 후, 좋은 것만 더 많은 자원으로 재평가합니다.

**단계별 과정:**

```
Round 1: 64개 조합 × 1 epoch  → 상위 32개 선택
Round 2: 32개 조합 × 2 epochs → 상위 16개 선택
Round 3: 16개 조합 × 4 epochs → 상위 8개 선택
Round 4:  8개 조합 × 8 epochs → 상위 4개 선택
Round 5:  4개 조합 × 16 epochs → 최적 1개 선택
```

**자원 사용량 비교:**

그리드 서치: 64개 × 16 epochs = 1,024 epoch-runs

연속적 반감:
$$64×1 + 32×2 + 16×4 + 8×8 + 4×16 = 248 \text{ epoch-runs}$$

$\rightarrow$ 약 76% 자원 절약!

**수학적 표현:**

라운드 $r$에서:
- 조합 수: $\frac{n}{2^{r-1}}$
- 자원: $r_0 \times 2^{r-1}$

총 자원:
$$R_{total} = \sum_{r=1}^{R} \frac{n}{2^{r-1}} \times r_0 \times 2^{r-1} = n \times r_0 \times R$$

#### 6.6 중첩 교차 검증 (Nested Cross-Validation)

**목적:**
모델 선택과 성능 평가를 독립적으로 수행합니다.

**구조:**

```
외부 루프 (모델 평가):
  Fold 1, 2, 3, 4, 5

  각 외부 fold마다:
    내부 루프 (하이퍼파라미터 튜닝):
      Fold 1, 2, 3, 4
```

**단계:**

1. **외부 루프**: 데이터를 5개 fold로 분할
2. 각 외부 fold마다:
   - **내부 루프**: 학습 데이터를 다시 4개 fold로 분할
   - 내부 교차 검증으로 최적 하이퍼파라미터 찾기
   - 최적 모델로 외부 테스트 fold 평가

**왜 필요한가?**

**단순 교차 검증의 문제:**
```
전체 데이터에서 그리드 서치 → 최적 파라미터 찾음
같은 데이터로 교차 검증 → 성능 평가

→ 낙관적 편향! (같은 데이터 사용)
```

**중첩 교차 검증:**
```
내부: 하이퍼파라미터 튜닝용 데이터
외부: 성능 평가용 데이터 (독립적!)

→ 편향 없는 성능 추정
```

**계산 복잡도:**

5×4 중첩 교차 검증 + 10개 조합:
$$5 \times 4 \times 10 = 200 \text{ 회 학습}$$

---

## 7. 여러 가지 성능 평가 지표

### 이론

#### 7.1 오차 행렬 (Confusion Matrix)

**정의:**
분류 모델의 예측 결과를 실제 클래스와 비교한 표입니다.

**2×2 오차 행렬:**

```
                예측
           Positive  Negative
실제 Pos    TP         FN
     Neg    FP         TN
```

**용어 설명:**

- **TP (True Positive)**: 양성을 양성으로 정확히 예측
- **TN (True Negative)**: 음성을 음성으로 정확히 예측
- **FP (False Positive)**: 음성을 양성으로 잘못 예측 (1종 오류)
- **FN (False Negative)**: 양성을 음성으로 잘못 예측 (2종 오류)

**예제:**

100명의 환자 중:
- 실제 암 환자: 40명
- 실제 건강한 사람: 60명

모델 예측:
```
              예측
         암    건강
실제 암   35     5
    건강   10    50
```

- TP = 35 (암을 암으로 예측)
- FN = 5 (암을 건강으로 잘못 예측)
- FP = 10 (건강을 암으로 잘못 예측)
- TN = 50 (건강을 건강으로 예측)

#### 7.2 정확도 (Accuracy)

**정의:**
전체 예측 중 올바른 예측의 비율

**수식:**

$$Accuracy = \frac{TP + TN}{TP + TN + FP + FN}$$

**예제 계산:**

$$Accuracy = \frac{35 + 50}{35 + 50 + 10 + 5} = \frac{85}{100} = 0.85$$

**한계:**

불균형 데이터에서 문제 발생!

예: 암 환자 1%, 건강한 사람 99%
```
모든 것을 "건강"으로 예측
→ 정확도 = 99% (높아 보이지만 쓸모없음!)
```

#### 7.3 정밀도 (Precision)

**정의:**
양성으로 예측한 것 중 실제 양성의 비율

**수식:**

$$Precision = \frac{TP}{TP + FP}$$

**의미:**
"모델이 양성이라고 한 것 중 몇 %가 실제 양성인가?"

**예제 계산:**

$$Precision = \frac{35}{35 + 10} = \frac{35}{45} \approx 0.78$$

**언제 중요한가?**
- 거짓 양성(FP)의 비용이 클 때
- 예: 스팸 메일 필터 (정상 메일을 스팸으로 분류하면 안 됨)

#### 7.4 재현율 (Recall) = 민감도 (Sensitivity)

**정의:**
실제 양성 중 양성으로 예측한 비율

**수식:**

$$Recall = \frac{TP}{TP + FN}$$

**의미:**
"실제 양성 중 몇 %를 찾아냈는가?"

**예제 계산:**

$$Recall = \frac{35}{35 + 5} = \frac{35}{40} = 0.875$$

**언제 중요한가?**
- 거짓 음성(FN)의 비용이 클 때
- 예: 암 진단 (암 환자를 놓치면 안 됨)

#### 7.5 F1 점수 (F1-Score)

**정의:**
정밀도와 재현율의 조화 평균

**수식:**

$$F1 = 2 \times \frac{Precision \times Recall}{Precision + Recall}$$

**왜 조화 평균인가?**

산술 평균은 한쪽이 높으면 평균이 높아짐:
$$\frac{0.9 + 0.1}{2} = 0.5$$

조화 평균은 둘 다 높아야 높아짐:
$$\frac{2 \times 0.9 \times 0.1}{0.9 + 0.1} = 0.18$$

**예제 계산:**

$$F1 = 2 \times \frac{0.78 \times 0.875}{0.78 + 0.875} = 2 \times \frac{0.6825}{1.655} \approx 0.824$$

**일반화: F-beta 점수**

$$F_\beta = (1 + \beta^2) \times \frac{Precision \times Recall}{\beta^2 \times Precision + Recall}$$

- $\beta < 1$: 정밀도 중시
- $\beta = 1$: F1 점수 (균형)
- $\beta > 1$: 재현율 중시

#### 7.6 특이도 (Specificity)

**정의:**
실제 음성 중 음성으로 예측한 비율

**수식:**

$$Specificity = \frac{TN}{TN + FP}$$

**예제 계산:**

$$Specificity = \frac{50}{50 + 10} = \frac{50}{60} \approx 0.833$$

#### 7.7 ROC 곡선 (Receiver Operating Characteristic)

**정의:**
다양한 임계값에서 FPR과 TPR의 관계를 나타낸 곡선

**구성 요소:**

**TPR (True Positive Rate) = Recall:**
$$TPR = \frac{TP}{TP + FN}$$

**FPR (False Positive Rate):**
$$FPR = \frac{FP}{FP + TN} = 1 - Specificity$$

**ROC 곡선 그리기:**

1. 예측 확률을 기준으로 정렬
2. 각 임계값마다 TPR, FPR 계산
3. (FPR, TPR) 좌표 그리기

**예제:**

예측 확률: [0.9, 0.8, 0.6, 0.4, 0.3]
실제 라벨:  [1,   1,   0,   1,   0]

| 임계값 | TP | FP | FN | TN | TPR | FPR |
|-------|----|----|----|----|-----|-----|
| 0.0   | 3  | 2  | 0  | 0  | 1.0 | 1.0 |
| 0.5   | 2  | 1  | 1  | 1  | 0.67| 0.5 |
| 0.7   | 2  | 0  | 1  | 2  | 0.67| 0.0 |
| 1.0   | 0  | 0  | 3  | 2  | 0.0 | 0.0 |

```
TPR
 ^
1|    ●
 |   /
 |  ●
 | /
 |●
 +--------> FPR
0        1
```

**완벽한 모델:** (0,1) 좌측 상단 모서리
**무작위 모델:** 대각선
**나쁜 모델:** 대각선 아래

#### 7.8 AUC (Area Under the Curve)

**정의:**
ROC 곡선 아래 면적

**값의 범위:**
- 0.5: 무작위 예측
- 1.0: 완벽한 예측
- < 0.5: 무작위보다 못함

**해석:**

$$AUC = P(\text{양성 샘플의 점수} > \text{음성 샘플의 점수})$$

**수치적 계산:**

사다리꼴 법칙 사용:
$$AUC = \sum_{i=1}^{n-1} \frac{(TPR_i + TPR_{i+1})}{2} \times (FPR_{i+1} - FPR_i)$$

**예제:**

| FPR | TPR |
|-----|-----|
| 0.0 | 0.0 |
| 0.0 | 0.67|
| 0.5 | 0.67|
| 1.0 | 1.0 |

$$AUC = \frac{0 + 0.67}{2} \times 0 + \frac{0.67 + 0.67}{2} \times 0.5 + \frac{0.67 + 1}{2} \times 0.5$$
$$= 0 + 0.335 + 0.4175 = 0.7525$$

#### 7.9 다중 분류의 성능 지표

**3개 이상의 클래스가 있을 때:**

**오차 행렬 (3×3 예제):**

```
           예측
       고양이 개  새
실제 
고양이  50   5   2
개       3  40   4
새       2   3  41
```

**Macro 평균:**
각 클래스의 지표를 단순 평균

$$Macro\text{-}Precision = \frac{Precision_{cat} + Precision_{dog} + Precision_{bird}}{3}$$

**예제:**
- 고양이 Precision: 50/(50+3+2) = 0.909
- 개 Precision: 40/(5+40+3) = 0.833
- 새 Precision: 41/(2+4+41) = 0.872

$$Macro\text{-}Precision = \frac{0.909 + 0.833 + 0.872}{3} = 0.871$$

**Micro 평균:**
모든 TP, FP, FN을 합산 후 계산

$$Micro\text{-}Precision = \frac{\sum TP}{\sum TP + \sum FP}$$

**예제:**
$$Micro\text{-}Precision = \frac{50 + 40 + 41}{50 + 40 + 41 + 5 + 3 + 3 + 5 + 2 + 4} = \frac{131}{153} = 0.856$$

**언제 사용하나?**

- **Macro**: 모든 클래스를 동등하게 중요시
- **Micro**: 샘플이 많은 클래스에 가중치
- **Weighted**: 각 클래스를 샘플 수로 가중 평균

---

## 8. 불균형한 클래스 다루기

### 이론

#### 8.1 클래스 불균형 문제

**정의:**
한 클래스의 샘플이 다른 클래스보다 훨씬 많은 경우

**예제:**

신용카드 사기 탐지:
- 정상 거래: 99.8%
- 사기 거래: 0.2%

**문제점:**

모든 것을 "정상"으로 예측:
- 정확도 = 99.8% (높아 보임)
- 하지만 사기는 하나도 못 찾음!

**영향:**

1. 모델이 다수 클래스에 편향됨
2. 소수 클래스를 무시하는 경향
3. 정확도가 의미 없음

#### 8.2 해결 방법 1: 리샘플링

**1. 언더샘플링 (Under-sampling)**

다수 클래스의 샘플을 제거합니다.

```
변환 전:
클래스 0: ●●●●●●●●●● (100개)
클래스 1: ●● (10개)

변환 후:
클래스 0: ●●●●●●●●●● (10개)
클래스 1: ●● (10개)
```

**장점:**
- 학습 시간 단축
- 균형 잡힌 데이터

**단점:**
- 정보 손실
- 작은 데이터셋이 됨

**2. 오버샘플링 (Over-sampling)**

소수 클래스의 샘플을 복제합니다.

```
변환 전:
클래스 0: ●●●●●●●●●● (100개)
클래스 1: ●● (10개)

변환 후:
클래스 0: ●●●●●●●●●● (100개)
클래스 1: ●●●●●●●●●● (100개, 복제됨)
```

**장점:**
- 정보 손실 없음
- 균형 잡힌 데이터

**단점:**
- 과대적합 위험
- 학습 시간 증가

**3. SMOTE (Synthetic Minority Over-sampling TEchnique)**

소수 클래스의 새로운 합성 샘플을 생성합니다.

**알고리즘:**

1. 소수 클래스 샘플 하나 선택: $x_i$
2. k개의 최근접 이웃 찾기
3. 이웃 중 하나 무작위 선택: $x_{nn}$
4. 새 샘플 생성:
   $$x_{new} = x_i + \lambda \times (x_{nn} - x_i)$$
   여기서 $\lambda \in [0, 1]$은 무작위 값

**예제:**

원본 샘플들:
- $x_1 = [2, 3]$
- $x_2 = [3, 4]$ (최근접 이웃)

$\lambda = 0.5$일 때:
$$x_{new} = [2, 3] + 0.5 \times ([3, 4] - [2, 3])$$
$$= [2, 3] + 0.5 \times [1, 1]$$
$$= [2, 3] + [0.5, 0.5]$$
$$= [2.5, 3.5]$$

**장점:**
- 과대적합 위험 감소
- 더 일반화된 샘플

#### 8.3 해결 방법 2: 클래스 가중치

**개념:**
손실 함수에서 소수 클래스에 더 큰 가중치를 부여합니다.

**수식:**

일반 손실:
$$L = \sum_{i=1}^{n} loss(y_i, \hat{y}_i)$$

가중 손실:
$$L = \sum_{i=1}^{n} w_{y_i} \times loss(y_i, \hat{y}_i)$$

**가중치 계산:**

**균형 가중치:**
$$w_c = \frac{n}{k \times n_c}$$

여기서:
- $n$: 전체 샘플 수
- $k$: 클래스 수
- $n_c$: 클래스 $c$의 샘플 수

**예제:**

- 전체 샘플: 1000개
- 클래스 0: 900개
- 클래스 1: 100개

$$w_0 = \frac{1000}{2 \times 900} = 0.556$$
$$w_1 = \frac{1000}{2 \times 100} = 5.0$$

$\rightarrow$ 클래스 1의 오차가 9배 더 중요!

#### 8.4 해결 방법 3: 앙상블 방법

**1. Balanced Random Forest**

각 트리를 만들 때 다수 클래스를 언더샘플링합니다.

```
전체 데이터:
클래스 0: 900개
클래스 1: 100개

트리 1: 클래스 0에서 100개 샘플링 + 클래스 1 100개
트리 2: 클래스 0에서 다른 100개 샘플링 + 클래스 1 100개
...
트리 n: 클래스 0에서 또 다른 100개 샘플링 + 클래스 1 100개
```

**2. EasyEnsemble**

여러 개의 균형 잡힌 서브셋을 만들어 앙상블합니다.

#### 8.5 해결 방법 4: 적절한 평가 지표 선택

**불균형 데이터에서 사용할 지표:**

1. **F1-Score**: 정밀도와 재현율의 균형
2. **AUC-ROC**: 임계값에 무관한 평가
3. **PR 곡선**: Precision-Recall 곡선
4. **Cohen's Kappa**: 우연 일치를 보정한 정확도

**Cohen's Kappa:**

$$\kappa = \frac{p_o - p_e}{1 - p_e}$$

여기서:
- $p_o$: 관측된 일치도 (정확도)
- $p_e$: 우연 일치 확률

**예제:**

오차 행렬:
```
         예측
      0    1
실제 0  90   10
    1   5   95
```

$$p_o = \frac{90 + 95}{200} = 0.925$$

우연 일치:
$$p_e = \frac{(90+10) \times (90+5)}{200 \times 200} + \frac{(5+95) \times (10+95)}{200 \times 200}$$
$$= \frac{100 \times 95}{40000} + \frac{100 \times 105}{40000}$$
$$= 0.2375 + 0.2625 = 0.5$$

$$\kappa = \frac{0.925 - 0.5}{1 - 0.5} = \frac{0.425}{0.5} = 0.85$$

**해석:**
- $\kappa = 1$: 완벽한 일치
- $\kappa = 0$: 우연 수준
- $\kappa < 0$: 우연보다 못함

#### 8.6 해결 방법 5: 임계값 조정

**기본 임계값:**
확률 > 0.5 → 양성

**조정된 임계값:**
확률 > 0.3 → 양성 (재현율 증가)
확률 > 0.7 → 양성 (정밀도 증가)

**최적 임계값 찾기:**

1. ROC 곡선 그리기
2. Youden's J statistic 사용:
   $$J = Sensitivity + Specificity - 1$$
3. J를 최대화하는 임계값 선택

**예제:**

| 임계값 | TPR | FPR | J = TPR - FPR |
|-------|-----|-----|---------------|
| 0.3   | 0.95| 0.60| 0.35          |
| 0.5   | 0.80| 0.30| 0.50 ← 최적   |
| 0.7   | 0.60| 0.10| 0.50          |

---

## 요약

### 핵심 개념 정리

1. **파이프라인**: 전처리와 모델을 하나로 묶어 데이터 누수 방지
2. **교차 검증**: 모든 데이터를 활용한 신뢰성 있는 성능 평가
3. **학습/검증 곡선**: 편향과 분산 문제 진단
4. **그리드/랜덤 서치**: 최적 하이퍼파라미터 탐색
5. **다양한 지표**: 문제에 맞는 평가 지표 선택
6. **불균형 처리**: 리샘플링, 가중치, 앙상블로 해결

### 실무 체크리스트

- [ ] 파이프라인으로 전체 워크플로 구성
- [ ] 교차 검증으로 성능 평가 (최소 5-겹)
- [ ] 학습 곡선으로 더 많은 데이터 필요성 확인
- [ ] 검증 곡선으로 하이퍼파라미터 범위 파악
- [ ] 그리드/랜덤 서치로 세부 튜닝
- [ ] 문제에 맞는 평가 지표 사용
- [ ] 클래스 불균형 확인 및 처리
- [ ] 중첩 교차 검증으로 최종 성능 확인

### 다음 단계

실습 파일 `06_model_evaluation.py`에서 이론을 코드로 구현해봅시다!

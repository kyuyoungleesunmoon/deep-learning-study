# ğŸ“– Chapter 10: ê²€ìƒ‰ ì¦ê°• ìƒì„± (RAG)ê³¼ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰

## ğŸ“‹ ê°œìš”

ì´ ì±•í„°ì—ì„œëŠ” RAG(Retrieval-Augmented Generation)ì˜ í•µì‹¬ ê²€ìƒ‰ ê¸°ë²•ë“¤ì„ í•™ìŠµí•©ë‹ˆë‹¤.
- ë²¡í„° ê¸°ë°˜ ë°€ì§‘ ê²€ìƒ‰ (Dense Vector Search)
- BM25 í‚¤ì›Œë“œ ê¸°ë°˜ í¬ì†Œ ê²€ìƒ‰ (Sparse Search)
- ë‘ ë°©ì‹ì„ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (Hybrid Search)

## ğŸ”¬ í•µì‹¬ ì•Œê³ ë¦¬ì¦˜

### 1. Dense Vector Search (ë°€ì§‘ ë²¡í„° ê²€ìƒ‰)

**ì›ë¦¬**: ë¬¸ì¥ì„ ê³ ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜í•˜ê³ , ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¡œ ì˜ë¯¸ì  ìœ ì‚¬ì„±ì„ ì¸¡ì •í•©ë‹ˆë‹¤.

```
similarity(q, d) = cos(Î¸) = (q Â· d) / (||q|| Ã— ||d||)
```

**ì¥ì **:
- ì˜ë¯¸ì  ìœ ì‚¬ì„± í¬ì°© (ë™ì˜ì–´, íŒ¨ëŸ¬í”„ë ˆì´ì¦ˆ)
- "ë¹„ê°€ ì˜¨ë‹¤" â†” "ì¥ë§ˆê°€ ì‹œì‘ëë‹¤" ì—°ê²° ê°€ëŠ¥

**ë‹¨ì **:
- ê³ ìœ ëª…ì‚¬, ìˆ«ì ë“± ì •í™•í•œ ë§¤ì¹­ì— ì•½í•¨

### 2. BM25 (Best Match 25)

**ì›ë¦¬**: TF-IDFì˜ ê°œì„  ë²„ì „ìœ¼ë¡œ, ë¬¸ì„œ ë‚´ ë‹¨ì–´ ë¹ˆë„ì™€ í¬ì†Œì„±ì„ ê³ ë ¤í•©ë‹ˆë‹¤.

```
BM25(D, Q) = Î£ IDF(qi) Ã— (f(qi, D) Ã— (k1 + 1)) / (f(qi, D) + k1 Ã— (1 - b + b Ã— |D|/avgdl))
```

**ìˆ˜ì‹ ì„¤ëª…**:
- `IDF(qi)`: ë‹¨ì–´ qiì˜ ì—­ë¬¸ì„œ ë¹ˆë„ (ë“œë¬¸ ë‹¨ì–´ì¼ìˆ˜ë¡ ë†’ìŒ)
- `f(qi, D)`: ë¬¸ì„œ Dì—ì„œ ë‹¨ì–´ qiì˜ ì¶œí˜„ ë¹ˆë„
- `k1`: í¬í™” íŒŒë¼ë¯¸í„° (ë³´í†µ 1.2~2.0)
- `b`: ë¬¸ì„œ ê¸¸ì´ ì •ê·œí™” íŒŒë¼ë¯¸í„° (ë³´í†µ 0.75)
- `avgdl`: ì „ì²´ ë¬¸ì„œì˜ í‰ê·  ê¸¸ì´

**ì¥ì **:
- ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­
- "ë¡œë²„íŠ¸ í—¨ë¦¬ ë”•" ê°™ì€ ê³ ìœ ëª…ì‚¬ ê²€ìƒ‰ì— ê°•í•¨

**ë‹¨ì **:
- ì˜ë¯¸ì  ìœ ì‚¬ì„± í¬ì°© ë¶ˆê°€
- "ë¹„" â†” "ì¥ë§ˆ" ì—°ê²° ì–´ë ¤ì›€

### 3. Reciprocal Rank Fusion (RRF)

**ì›ë¦¬**: ì—¬ëŸ¬ ê²€ìƒ‰ ê²°ê³¼ì˜ ìˆœìœ„ë¥¼ í†µí•©í•˜ì—¬ ìµœì¢… ë­í‚¹ì„ ìƒì„±í•©ë‹ˆë‹¤.

```
RRF(d) = Î£ 1 / (k + rank_i(d))
```

**ìˆ˜ì‹ ì„¤ëª…**:
- `d`: ë¬¸ì„œ
- `k`: ìƒìˆ˜ (ë³´í†µ 60)
- `rank_i(d)`: ië²ˆì§¸ ê²€ìƒ‰ì—ì„œ ë¬¸ì„œ dì˜ ìˆœìœ„

**ì¥ì **:
- ë‹¤ì–‘í•œ ê²€ìƒ‰ ë°©ì‹ì˜ ì¥ì  ê²°í•©
- ì ìˆ˜ ìŠ¤ì¼€ì¼ì´ ë‹¤ë¥¸ ê²€ìƒ‰ ê²°ê³¼ë„ í†µí•© ê°€ëŠ¥

## ğŸ“Š ì‹¤ìŠµ ì˜ˆì œ

### ì˜ˆì œ 1: ë¬¸ì¥ ì„ë² ë”©ìœ¼ë¡œ ë²¡í„° ê²€ìƒ‰

```python
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np

# í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')

# ì˜ˆì‹œ ë¬¸ì„œ
documents = [
    "ì˜¬í•´ ì—¬ë¦„ ì¥ë§ˆê°€ ì‹œì‘ëë‹¤",
    "í”„ë¦°ìŠ¤í„´ ëŒ€í•™êµì—ì„œ í•™ìœ„ë¥¼ ë°›ì•˜ë‹¤",
    "ê°¤ëŸ­ì‹œ S5ê°€ ì¶œì‹œëë‹¤"
]

# ë¬¸ì„œ ì„ë² ë”©
doc_embeddings = model.encode(documents)

# FAISS ì¸ë±ìŠ¤ ìƒì„±
dimension = doc_embeddings.shape[1]
index = faiss.IndexFlatL2(dimension)
index.add(doc_embeddings.astype('float32'))

# ì¿¼ë¦¬ ê²€ìƒ‰
query = "ë¹„ê°€ ë§ì´ ì˜¬ ì‹œê¸°ëŠ”?"
query_embedding = model.encode([query])
distances, indices = index.search(query_embedding.astype('float32'), k=3)

print("ê²€ìƒ‰ ê²°ê³¼:")
for i, (dist, idx) in enumerate(zip(distances[0], indices[0])):
    print(f"{i+1}. {documents[idx]} (ê±°ë¦¬: {dist:.4f})")
```

### ì˜ˆì œ 2: BM25 ê²€ìƒ‰ êµ¬í˜„

```python
import math
from collections import defaultdict
from transformers import AutoTokenizer

class SimpleBM25:
    def __init__(self, documents, k1=1.2, b=0.75):
        self.tokenizer = AutoTokenizer.from_pretrained('klue/roberta-base')
        self.k1 = k1
        self.b = b
        self.documents = documents
        self.tokenized_docs = [
            self.tokenizer.tokenize(doc) for doc in documents
        ]
        self.avg_doc_len = sum(len(d) for d in self.tokenized_docs) / len(self.tokenized_docs)
        self.idf = self._compute_idf()
    
    def _compute_idf(self):
        idf = defaultdict(float)
        N = len(self.tokenized_docs)
        
        # ê° ë‹¨ì–´ì˜ ë¬¸ì„œ ë¹ˆë„ ê³„ì‚°
        df = defaultdict(int)
        for doc in self.tokenized_docs:
            for token in set(doc):
                df[token] += 1
        
        # IDF ê³„ì‚°
        for token, freq in df.items():
            idf[token] = math.log((N - freq + 0.5) / (freq + 0.5) + 1)
        
        return idf
    
    def score(self, query):
        query_tokens = self.tokenizer.tokenize(query)
        scores = []
        
        for doc in self.tokenized_docs:
            score = 0
            doc_len = len(doc)
            
            # ë‹¨ì–´ ë¹ˆë„ ê³„ì‚°
            tf = defaultdict(int)
            for token in doc:
                tf[token] += 1
            
            for token in query_tokens:
                if token in tf:
                    freq = tf[token]
                    numerator = self.idf[token] * freq * (self.k1 + 1)
                    denominator = freq + self.k1 * (1 - self.b + self.b * doc_len / self.avg_doc_len)
                    score += numerator / denominator
            
            scores.append(score)
        
        return scores

# ì‚¬ìš© ì˜ˆì‹œ
documents = ["ë¡œë²„íŠ¸ í—¨ë¦¬ ë”•ì´ 1946ë…„ì— ì—°êµ¬í–ˆë‹¤", "2023ë…„ AI ê¸°ìˆ ì´ ë°œì „í–ˆë‹¤", "í”„ë¦°ìŠ¤í„´ ëŒ€í•™êµ"]
bm25 = SimpleBM25(documents)
query = "ë¡œë²„íŠ¸ í—¨ë¦¬ ë”• ì—°êµ¬"
scores = bm25.score(query)
print(f"BM25 ì ìˆ˜: {scores}")
```

### ì˜ˆì œ 3: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰

```python
def reciprocal_rank_fusion(rankings, k=60):
    """
    ì—¬ëŸ¬ ê²€ìƒ‰ ê²°ê³¼ì˜ ìˆœìœ„ë¥¼ RRFë¡œ í†µí•©
    
    Args:
        rankings: ê° ê²€ìƒ‰ ë°©ì‹ì˜ ë¬¸ì„œ ì¸ë±ìŠ¤ ìˆœìœ„ ë¦¬ìŠ¤íŠ¸
        k: ìƒìˆ˜ (ê¸°ë³¸ê°’ 60)
    
    Returns:
        í†µí•© ì ìˆ˜ë¡œ ì •ë ¬ëœ (ë¬¸ì„œì¸ë±ìŠ¤, ì ìˆ˜) ë¦¬ìŠ¤íŠ¸
    """
    rrf_scores = defaultdict(float)
    
    for ranking in rankings:
        for rank, doc_id in enumerate(ranking, 1):
            rrf_scores[doc_id] += 1.0 / (k + rank)
    
    return sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)

def hybrid_search(query, dense_ranking, sparse_ranking, k=60):
    """
    Dense(ë²¡í„°)ì™€ Sparse(BM25) ê²€ìƒ‰ ê²°ê³¼ í†µí•©
    """
    results = reciprocal_rank_fusion([dense_ranking, sparse_ranking], k=k)
    return results

# ì‚¬ìš© ì˜ˆì‹œ
# ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ (ë¬¸ì„œ ì¸ë±ìŠ¤): [2, 0, 1] (2ë²ˆ ë¬¸ì„œê°€ 1ìœ„)
# BM25 ê²€ìƒ‰ ê²°ê³¼ (ë¬¸ì„œ ì¸ë±ìŠ¤): [0, 2, 1] (0ë²ˆ ë¬¸ì„œê°€ 1ìœ„)
dense_ranking = [2, 0, 1]
sparse_ranking = [0, 2, 1]

final_ranking = hybrid_search("ê²€ìƒ‰ ì¿¼ë¦¬", dense_ranking, sparse_ranking)
print(f"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê²°ê³¼: {final_ranking}")
```

## ğŸ¯ í•µì‹¬ í¬ì¸íŠ¸

1. **Dense Search**: ì˜ë¯¸ì  ìœ ì‚¬ì„±ì— ê°•í•¨ â†’ ì§ˆë¬¸-ë‹µë³€, íŒ¨ëŸ¬í”„ë ˆì´ì¦ˆ ê²€ìƒ‰
2. **BM25**: ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­ì— ê°•í•¨ â†’ ê³ ìœ ëª…ì‚¬, íŠ¹ì • ìš©ì–´ ê²€ìƒ‰
3. **Hybrid Search**: ë‘ ë°©ì‹ì˜ ì¥ì ì„ ê²°í•© â†’ ì‹¤ë¬´ì—ì„œ ê°€ì¥ íš¨ê³¼ì 

## ğŸ“š ì°¸ê³  ìë£Œ

- ì›ë³¸ ì½”ë“œ: https://github.com/onlybooks/llm/tree/main/10ì¥
- FAISS ë¬¸ì„œ: https://faiss.ai/
- Sentence-Transformers: https://www.sbert.net/

"""
Chapter 10: RAGì™€ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤ìŠµ ì½”ë“œ
=============================================

ì´ íŒŒì¼ì€ ê²€ìƒ‰ ì¦ê°• ìƒì„±(RAG)ì˜ í•µì‹¬ ê²€ìƒ‰ ê¸°ë²•ë“¤ì„ ì‹¤ìŠµí•©ë‹ˆë‹¤:
1. Dense Vector Search (ë²¡í„° ê²€ìƒ‰)
2. BM25 (í‚¤ì›Œë“œ ê²€ìƒ‰)
3. Hybrid Search (í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰)

ì‹¤í–‰ ë°©ë²•:
    pip install sentence-transformers faiss-cpu transformers torch
    python chapter_10_practice.py
"""

import math
import numpy as np
from collections import defaultdict
from typing import List, Tuple, Dict
from dataclasses import dataclass


# ============================================================
# Part 1: ê°„ë‹¨í•œ ë²¡í„° ê²€ìƒ‰ (FAISS ì—†ì´ë„ ë™ì‘í•˜ëŠ” ë²„ì „)
# ============================================================

def cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) -> float:
    """ë‘ ë²¡í„° ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
    dot_product = np.dot(vec1, vec2)
    norm1 = np.linalg.norm(vec1)
    norm2 = np.linalg.norm(vec2)
    
    if norm1 == 0 or norm2 == 0:
        return 0.0
    
    return dot_product / (norm1 * norm2)


def simple_dense_search(query_embedding: np.ndarray, 
                        doc_embeddings: np.ndarray, 
                        k: int = 3) -> List[Tuple[int, float]]:
    """
    ê°„ë‹¨í•œ ë²¡í„° ê²€ìƒ‰ êµ¬í˜„
    
    Args:
        query_embedding: ì¿¼ë¦¬ ë²¡í„°
        doc_embeddings: ë¬¸ì„œ ë²¡í„°ë“¤
        k: ë°˜í™˜í•  ìƒìœ„ kê°œ ê²°ê³¼
    
    Returns:
        (ë¬¸ì„œ ì¸ë±ìŠ¤, ìœ ì‚¬ë„ ì ìˆ˜) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
    """
    similarities = []
    for idx, doc_emb in enumerate(doc_embeddings):
        sim = cosine_similarity(query_embedding, doc_emb)
        similarities.append((idx, sim))
    
    # ìœ ì‚¬ë„ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    similarities.sort(key=lambda x: x[1], reverse=True)
    return similarities[:k]


# ============================================================
# Part 2: BM25 ê²€ìƒ‰ êµ¬í˜„
# ============================================================

class BM25:
    """
    BM25 ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„
    
    BM25ëŠ” TF-IDFì˜ ê°œì„  ë²„ì „ìœ¼ë¡œ, ë‹¤ìŒ ìš”ì†Œë¥¼ ê³ ë ¤í•©ë‹ˆë‹¤:
    - ë‹¨ì–´ ë¹ˆë„ (Term Frequency)
    - ì—­ë¬¸ì„œ ë¹ˆë„ (Inverse Document Frequency)
    - ë¬¸ì„œ ê¸¸ì´ ì •ê·œí™”
    """
    
    def __init__(self, corpus: List[str], k1: float = 1.2, b: float = 0.75):
        """
        Args:
            corpus: ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
            k1: í¬í™” íŒŒë¼ë¯¸í„° (1.2 ~ 2.0 ê¶Œì¥)
            b: ë¬¸ì„œ ê¸¸ì´ ì •ê·œí™” íŒŒë¼ë¯¸í„° (0.75 ê¶Œì¥)
        """
        self.k1 = k1
        self.b = b
        self.corpus = corpus
        
        # ê°„ë‹¨í•œ í† í¬ë‚˜ì´ì € (ê³µë°± ê¸°ë°˜)
        self.tokenized_corpus = [doc.lower().split() for doc in corpus]
        self.n_docs = len(self.tokenized_corpus)
        self.avg_doc_len = sum(len(doc) for doc in self.tokenized_corpus) / self.n_docs
        
        # IDFì™€ TF ê³„ì‚°
        self.idf = self._calculate_idf()
        self.term_freqs = self._calculate_term_freqs()
    
    def _calculate_idf(self) -> Dict[str, float]:
        """IDF (ì—­ë¬¸ì„œ ë¹ˆë„) ê³„ì‚°"""
        idf = defaultdict(float)
        
        # ê° ë‹¨ì–´ì˜ ë¬¸ì„œ ë¹ˆë„ ê³„ì‚°
        for doc in self.tokenized_corpus:
            for token in set(doc):
                idf[token] += 1
        
        # IDF ê³„ì‚°: log((N - df + 0.5) / (df + 0.5) + 1)
        for token, doc_freq in idf.items():
            idf[token] = math.log(
                ((self.n_docs - doc_freq + 0.5) / (doc_freq + 0.5)) + 1
            )
        
        return dict(idf)
    
    def _calculate_term_freqs(self) -> List[Dict[str, int]]:
        """ê° ë¬¸ì„œë³„ ë‹¨ì–´ ë¹ˆë„ ê³„ì‚°"""
        term_freqs = []
        for doc in self.tokenized_corpus:
            tf = defaultdict(int)
            for token in doc:
                tf[token] += 1
            term_freqs.append(dict(tf))
        return term_freqs
    
    def get_scores(self, query: str) -> np.ndarray:
        """
        ì¿¼ë¦¬ì— ëŒ€í•œ ëª¨ë“  ë¬¸ì„œì˜ BM25 ì ìˆ˜ ê³„ì‚°
        
        BM25 ê³µì‹:
        score(D, Q) = Î£ IDF(qi) Ã— (f(qi,D) Ã— (k1+1)) / (f(qi,D) + k1 Ã— (1 - b + b Ã— |D|/avgdl))
        """
        query_tokens = query.lower().split()
        scores = np.zeros(self.n_docs)
        
        for i, (doc_tf, doc_tokens) in enumerate(zip(self.term_freqs, self.tokenized_corpus)):
            doc_len = len(doc_tokens)
            score = 0.0
            
            for q_token in query_tokens:
                if q_token not in self.idf:
                    continue
                
                idf = self.idf[q_token]
                freq = doc_tf.get(q_token, 0)
                
                # BM25 ì ìˆ˜ ê³„ì‚°
                numerator = idf * freq * (self.k1 + 1)
                denominator = freq + self.k1 * (1 - self.b + self.b * doc_len / self.avg_doc_len)
                score += numerator / denominator
            
            scores[i] = score
        
        return scores
    
    def get_top_k(self, query: str, k: int = 3) -> List[Tuple[int, float]]:
        """ìƒìœ„ kê°œ ë¬¸ì„œ ë°˜í™˜"""
        scores = self.get_scores(query)
        top_k_indices = np.argsort(scores)[-k:][::-1]
        return [(idx, scores[idx]) for idx in top_k_indices]


# ============================================================
# Part 3: Reciprocal Rank Fusion (RRF)
# ============================================================

def reciprocal_rank_fusion(rankings: List[List[int]], k: int = 60) -> List[Tuple[int, float]]:
    """
    Reciprocal Rank Fusionìœ¼ë¡œ ì—¬ëŸ¬ ê²€ìƒ‰ ê²°ê³¼ í†µí•©
    
    RRF ê³µì‹: RRF(d) = Î£ 1 / (k + rank(d))
    
    Args:
        rankings: ê° ê²€ìƒ‰ ë°©ì‹ì˜ ë¬¸ì„œ ì¸ë±ìŠ¤ ìˆœìœ„ ë¦¬ìŠ¤íŠ¸
                  ì˜ˆ: [[2, 0, 1], [0, 2, 1]] - ë‘ ê²€ìƒ‰ ê²°ê³¼
        k: ìƒìˆ˜ (ê¸°ë³¸ê°’ 60)
    
    Returns:
        í†µí•© ì ìˆ˜ë¡œ ì •ë ¬ëœ (ë¬¸ì„œì¸ë±ìŠ¤, ì ìˆ˜) ë¦¬ìŠ¤íŠ¸
    """
    rrf_scores = defaultdict(float)
    
    for ranking in rankings:
        for rank, doc_id in enumerate(ranking, 1):  # 1ë¶€í„° ì‹œì‘
            rrf_scores[doc_id] += 1.0 / (k + rank)
    
    # ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    return sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)


# ============================================================
# Part 4: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
# ============================================================

@dataclass
class SearchResult:
    """ê²€ìƒ‰ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    doc_index: int
    document: str
    score: float
    method: str


class HybridSearcher:
    """
    Dense Searchì™€ BM25ë¥¼ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸°
    """
    
    def __init__(self, documents: List[str]):
        self.documents = documents
        self.bm25 = BM25(documents)
        
        # ê°„ë‹¨í•œ ì„ë² ë”© (ì‹¤ì œë¡œëŠ” Sentence-Transformers ì‚¬ìš©)
        # ì—¬ê¸°ì„œëŠ” ë°ëª¨ìš©ìœ¼ë¡œ ëœë¤ ë²¡í„° ì‚¬ìš©
        np.random.seed(42)
        self.doc_embeddings = np.random.randn(len(documents), 128)
        # ì •ê·œí™”
        self.doc_embeddings = self.doc_embeddings / np.linalg.norm(
            self.doc_embeddings, axis=1, keepdims=True
        )
    
    def dense_search(self, query: str, k: int = 10) -> List[int]:
        """ë²¡í„° ê²€ìƒ‰ (ë°ëª¨ìš© ëœë¤ ì¿¼ë¦¬ ë²¡í„°)"""
        np.random.seed(hash(query) % 2**31)
        query_embedding = np.random.randn(128)
        query_embedding = query_embedding / np.linalg.norm(query_embedding)
        
        results = simple_dense_search(query_embedding, self.doc_embeddings, k)
        return [idx for idx, _ in results]
    
    def sparse_search(self, query: str, k: int = 10) -> List[int]:
        """BM25 ê²€ìƒ‰"""
        results = self.bm25.get_top_k(query, k)
        return [idx for idx, _ in results]
    
    def hybrid_search(self, query: str, k: int = 10, rrf_k: int = 60) -> List[SearchResult]:
        """
        í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆ˜í–‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            rrf_k: RRF ìƒìˆ˜
        
        Returns:
            SearchResult ë¦¬ìŠ¤íŠ¸
        """
        # ë‘ ê²€ìƒ‰ ë°©ì‹ ìˆ˜í–‰
        dense_ranking = self.dense_search(query, k=k)
        sparse_ranking = self.sparse_search(query, k=k)
        
        # RRFë¡œ í†µí•©
        fused_results = reciprocal_rank_fusion([dense_ranking, sparse_ranking], k=rrf_k)
        
        # SearchResult ìƒì„±
        results = []
        for doc_idx, score in fused_results[:k]:
            results.append(SearchResult(
                doc_index=doc_idx,
                document=self.documents[doc_idx],
                score=score,
                method="hybrid"
            ))
        
        return results


# ============================================================
# Part 5: ë°ëª¨ ì‹¤í–‰
# ============================================================

def demo_bm25():
    """BM25 ê²€ìƒ‰ ë°ëª¨"""
    print("\n" + "="*60)
    print("ğŸ“Š BM25 ê²€ìƒ‰ ë°ëª¨")
    print("="*60)
    
    documents = [
        "ì˜¬í•´ ì—¬ë¦„ ì¥ë§ˆê°€ 17ì¼ ì œì£¼ë„ì—ì„œ ì‹œì‘ëë‹¤ ì„œìš¸ ì¤‘ë¶€ì§€ë°©ì€ ì˜ˆë…„ë³´ë‹¤ ëŠ¦ë‹¤",
        "ê°¤ëŸ­ì‹œ S5 ì–¸ì œ ë°œë§¤í•œë‹¤ëŠ” ê±´ì§€ 27ì¼ íŒë§¤í•œë‹¤ê³  í–ˆë‹¤ê°€ 26ì¼ íŒë§¤í•œë‹¤",
        "ë¡œë²„íŠ¸ í—¨ë¦¬ ë”•ì´ 1946ë…„ì— ë§¤ì‚¬ì¶”ì„¸ì¸  ì—°êµ¬ì†Œì—ì„œ ì—°êµ¬í–ˆë‹¤",
        "í”„ë¦°ìŠ¤í„´ ëŒ€í•™êµì—ì„œ í•™ì‚¬ í•™ìœ„ë¥¼ ë§ˆì¹˜ê³  1939ë…„ì— ë¡œì²´ìŠ¤í„°ë¡œ ê°”ë‹¤",
        "ì¸êµ¬ ë¹„ìœ¨ë‹¹ ë…¸ë²¨ìƒì„ ê°€ì¥ ë§ì´ ë°›ì€ ë‚˜ë¼"
    ]
    
    bm25 = BM25(documents)
    
    queries = [
        "ë¹„ê°€ ì–¸ì œ ì˜¬ê¹Œ",
        "ë¡œë²„íŠ¸ í—¨ë¦¬ ë”• ì—°êµ¬"
    ]
    
    for query in queries:
        print(f"\nğŸ” ì¿¼ë¦¬: '{query}'")
        results = bm25.get_top_k(query, k=3)
        for rank, (idx, score) in enumerate(results, 1):
            print(f"  {rank}. [ì ìˆ˜: {score:.4f}] {documents[idx][:50]}...")


def demo_rrf():
    """Reciprocal Rank Fusion ë°ëª¨"""
    print("\n" + "="*60)
    print("ğŸ”— Reciprocal Rank Fusion ë°ëª¨")
    print("="*60)
    
    # ë‘ ê²€ìƒ‰ ë°©ì‹ì˜ ê²°ê³¼ (ë¬¸ì„œ ì¸ë±ìŠ¤ ìˆœìœ„)
    dense_ranking = [1, 4, 3, 5, 6]  # ë²¡í„° ê²€ìƒ‰: 1ë²ˆ ë¬¸ì„œê°€ 1ìœ„
    sparse_ranking = [2, 1, 3, 6, 4]  # BM25 ê²€ìƒ‰: 2ë²ˆ ë¬¸ì„œê°€ 1ìœ„
    
    print(f"Dense ê²€ìƒ‰ ìˆœìœ„: {dense_ranking}")
    print(f"Sparse ê²€ìƒ‰ ìˆœìœ„: {sparse_ranking}")
    
    fused = reciprocal_rank_fusion([dense_ranking, sparse_ranking], k=5)
    
    print("\ní†µí•© ê²°ê³¼ (RRF):")
    for doc_id, score in fused:
        print(f"  ë¬¸ì„œ {doc_id}: RRF ì ìˆ˜ = {score:.6f}")


def demo_hybrid():
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë°ëª¨"""
    print("\n" + "="*60)
    print("ğŸ”€ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë°ëª¨")
    print("="*60)
    
    documents = [
        "ì˜¬í•´ ì—¬ë¦„ ì¥ë§ˆê°€ ì‹œì‘ëë‹¤. ë¹„ê°€ ë§ì´ ì˜¬ ì˜ˆì •ì´ë‹¤.",
        "ë¡œë²„íŠ¸ í—¨ë¦¬ ë”•ì´ 1946ë…„ì— ë§¤ì‚¬ì¶”ì„¸ì¸ ì—ì„œ ì—°êµ¬í–ˆë‹¤.",
        "ê°¤ëŸ­ì‹œ S5ê°€ 27ì¼ì— ë°œë§¤ëœë‹¤.",
        "í”„ë¦°ìŠ¤í„´ ëŒ€í•™êµì—ì„œ í•™ìœ„ë¥¼ ë°›ì•˜ë‹¤.",
        "ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì´ ë¹ ë¥´ê²Œ ë°œì „í•˜ê³  ìˆë‹¤."
    ]
    
    searcher = HybridSearcher(documents)
    
    query = "ë¹„ê°€ ì–¸ì œ ì˜¬ê¹Œ"
    print(f"\nğŸ” ì¿¼ë¦¬: '{query}'")
    
    # ê° ê²€ìƒ‰ ë°©ì‹ ê²°ê³¼ ì¶œë ¥
    dense_results = searcher.dense_search(query, k=3)
    sparse_results = searcher.sparse_search(query, k=3)
    hybrid_results = searcher.hybrid_search(query, k=3)
    
    print("\n[Dense ê²€ìƒ‰ ê²°ê³¼]")
    for rank, idx in enumerate(dense_results, 1):
        print(f"  {rank}. {documents[idx][:40]}...")
    
    print("\n[BM25 ê²€ìƒ‰ ê²°ê³¼]")
    for rank, idx in enumerate(sparse_results, 1):
        print(f"  {rank}. {documents[idx][:40]}...")
    
    print("\n[í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê²°ê³¼]")
    for rank, result in enumerate(hybrid_results, 1):
        print(f"  {rank}. [ì ìˆ˜: {result.score:.6f}] {result.document[:40]}...")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("="*60)
    print("ğŸ¤– Chapter 10: RAGì™€ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤ìŠµ")
    print("="*60)
    
    demo_bm25()
    demo_rrf()
    demo_hybrid()
    
    print("\n" + "="*60)
    print("âœ… ì‹¤ìŠµ ì™„ë£Œ!")
    print("="*60)


if __name__ == "__main__":
    main()

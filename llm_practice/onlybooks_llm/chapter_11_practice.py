"""
Chapter 11: ë¬¸ì¥ ì„ë² ë”© ì‹¤ìŠµ ì½”ë“œ
=================================

ì´ íŒŒì¼ì€ ë¬¸ì¥ ì„ë² ë”©(Sentence Embeddings)ì„ ì‹¤ìŠµí•©ë‹ˆë‹¤:
1. ì§ì ‘ êµ¬í˜„í•œ Mean Pooling
2. ë¬¸ì¥ ìœ ì‚¬ë„ ê³„ì‚°
3. ìœ ì‚¬ ë¬¸ì¥ ê²€ìƒ‰
4. (ì„ íƒ) Sentence-Transformers í™œìš©

ì‹¤í–‰ ë°©ë²•:
    pip install numpy torch transformers
    python chapter_11_practice.py

    # Sentence-Transformers ì‚¬ìš© ì‹œ:
    pip install sentence-transformers
"""

import numpy as np
from typing import List, Tuple, Dict
from dataclasses import dataclass


# ============================================================
# Part 1: ê¸°ë³¸ ë²¡í„° ì—°ì‚°
# ============================================================

def cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) -> float:
    """ë‘ ë²¡í„° ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
    dot_product = np.dot(vec1, vec2)
    norm1 = np.linalg.norm(vec1)
    norm2 = np.linalg.norm(vec2)
    
    if norm1 == 0 or norm2 == 0:
        return 0.0
    
    return dot_product / (norm1 * norm2)


def euclidean_distance(vec1: np.ndarray, vec2: np.ndarray) -> float:
    """ë‘ ë²¡í„° ê°„ì˜ ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°"""
    return np.sqrt(np.sum((vec1 - vec2) ** 2))


def normalize_vectors(vectors: np.ndarray) -> np.ndarray:
    """ë²¡í„° ì •ê·œí™” (L2 norm = 1)"""
    norms = np.linalg.norm(vectors, axis=1, keepdims=True)
    norms = np.where(norms == 0, 1, norms)  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
    return vectors / norms


# ============================================================
# Part 2: Mean Pooling êµ¬í˜„
# ============================================================

def mean_pooling_simple(token_embeddings: np.ndarray, 
                        attention_mask: np.ndarray) -> np.ndarray:
    """
    Mean Pooling êµ¬í˜„ (NumPy ë²„ì „)
    
    Args:
        token_embeddings: (batch_size, seq_len, hidden_dim) í† í° ì„ë² ë”©
        attention_mask: (batch_size, seq_len) ì–´í…ì…˜ ë§ˆìŠ¤í¬ (1=ìœ íš¨, 0=íŒ¨ë”©)
    
    Returns:
        (batch_size, hidden_dim) ë¬¸ì¥ ì„ë² ë”©
    """
    # Attention mask í™•ì¥: (batch, seq_len) -> (batch, seq_len, hidden)
    input_mask_expanded = attention_mask[:, :, np.newaxis]
    
    # ë§ˆìŠ¤í‚¹ëœ í† í° ì œì™¸í•˜ê³  í•©ê³„
    sum_embeddings = np.sum(token_embeddings * input_mask_expanded, axis=1)
    
    # ìœ íš¨ í† í° ìˆ˜ë¡œ ë‚˜ëˆ„ê¸°
    sum_mask = np.sum(input_mask_expanded, axis=1)
    sum_mask = np.maximum(sum_mask, 1e-9)  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
    
    return sum_embeddings / sum_mask


def demo_mean_pooling():
    """Mean Pooling ë°ëª¨"""
    print("\n" + "="*60)
    print("ğŸ“Š Mean Pooling ë°ëª¨")
    print("="*60)
    
    # ê°€ìƒì˜ í† í° ì„ë² ë”© (2ê°œ ë¬¸ì¥, 5ê°œ í† í°, 4ì°¨ì›)
    # ë¬¸ì¥ 1: "ì•ˆë…•í•˜ì„¸ìš”" â†’ ì‹¤ì œ í† í° 3ê°œ + íŒ¨ë”© 2ê°œ
    # ë¬¸ì¥ 2: "ë°˜ê°‘ìŠµë‹ˆë‹¤ ì˜¤ëŠ˜" â†’ ì‹¤ì œ í† í° 4ê°œ + íŒ¨ë”© 1ê°œ
    
    np.random.seed(42)
    token_embeddings = np.random.randn(2, 5, 4)
    
    attention_mask = np.array([
        [1, 1, 1, 0, 0],  # ë¬¸ì¥ 1: 3ê°œ í† í° ìœ íš¨
        [1, 1, 1, 1, 0]   # ë¬¸ì¥ 2: 4ê°œ í† í° ìœ íš¨
    ])
    
    print("í† í° ì„ë² ë”© shape:", token_embeddings.shape)
    print("ì–´í…ì…˜ ë§ˆìŠ¤í¬:\n", attention_mask)
    
    # Mean Pooling ì ìš©
    sentence_embeddings = mean_pooling_simple(token_embeddings, attention_mask)
    print("\në¬¸ì¥ ì„ë² ë”© shape:", sentence_embeddings.shape)
    print("ë¬¸ì¥ ì„ë² ë”©:\n", sentence_embeddings)
    
    # ìˆ˜ë™ ê³„ì‚°ìœ¼ë¡œ ê²€ì¦ (ë¬¸ì¥ 1)
    manual_mean = np.mean(token_embeddings[0, :3, :], axis=0)
    print("\nìˆ˜ë™ ê³„ì‚° (ë¬¸ì¥ 1):", manual_mean)
    print("Mean Pooling ê²°ê³¼:", sentence_embeddings[0])
    print("ì¼ì¹˜ ì—¬ë¶€:", np.allclose(manual_mean, sentence_embeddings[0]))


# ============================================================
# Part 3: ë¬¸ì¥ ìœ ì‚¬ë„ ê³„ì‚°
# ============================================================

@dataclass
class SentencePair:
    """ë¬¸ì¥ ìŒ ë°ì´í„°"""
    sentence1: str
    sentence2: str
    similarity: float


class SimpleSentenceEncoder:
    """
    ê°„ë‹¨í•œ ë¬¸ì¥ ì¸ì½”ë” (ë°ëª¨ìš©)
    
    ì‹¤ì œë¡œëŠ” Sentence-Transformersë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
    ì—¬ê¸°ì„œëŠ” ë‹¨ì–´ ì„ë² ë”©ì˜ í‰ê· ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, embedding_dim: int = 64):
        self.embedding_dim = embedding_dim
        self.word_embeddings = {}
        np.random.seed(42)
    
    def _get_word_embedding(self, word: str) -> np.ndarray:
        """ë‹¨ì–´ ì„ë² ë”© ë°˜í™˜ (í•´ì‹œ ê¸°ë°˜ ëœë¤ ìƒì„±)"""
        if word not in self.word_embeddings:
            # ë‹¨ì–´ë³„ ì¼ê´€ëœ ì„ë² ë”© ìƒì„±
            np.random.seed(hash(word) % 2**31)
            embedding = np.random.randn(self.embedding_dim)
            self.word_embeddings[word] = embedding / np.linalg.norm(embedding)
        return self.word_embeddings[word]
    
    def encode(self, sentences: List[str]) -> np.ndarray:
        """ë¬¸ì¥ë“¤ì„ ë²¡í„°ë¡œ ì¸ì½”ë”©"""
        embeddings = []
        
        for sentence in sentences:
            words = sentence.lower().split()
            if not words:
                embeddings.append(np.zeros(self.embedding_dim))
                continue
            
            word_embs = [self._get_word_embedding(w) for w in words]
            sentence_emb = np.mean(word_embs, axis=0)
            embeddings.append(sentence_emb)
        
        return np.array(embeddings)


def compute_similarity_matrix(embeddings: np.ndarray) -> np.ndarray:
    """ì„ë² ë”©ë“¤ ê°„ì˜ ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚°"""
    # ì •ê·œí™”
    normalized = normalize_vectors(embeddings)
    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ = ì •ê·œí™”ëœ ë²¡í„°ì˜ ë‚´ì 
    return np.dot(normalized, normalized.T)


def demo_similarity():
    """ë¬¸ì¥ ìœ ì‚¬ë„ ë°ëª¨"""
    print("\n" + "="*60)
    print("ğŸ” ë¬¸ì¥ ìœ ì‚¬ë„ ê³„ì‚° ë°ëª¨")
    print("="*60)
    
    encoder = SimpleSentenceEncoder()
    
    sentences = [
        "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ìŠµë‹ˆë‹¤",
        "ì˜¤ëŠ˜ í•˜ëŠ˜ì´ ë§‘ì•„ìš”",
        "í”„ë¡œê·¸ë˜ë°ì„ ê³µë¶€í•©ë‹ˆë‹¤",
        "ì½”ë”©ì„ ë°°ìš°ê³  ìˆìŠµë‹ˆë‹¤"
    ]
    
    print("ë¬¸ì¥ ëª©ë¡:")
    for i, s in enumerate(sentences):
        print(f"  {i}: {s}")
    
    # ì„ë² ë”© ìƒì„±
    embeddings = encoder.encode(sentences)
    print(f"\nì„ë² ë”© shape: {embeddings.shape}")
    
    # ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚°
    similarity_matrix = compute_similarity_matrix(embeddings)
    
    print("\nìœ ì‚¬ë„ í–‰ë ¬:")
    print("     ", end="")
    for i in range(len(sentences)):
        print(f"  [{i}]  ", end="")
    print()
    
    for i, row in enumerate(similarity_matrix):
        print(f"[{i}]", end="")
        for val in row:
            print(f"  {val:5.3f}", end="")
        print()
    
    # ê°€ì¥ ìœ ì‚¬í•œ ìŒ ì°¾ê¸°
    print("\nê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì¥ ìŒ:")
    for i in range(len(sentences)):
        for j in range(i + 1, len(sentences)):
            sim = similarity_matrix[i][j]
            if sim > 0.5:
                print(f"  '{sentences[i]}' â†” '{sentences[j]}': {sim:.3f}")


# ============================================================
# Part 4: ìœ ì‚¬ ë¬¸ì¥ ê²€ìƒ‰
# ============================================================

class SentenceSearchEngine:
    """ë¬¸ì¥ ê²€ìƒ‰ ì—”ì§„"""
    
    def __init__(self, encoder: SimpleSentenceEncoder):
        self.encoder = encoder
        self.documents = []
        self.embeddings = None
    
    def add_documents(self, documents: List[str]):
        """ë¬¸ì„œ ì¶”ê°€"""
        self.documents = documents
        self.embeddings = self.encoder.encode(documents)
        # ì •ê·œí™”
        self.embeddings = normalize_vectors(self.embeddings)
    
    def search(self, query: str, top_k: int = 3) -> List[Tuple[str, float]]:
        """ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰"""
        query_embedding = self.encoder.encode([query])[0]
        query_embedding = query_embedding / np.linalg.norm(query_embedding)
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = np.dot(self.embeddings, query_embedding)
        
        # ìƒìœ„ kê°œ ì¸ë±ìŠ¤
        top_indices = np.argsort(similarities)[-top_k:][::-1]
        
        results = []
        for idx in top_indices:
            results.append((self.documents[idx], similarities[idx]))
        
        return results


def demo_search():
    """ìœ ì‚¬ ë¬¸ì¥ ê²€ìƒ‰ ë°ëª¨"""
    print("\n" + "="*60)
    print("ğŸ” ìœ ì‚¬ ë¬¸ì¥ ê²€ìƒ‰ ë°ëª¨")
    print("="*60)
    
    documents = [
        "ì¸ê³µì§€ëŠ¥ì€ ë¯¸ë˜ ê¸°ìˆ ì˜ í•µì‹¬ì…ë‹ˆë‹¤",
        "ë¨¸ì‹ ëŸ¬ë‹ì€ ë°ì´í„°ì—ì„œ íŒ¨í„´ì„ í•™ìŠµí•©ë‹ˆë‹¤",
        "ë”¥ëŸ¬ë‹ì€ ì‹¬ì¸µ ì‹ ê²½ë§ì„ ì‚¬ìš©í•©ë‹ˆë‹¤",
        "ì˜¤ëŠ˜ ì ì‹¬ ë©”ë‰´ëŠ” ê¹€ì¹˜ì°Œê°œì…ë‹ˆë‹¤",
        "íŒŒì´ì¬ì€ ì¸ê¸°ìˆëŠ” í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤",
        "ìì—°ì–´ ì²˜ë¦¬ëŠ” í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤",
        "ì»´í“¨í„° ë¹„ì „ì€ ì´ë¯¸ì§€ë¥¼ ì´í•´í•©ë‹ˆë‹¤"
    ]
    
    encoder = SimpleSentenceEncoder()
    search_engine = SentenceSearchEngine(encoder)
    search_engine.add_documents(documents)
    
    queries = [
        "AI ê¸°ìˆ ",
        "ìŒì‹ ë©”ë‰´",
        "ì´ë¯¸ì§€ ë¶„ì„"
    ]
    
    for query in queries:
        print(f"\nğŸ” ì¿¼ë¦¬: '{query}'")
        results = search_engine.search(query, top_k=3)
        
        for rank, (doc, score) in enumerate(results, 1):
            print(f"  {rank}. [{score:.3f}] {doc}")


# ============================================================
# Part 5: Spearman ìƒê´€ê³„ìˆ˜ ê³„ì‚°
# ============================================================

def spearman_correlation(predictions: List[float], labels: List[float]) -> float:
    """
    Spearman ìƒê´€ê³„ìˆ˜ ê³„ì‚°
    
    ë¬¸ì¥ ìœ ì‚¬ë„ ëª¨ë¸ í‰ê°€ì— ì‚¬ìš©ë©ë‹ˆë‹¤.
    """
    n = len(predictions)
    
    # ìˆœìœ„ ê³„ì‚°
    pred_ranks = np.argsort(np.argsort(predictions)) + 1
    label_ranks = np.argsort(np.argsort(labels)) + 1
    
    # ìˆœìœ„ ì°¨ì´
    d = pred_ranks - label_ranks
    d_squared = np.sum(d ** 2)
    
    # Spearman ìƒê´€ê³„ìˆ˜
    correlation = 1 - (6 * d_squared) / (n * (n ** 2 - 1))
    return correlation


def demo_evaluation():
    """ëª¨ë¸ í‰ê°€ ë°ëª¨"""
    print("\n" + "="*60)
    print("ğŸ“ˆ ëª¨ë¸ í‰ê°€ (Spearman ìƒê´€ê³„ìˆ˜) ë°ëª¨")
    print("="*60)
    
    # ê°€ìƒì˜ ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’
    predictions = [0.9, 0.7, 0.3, 0.8, 0.2, 0.6]
    labels = [0.85, 0.75, 0.25, 0.9, 0.15, 0.65]
    
    print("ì˜ˆì¸¡ê°’:", [f"{p:.2f}" for p in predictions])
    print("ì‹¤ì œê°’:", [f"{l:.2f}" for l in labels])
    
    correlation = spearman_correlation(predictions, labels)
    print(f"\nSpearman ìƒê´€ê³„ìˆ˜: {correlation:.4f}")
    
    if correlation > 0.8:
        print("í‰ê°€: ë§¤ìš° ì¢‹ìŒ âœ…")
    elif correlation > 0.6:
        print("í‰ê°€: ì¢‹ìŒ ğŸ‘")
    elif correlation > 0.4:
        print("í‰ê°€: ë³´í†µ âš ï¸")
    else:
        print("í‰ê°€: ê°œì„  í•„ìš” âŒ")


# ============================================================
# Part 6: Sentence-Transformers ì‚¬ìš© (ì„ íƒì )
# ============================================================

def demo_sentence_transformers():
    """Sentence-Transformers ì‚¬ìš© ë°ëª¨ (ì„¤ì¹˜ëœ ê²½ìš°)"""
    try:
        from sentence_transformers import SentenceTransformer
        
        print("\n" + "="*60)
        print("ğŸš€ Sentence-Transformers ë°ëª¨")
        print("="*60)
        
        # ë‹¤êµ­ì–´ ëª¨ë¸ ë¡œë“œ (í•œêµ­ì–´ ì§€ì›)
        model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
        
        sentences = [
            "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ìŠµë‹ˆë‹¤",
            "ì˜¤ëŠ˜ í•˜ëŠ˜ì´ ë§‘ì•„ìš”",
            "í”„ë¡œê·¸ë˜ë°ì„ ê³µë¶€í•©ë‹ˆë‹¤"
        ]
        
        print("ë¬¸ì¥:")
        for s in sentences:
            print(f"  - {s}")
        
        # ì„ë² ë”© ìƒì„±
        embeddings = model.encode(sentences)
        print(f"\nì„ë² ë”© shape: {embeddings.shape}")
        
        # ìœ ì‚¬ë„ ê³„ì‚°
        from sentence_transformers.util import cos_sim
        similarity = cos_sim(embeddings, embeddings)
        
        print("\nìœ ì‚¬ë„ í–‰ë ¬:")
        print(similarity.numpy())
        
    except ImportError:
        print("\nâš ï¸ sentence-transformersê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ì„¤ì¹˜: pip install sentence-transformers")


# ============================================================
# ë©”ì¸ í•¨ìˆ˜
# ============================================================

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("="*60)
    print("ğŸ¤– Chapter 11: ë¬¸ì¥ ì„ë² ë”© ì‹¤ìŠµ")
    print("="*60)
    
    demo_mean_pooling()
    demo_similarity()
    demo_search()
    demo_evaluation()
    demo_sentence_transformers()
    
    print("\n" + "="*60)
    print("âœ… ì‹¤ìŠµ ì™„ë£Œ!")
    print("="*60)


if __name__ == "__main__":
    main()

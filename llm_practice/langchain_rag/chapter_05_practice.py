"""
Chapter 05: RAG ê¸°ì´ˆ ì‹¤ìŠµ ì½”ë“œ
==============================

ì´ íŒŒì¼ì€ RAG (Retrieval-Augmented Generation)ì˜ í•µì‹¬ ê°œë…ì„ ì‹¤ìŠµí•©ë‹ˆë‹¤:
1. ë²¡í„° ì €ì¥ì†Œ ì‹œë®¬ë ˆì´ì…˜
2. Retriever êµ¬í˜„
3. RAG ì²´ì¸ êµ¬ì„±

ì‹¤í–‰ ë°©ë²•:
    pip install numpy
    python chapter_05_practice.py

    # LangChain ì‚¬ìš© ì‹œ:
    pip install langchain langchain-openai langchain-chroma
"""

import numpy as np
from typing import List, Dict, Any, Tuple
from dataclasses import dataclass, field


# ============================================================
# Part 1: Document í´ë˜ìŠ¤
# ============================================================

@dataclass
class Document:
    """ë¬¸ì„œ í´ë˜ìŠ¤"""
    page_content: str
    metadata: Dict[str, Any] = field(default_factory=dict)


# ============================================================
# Part 2: ê°„ë‹¨í•œ ì„ë² ë”© ëª¨ë¸
# ============================================================

class SimpleEmbedding:
    """ê°„ë‹¨í•œ ì„ë² ë”© ëª¨ë¸ (ë°ëª¨ìš©)"""
    
    def __init__(self, dim: int = 64):
        self.dim = dim
    
    def embed_documents(self, texts: List[str]) -> List[np.ndarray]:
        """ë¬¸ì„œë“¤ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        return [self._embed(text) for text in texts]
    
    def embed_query(self, text: str) -> np.ndarray:
        """ì¿¼ë¦¬ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        return self._embed(text)
    
    def _embed(self, text: str) -> np.ndarray:
        """í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜ (í•´ì‹œ ê¸°ë°˜)"""
        np.random.seed(hash(text.lower()[:100]) % 2**31)
        embedding = np.random.randn(self.dim)
        return embedding / np.linalg.norm(embedding)


# ============================================================
# Part 3: ë²¡í„° ì €ì¥ì†Œ
# ============================================================

class SimpleVectorStore:
    """ê°„ë‹¨í•œ ë²¡í„° ì €ì¥ì†Œ"""
    
    def __init__(self, embedding_model: SimpleEmbedding):
        self.embedding_model = embedding_model
        self.documents: List[Document] = []
        self.embeddings: List[np.ndarray] = []
    
    def add_documents(self, documents: List[Document]):
        """ë¬¸ì„œ ì¶”ê°€"""
        texts = [doc.page_content for doc in documents]
        new_embeddings = self.embedding_model.embed_documents(texts)
        
        self.documents.extend(documents)
        self.embeddings.extend(new_embeddings)
    
    def similarity_search(self, query: str, k: int = 4) -> List[Document]:
        """ìœ ì‚¬ë„ ê²€ìƒ‰"""
        query_embedding = self.embedding_model.embed_query(query)
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = []
        for emb in self.embeddings:
            sim = np.dot(query_embedding, emb)
            similarities.append(sim)
        
        # ìƒìœ„ kê°œ ì¸ë±ìŠ¤
        top_indices = np.argsort(similarities)[-k:][::-1]
        
        return [self.documents[i] for i in top_indices]
    
    def similarity_search_with_score(self, query: str, k: int = 4) -> List[Tuple[Document, float]]:
        """ìœ ì‚¬ë„ ì ìˆ˜ì™€ í•¨ê»˜ ê²€ìƒ‰"""
        query_embedding = self.embedding_model.embed_query(query)
        
        similarities = []
        for emb in self.embeddings:
            sim = np.dot(query_embedding, emb)
            similarities.append(sim)
        
        top_indices = np.argsort(similarities)[-k:][::-1]
        
        return [(self.documents[i], similarities[i]) for i in top_indices]
    
    def as_retriever(self, search_kwargs: Dict = None) -> 'SimpleRetriever':
        """Retriever ë°˜í™˜"""
        return SimpleRetriever(self, search_kwargs or {"k": 4})


# ============================================================
# Part 4: Retriever
# ============================================================

class SimpleRetriever:
    """ê°„ë‹¨í•œ Retriever"""
    
    def __init__(self, vectorstore: SimpleVectorStore, search_kwargs: Dict):
        self.vectorstore = vectorstore
        self.search_kwargs = search_kwargs
    
    def invoke(self, query: str) -> List[Document]:
        """ì¿¼ë¦¬ì— ëŒ€í•œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰"""
        k = self.search_kwargs.get("k", 4)
        return self.vectorstore.similarity_search(query, k=k)


# ============================================================
# Part 5: RAG ì²´ì¸
# ============================================================

class SimpleLLM:
    """ê°„ë‹¨í•œ LLM ì‹œë®¬ë ˆì´í„°"""
    
    def invoke(self, prompt: str) -> str:
        """LLM í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜"""
        # í”„ë¡¬í”„íŠ¸ì—ì„œ ì»¨í…ìŠ¤íŠ¸ì™€ ì§ˆë¬¸ ì¶”ì¶œ (ê°„ì†Œí™”)
        if "ì»¨í…ìŠ¤íŠ¸" in prompt or "context" in prompt.lower():
            return "ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤: [ë‹µë³€ ë‚´ìš©]"
        return f"'{prompt[:50]}...'ì— ëŒ€í•œ ì‘ë‹µì…ë‹ˆë‹¤."


class SimpleRAGChain:
    """ê°„ë‹¨í•œ RAG ì²´ì¸"""
    
    def __init__(self, retriever: SimpleRetriever, llm: SimpleLLM, 
                 prompt_template: str = None):
        self.retriever = retriever
        self.llm = llm
        self.prompt_template = prompt_template or """
ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.

ì»¨í…ìŠ¤íŠ¸:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€:"""
    
    def _format_docs(self, docs: List[Document]) -> str:
        """ë¬¸ì„œë“¤ì„ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…"""
        return "\n\n".join(doc.page_content for doc in docs)
    
    def invoke(self, question: str) -> Dict[str, Any]:
        """RAG ì²´ì¸ ì‹¤í–‰"""
        # 1. ê²€ìƒ‰
        docs = self.retriever.invoke(question)
        context = self._format_docs(docs)
        
        # 2. í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self.prompt_template.format(
            context=context,
            question=question
        )
        
        # 3. LLM í˜¸ì¶œ
        answer = self.llm.invoke(prompt)
        
        return {
            "question": question,
            "answer": answer,
            "source_documents": docs,
            "context": context
        }


# ============================================================
# ë°ëª¨ í•¨ìˆ˜ë“¤
# ============================================================

def demo_vector_store():
    """ë²¡í„° ì €ì¥ì†Œ ë°ëª¨"""
    print("\n" + "="*60)
    print("ğŸ—„ï¸ ë²¡í„° ì €ì¥ì†Œ ë°ëª¨")
    print("="*60)
    
    # ì„ë² ë”© ëª¨ë¸
    embedding_model = SimpleEmbedding(dim=64)
    
    # ë²¡í„° ì €ì¥ì†Œ
    vectorstore = SimpleVectorStore(embedding_model)
    
    # ìƒ˜í”Œ ë¬¸ì„œ
    documents = [
        Document(page_content="ì¸ê³µì§€ëŠ¥ì€ ì»´í“¨í„°ê°€ ì¸ê°„ì˜ ì§€ëŠ¥ì„ ëª¨ë°©í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤."),
        Document(page_content="ë¨¸ì‹ ëŸ¬ë‹ì€ ë°ì´í„°ì—ì„œ íŒ¨í„´ì„ í•™ìŠµí•˜ëŠ” AIì˜ í•œ ë¶„ì•¼ì…ë‹ˆë‹¤."),
        Document(page_content="ë”¥ëŸ¬ë‹ì€ ì‹ ê²½ë§ì„ ì‚¬ìš©í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ë°©ë²•ì…ë‹ˆë‹¤."),
        Document(page_content="ìì—°ì–´ ì²˜ë¦¬ëŠ” ì»´í“¨í„°ê°€ í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤."),
        Document(page_content="ì»´í“¨í„° ë¹„ì „ì€ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ëŠ” AI ê¸°ìˆ ì…ë‹ˆë‹¤.")
    ]
    
    # ë¬¸ì„œ ì¶”ê°€
    vectorstore.add_documents(documents)
    print(f"\në¬¸ì„œ {len(documents)}ê°œ ì¶”ê°€ë¨")
    
    # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    query = "AI ê¸°ìˆ "
    results = vectorstore.similarity_search_with_score(query, k=3)
    
    print(f"\nì¿¼ë¦¬: '{query}'")
    print("\nê²€ìƒ‰ ê²°ê³¼:")
    for doc, score in results:
        print(f"  [{score:.3f}] {doc.page_content}")


def demo_retriever():
    """Retriever ë°ëª¨"""
    print("\n" + "="*60)
    print("ğŸ” Retriever ë°ëª¨")
    print("="*60)
    
    # ì„¤ì •
    embedding_model = SimpleEmbedding(dim=64)
    vectorstore = SimpleVectorStore(embedding_model)
    
    documents = [
        Document(page_content="ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.", metadata={"source": "ì§€ë¦¬"}),
        Document(page_content="ì„œìš¸ì˜ ì¸êµ¬ëŠ” ì•½ ì²œë§Œ ëª…ì…ë‹ˆë‹¤.", metadata={"source": "í†µê³„"}),
        Document(page_content="í•œê°•ì€ ì„œìš¸ì„ ê´€í†µí•˜ëŠ” ê°•ì…ë‹ˆë‹¤.", metadata={"source": "ì§€ë¦¬"}),
        Document(page_content="ê²½ë³µê¶ì€ ì„œìš¸ì— ìˆëŠ” ì¡°ì„ ì‹œëŒ€ ê¶ê¶ì…ë‹ˆë‹¤.", metadata={"source": "ì—­ì‚¬"}),
        Document(page_content="íŒŒë¦¬ëŠ” í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ì…ë‹ˆë‹¤.", metadata={"source": "ì§€ë¦¬"})
    ]
    
    vectorstore.add_documents(documents)
    
    # Retriever ìƒì„±
    retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
    
    # ê²€ìƒ‰
    queries = ["ì„œìš¸ì— ëŒ€í•´ ì•Œë ¤ì¤˜", "ìœ ëŸ½ì˜ ë„ì‹œ"]
    
    for query in queries:
        print(f"\nì¿¼ë¦¬: '{query}'")
        docs = retriever.invoke(query)
        print("ê²€ìƒ‰ëœ ë¬¸ì„œ:")
        for doc in docs:
            print(f"  - {doc.page_content[:50]}...")


def demo_rag_chain():
    """RAG ì²´ì¸ ë°ëª¨"""
    print("\n" + "="*60)
    print("â›“ï¸ RAG ì²´ì¸ ë°ëª¨")
    print("="*60)
    
    # êµ¬ì„± ìš”ì†Œ ìƒì„±
    embedding_model = SimpleEmbedding(dim=64)
    vectorstore = SimpleVectorStore(embedding_model)
    
    documents = [
        Document(page_content="GPT-4ëŠ” OpenAIê°€ ê°œë°œí•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤."),
        Document(page_content="ClaudeëŠ” Anthropicì´ ê°œë°œí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."),
        Document(page_content="LLaMAëŠ” Metaê°€ ê°œë°œí•œ ì˜¤í”ˆì†ŒìŠ¤ ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤."),
        Document(page_content="GeminiëŠ” Googleì´ ê°œë°œí•œ ë©€í‹°ëª¨ë‹¬ AI ëª¨ë¸ì…ë‹ˆë‹¤.")
    ]
    
    vectorstore.add_documents(documents)
    retriever = vectorstore.as_retriever(search_kwargs={"k": 2})
    llm = SimpleLLM()
    
    # RAG ì²´ì¸
    rag_chain = SimpleRAGChain(retriever, llm)
    
    # ì§ˆë¬¸
    question = "OpenAIì˜ ëª¨ë¸ì€ ë¬´ì—‡ì¸ê°€ìš”?"
    result = rag_chain.invoke(question)
    
    print(f"\nì§ˆë¬¸: {result['question']}")
    print(f"\nì»¨í…ìŠ¤íŠ¸:")
    for doc in result['source_documents']:
        print(f"  - {doc.page_content}")
    print(f"\në‹µë³€: {result['answer']}")


def demo_lcel_simulation():
    """LCEL ìŠ¤íƒ€ì¼ ì²´ì¸ ë°ëª¨"""
    print("\n" + "="*60)
    print("ğŸ”— LCEL ìŠ¤íƒ€ì¼ ì²´ì¸ ì‹œë®¬ë ˆì´ì…˜")
    print("="*60)
    
    class Runnable:
        """LCEL Runnable ì‹œë®¬ë ˆì´ì…˜"""
        
        def __init__(self, func):
            self.func = func
        
        def __or__(self, other):
            """| ì—°ì‚°ì ì˜¤ë²„ë¡œë”©"""
            return ChainedRunnable([self, other])
        
        def invoke(self, input_data):
            return self.func(input_data)
    
    class ChainedRunnable(Runnable):
        """ì²´ì¸ëœ Runnable"""
        
        def __init__(self, runnables):
            self.runnables = runnables
        
        def __or__(self, other):
            return ChainedRunnable(self.runnables + [other])
        
        def invoke(self, input_data):
            result = input_data
            for runnable in self.runnables:
                result = runnable.invoke(result)
            return result
    
    # ì²´ì¸ êµ¬ì„± ìš”ì†Œ
    def retrieve(query):
        return {"query": query, "docs": ["ë¬¸ì„œ1", "ë¬¸ì„œ2"]}
    
    def format_context(data):
        return {**data, "context": " | ".join(data["docs"])}
    
    def generate(data):
        return f"ì¿¼ë¦¬ '{data['query']}'ì— ëŒ€í•œ ë‹µë³€ (ì»¨í…ìŠ¤íŠ¸: {data['context']})"
    
    # LCEL ìŠ¤íƒ€ì¼ ì²´ì¸
    chain = Runnable(retrieve) | Runnable(format_context) | Runnable(generate)
    
    result = chain.invoke("í…ŒìŠ¤íŠ¸ ì§ˆë¬¸")
    print(f"\nì²´ì¸ ê²°ê³¼: {result}")


def demo_langchain_rag():
    """LangChain RAG ì‹¤ì œ ì‚¬ìš© (ì„ íƒì )"""
    try:
        from langchain_openai import ChatOpenAI, OpenAIEmbeddings
        from langchain_chroma import Chroma
        import os
        
        print("\n" + "="*60)
        print("ğŸš€ LangChain RAG ë°ëª¨")
        print("="*60)
        
        if not os.environ.get("OPENAI_API_KEY"):
            print("\nâš ï¸ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        # ì‹¤ì œ RAG êµ¬í˜„ ì˜ˆì‹œ ì½”ë“œ
        print("""
ì˜ˆì œ ì½”ë“œ:

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.runnables import RunnablePassthrough

# ë¬¸ì„œ ì¤€ë¹„ ë° ë²¡í„° ì €ì¥ì†Œ ìƒì„±
vectorstore = Chroma.from_documents(docs, OpenAIEmbeddings())
retriever = vectorstore.as_retriever()

# RAG ì²´ì¸
rag_chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | ChatOpenAI(model="gpt-4o-mini")
    | StrOutputParser()
)

answer = rag_chain.invoke("ì§ˆë¬¸...")
        """)
        
    except ImportError:
        print("\nâš ï¸ langchain íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ì„¤ì¹˜: pip install langchain langchain-openai langchain-chroma")


# ============================================================
# ë©”ì¸ í•¨ìˆ˜
# ============================================================

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("="*60)
    print("ğŸ¤– Chapter 05: RAG ê¸°ì´ˆ ì‹¤ìŠµ")
    print("="*60)
    
    demo_vector_store()
    demo_retriever()
    demo_rag_chain()
    demo_lcel_simulation()
    demo_langchain_rag()
    
    print("\n" + "="*60)
    print("âœ… ì‹¤ìŠµ ì™„ë£Œ!")
    print("="*60)


if __name__ == "__main__":
    main()

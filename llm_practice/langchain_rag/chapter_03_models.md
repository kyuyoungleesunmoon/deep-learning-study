# ğŸ“– Chapter 03: Models & Prompts

## ğŸ“‹ ê°œìš”

ì´ ì±•í„°ì—ì„œëŠ” LangChainì„ í™œìš©í•œ LLM API ì‚¬ìš©ë²•ê³¼ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì„ í•™ìŠµí•©ë‹ˆë‹¤.
- ë‹¤ì–‘í•œ LLM API í†µí•© (OpenAI, Anthropic)
- í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
- Output Parser

## ğŸ”¬ í•µì‹¬ ê°œë…

### 1. LangChainì˜ ì¥ì 

**ì§ì ‘ API í˜¸ì¶œ**:
```python
from openai import OpenAI
client = OpenAI(api_key="...")
response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": "Hello"}]
)
```

**LangChain í™œìš©**:
```python
from langchain_openai import ChatOpenAI
chat = ChatOpenAI(model_name="gpt-4o-mini")
response = chat.invoke("Hello")
```

**ì¥ì **:
- ë‹¤ì–‘í•œ LLMì„ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤ë¡œ ì‚¬ìš©
- í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿, ë©”ëª¨ë¦¬, ì²´ì¸ ë“± ì¶”ê°€ ê¸°ëŠ¥
- ì‰¬ìš´ ëª¨ë¸ ì „í™˜ (OpenAI â†” Anthropic)

### 2. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿

**PromptTemplate**: ê¸°ë³¸ ë¬¸ìì—´ í…œí”Œë¦¿
```python
from langchain.prompts import PromptTemplate

template = PromptTemplate.from_template(
    "ìš”ë¦¬ì‚¬ë¡œì„œ {ì¬ë£Œ}ë¡œ ë§Œë“¤ ìˆ˜ ìˆëŠ” ìš”ë¦¬ {ê°œìˆ˜}ê°œë¥¼ ì¶”ì²œí•´ì¤˜"
)
prompt = template.format(ì¬ë£Œ="ê³„ë€, ì–‘íŒŒ", ê°œìˆ˜=3)
```

**ChatPromptTemplate**: ëŒ€í™”í˜• í…œí”Œë¦¿
```python
from langchain_core.prompts import ChatPromptTemplate

template = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful assistant named {name}"),
    ("human", "{question}")
])
messages = template.format_messages(name="Bob", question="What's your name?")
```

### 3. Output Parser

**ëª©ì **: LLM ì¶œë ¥ì„ êµ¬ì¡°í™”ëœ í˜•ì‹ìœ¼ë¡œ ë³€í™˜

| Parser | ì¶œë ¥ í˜•ì‹ | ìš©ë„ |
|--------|----------|------|
| `CommaSeparatedListOutputParser` | ë¦¬ìŠ¤íŠ¸ | ëª©ë¡ ìƒì„± |
| `DatetimeOutputParser` | datetime | ë‚ ì§œ ì¶”ì¶œ |
| `JsonOutputParser` | JSON/Dict | êµ¬ì¡°í™” ë°ì´í„° |
| `PydanticOutputParser` | Pydantic ëª¨ë¸ | íƒ€ì… ê²€ì¦ |

### 4. Temperature íŒŒë¼ë¯¸í„°

| ê°’ | íŠ¹ì„± | ìš©ë„ |
|---|------|------|
| 0 | ê²°ì •ë¡ ì , ì¼ê´€ì„± | íŒ©íŠ¸ ê¸°ë°˜ ë‹µë³€ |
| 0.5 | ê· í˜• | ì¼ë°˜ ëŒ€í™” |
| 1.0 | ì°½ì˜ì , ë‹¤ì–‘ì„± | ì°½ì‘, ë¸Œë ˆì¸ìŠ¤í† ë° |

## ğŸ“Š ì‹¤ìŠµ ì˜ˆì œ

### ì˜ˆì œ 1: ê¸°ë³¸ LLM í˜¸ì¶œ

```python
import os
from langchain_openai import ChatOpenAI

os.environ["OPENAI_API_KEY"] = "your-api-key"

# ëª¨ë¸ ì´ˆê¸°í™”
chat = ChatOpenAI(
    model_name="gpt-4o-mini",
    temperature=0
)

# ë‹¨ìˆœ í˜¸ì¶œ
response = chat.invoke("íŒŒì´ì¬ì˜ ì¥ì ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì¤˜")
print(response.content)
```

### ì˜ˆì œ 2: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import SystemMessage, HumanMessage

# ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¡œ ì—­í•  ë¶€ì—¬
template = ChatPromptTemplate.from_messages([
    ("system", "ë‹¹ì‹ ì€ {role} ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”."),
    ("human", "{question}")
])

# ë©”ì‹œì§€ ìƒì„±
messages = template.format_messages(
    role="Python í”„ë¡œê·¸ë˜ë°",
    question="ë¦¬ìŠ¤íŠ¸ì™€ íŠœí”Œì˜ ì°¨ì´ê°€ ë­ì•¼?"
)

# LLM í˜¸ì¶œ
response = chat.invoke(messages)
print(response.content)
```

### ì˜ˆì œ 3: Few-shot í”„ë¡¬í”„íŠ¸

```python
from langchain.prompts import FewShotPromptTemplate, PromptTemplate

# ì˜ˆì‹œë“¤
examples = [
    {"input": "ì•„ì´ìœ ", "output": "ì•„: ì•„ì´ìœ ëŠ”\nì´: ì´ë ‡ê²Œ\nìœ : ìœ ëª…í•´ìš”"},
    {"input": "ë°©íƒ„", "output": "ë°©: ë°©ê¸ˆ\níƒ„: íƒ„ìƒí•œ\n"}
]

# ì˜ˆì‹œ í…œí”Œë¦¿
example_template = PromptTemplate(
    input_variables=["input", "output"],
    template="ì…ë ¥: {input}\nì¶œë ¥:\n{output}"
)

# Few-shot í…œí”Œë¦¿
prompt = FewShotPromptTemplate(
    examples=examples,
    example_prompt=example_template,
    prefix="ì‚¼í–‰ì‹œë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.\n",
    suffix="ì…ë ¥: {word}\nì¶œë ¥:",
    input_variables=["word"]
)

# ì‚¬ìš©
final_prompt = prompt.format(word="ì½”ë”©")
response = chat.invoke(final_prompt)
```

### ì˜ˆì œ 4: Output Parser

```python
from langchain.output_parsers import CommaSeparatedListOutputParser
from langchain.prompts import PromptTemplate

# íŒŒì„œ ìƒì„±
parser = CommaSeparatedListOutputParser()

# íŒŒì„œ ì§€ì¹¨ì„ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
template = PromptTemplate(
    template="{subject}ì˜ ì¢…ë¥˜ {count}ê°œë¥¼ ë‚˜ì—´í•´ì£¼ì„¸ìš”.\n{format_instructions}",
    input_variables=["subject", "count"],
    partial_variables={"format_instructions": parser.get_format_instructions()}
)

# ì²´ì¸ êµ¬ì„±
prompt = template.format(subject="í”„ë¡œê·¸ë˜ë° ì–¸ì–´", count=5)
response = chat.invoke(prompt)

# íŒŒì‹±
result = parser.parse(response.content)
print(result)  # ['Python', 'JavaScript', 'Java', 'C++', 'Go']
```

### ì˜ˆì œ 5: JSON Output Parser

```python
from langchain_core.output_parsers import JsonOutputParser
from pydantic import BaseModel, Field

# ì¶œë ¥ ìŠ¤í‚¤ë§ˆ ì •ì˜
class Country(BaseModel):
    name: str = Field(description="ë‚˜ë¼ ì´ë¦„")
    capital: str = Field(description="ìˆ˜ë„")
    population: int = Field(description="ì¸êµ¬ìˆ˜")

parser = JsonOutputParser(pydantic_object=Country)

template = PromptTemplate(
    template="{country}ì— ëŒ€í•œ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.\n{format_instructions}",
    input_variables=["country"],
    partial_variables={"format_instructions": parser.get_format_instructions()}
)

# ì²´ì¸ (LCEL)
chain = template | chat | parser
result = chain.invoke({"country": "ëŒ€í•œë¯¼êµ­"})
print(result)  # {'name': 'ëŒ€í•œë¯¼êµ­', 'capital': 'ì„œìš¸', 'population': 51000000}
```

### ì˜ˆì œ 6: ìŠ¤íŠ¸ë¦¬ë°

```python
from langchain_openai import ChatOpenAI

chat = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

# ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥
for chunk in chat.stream("ë‹¬ì— ëŒ€í•œ ì‹œë¥¼ ì¨ì¤˜"):
    print(chunk.content, end="", flush=True)
```

## ğŸ¯ í•µì‹¬ í¬ì¸íŠ¸

1. **LangChainì˜ ì¶”ìƒí™”**: ë‹¤ì–‘í•œ LLMì„ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤ë¡œ ì‚¬ìš©
2. **í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§**: í…œí”Œë¦¿ìœ¼ë¡œ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡¬í”„íŠ¸ ì„¤ê³„
3. **Output Parser**: êµ¬ì¡°í™”ëœ ì¶œë ¥ìœ¼ë¡œ í›„ì²˜ë¦¬ ìš©ì´
4. **LCEL**: `|` ì—°ì‚°ìë¡œ ì§ê´€ì ì¸ ì²´ì¸ êµ¬ì„±

## ğŸ“š ì°¸ê³  ìë£Œ

- ì›ë³¸ ì½”ë“œ: https://github.com/Kane0002/Langchain-RAG/tree/main/3ì¥
- LangChain ë¬¸ì„œ: https://python.langchain.com/
- OpenAI API: https://platform.openai.com/docs

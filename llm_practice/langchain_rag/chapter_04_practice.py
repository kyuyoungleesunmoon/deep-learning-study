"""
Chapter 04: Document Loaders & Text Splitters ì‹¤ìŠµ ì½”ë“œ
=======================================================

ì´ íŒŒì¼ì€ ë¬¸ì„œ ë¡œë”©ê³¼ í…ìŠ¤íŠ¸ ë¶„í• ì„ ì‹¤ìŠµí•©ë‹ˆë‹¤:
1. ë‹¤ì–‘í•œ ë¬¸ì„œ í¬ë§· ì²˜ë¦¬
2. Text Splitter êµ¬í˜„
3. Chunk Overlap ê°œë…

ì‹¤í–‰ ë°©ë²•:
    pip install langchain langchain-text-splitters
    python chapter_04_practice.py
"""

from typing import List, Dict, Any
from dataclasses import dataclass, field
import re


# ============================================================
# Part 1: Document í´ë˜ìŠ¤
# ============================================================

@dataclass
class Document:
    """LangChain Documentì™€ ìœ ì‚¬í•œ í´ë˜ìŠ¤"""
    page_content: str
    metadata: Dict[str, Any] = field(default_factory=dict)


# ============================================================
# Part 2: Document Loader êµ¬í˜„
# ============================================================

class TextLoader:
    """í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë” ì‹œë®¬ë ˆì´ì…˜"""
    
    def __init__(self, file_path: str):
        self.file_path = file_path
    
    def load(self) -> List[Document]:
        """íŒŒì¼ ë¡œë“œ ì‹œë®¬ë ˆì´ì…˜"""
        # ì‹¤ì œë¡œëŠ” íŒŒì¼ì„ ì½ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜
        content = f"[{self.file_path}ì˜ ë‚´ìš©]\n" + "ìƒ˜í”Œ í…ìŠ¤íŠ¸ " * 50
        
        return [Document(
            page_content=content,
            metadata={"source": self.file_path}
        )]


class PDFLoader:
    """PDF ë¡œë” ì‹œë®¬ë ˆì´ì…˜"""
    
    def __init__(self, file_path: str):
        self.file_path = file_path
    
    def load(self) -> List[Document]:
        """PDF í˜ì´ì§€ë³„ ë¡œë“œ ì‹œë®¬ë ˆì´ì…˜"""
        # 3ê°œ í˜ì´ì§€ ì‹œë®¬ë ˆì´ì…˜
        pages = []
        for i in range(3):
            content = f"PDF í˜ì´ì§€ {i+1}ì˜ ë‚´ìš©ì…ë‹ˆë‹¤. " + "í…ìŠ¤íŠ¸ " * 30
            pages.append(Document(
                page_content=content,
                metadata={"source": self.file_path, "page": i}
            ))
        
        return pages


class CSVLoader:
    """CSV ë¡œë” ì‹œë®¬ë ˆì´ì…˜"""
    
    def __init__(self, file_path: str):
        self.file_path = file_path
    
    def load(self) -> List[Document]:
        """CSV í–‰ë³„ ë¡œë“œ ì‹œë®¬ë ˆì´ì…˜"""
        rows = [
            {"name": "Alice", "age": 30, "city": "Seoul"},
            {"name": "Bob", "age": 25, "city": "Busan"},
            {"name": "Charlie", "age": 35, "city": "Incheon"}
        ]
        
        docs = []
        for i, row in enumerate(rows):
            content = ", ".join([f"{k}: {v}" for k, v in row.items()])
            docs.append(Document(
                page_content=content,
                metadata={"source": self.file_path, "row": i}
            ))
        
        return docs


def demo_loaders():
    """Document Loader ë°ëª¨"""
    print("\n" + "="*60)
    print("ğŸ“„ Document Loader ë°ëª¨")
    print("="*60)
    
    # í…ìŠ¤íŠ¸ ë¡œë”
    text_loader = TextLoader("sample.txt")
    text_docs = text_loader.load()
    print(f"\n[TextLoader]")
    print(f"  ë¬¸ì„œ ìˆ˜: {len(text_docs)}")
    print(f"  ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {text_docs[0].page_content[:50]}...")
    
    # PDF ë¡œë”
    pdf_loader = PDFLoader("sample.pdf")
    pdf_docs = pdf_loader.load()
    print(f"\n[PDFLoader]")
    print(f"  í˜ì´ì§€ ìˆ˜: {len(pdf_docs)}")
    for doc in pdf_docs:
        print(f"  - í˜ì´ì§€ {doc.metadata['page']}: {doc.page_content[:30]}...")
    
    # CSV ë¡œë”
    csv_loader = CSVLoader("sample.csv")
    csv_docs = csv_loader.load()
    print(f"\n[CSVLoader]")
    print(f"  í–‰ ìˆ˜: {len(csv_docs)}")
    for doc in csv_docs:
        print(f"  - í–‰ {doc.metadata['row']}: {doc.page_content}")


# ============================================================
# Part 3: Text Splitter êµ¬í˜„
# ============================================================

class CharacterTextSplitter:
    """ë¬¸ì ê¸°ë°˜ í…ìŠ¤íŠ¸ ë¶„í• ê¸°"""
    
    def __init__(self, separator: str = "\n", chunk_size: int = 100,
                 chunk_overlap: int = 20, length_function=len):
        self.separator = separator
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap
        self.length_function = length_function
    
    def split_text(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• """
        # êµ¬ë¶„ìë¡œ ë¶„í• 
        splits = text.split(self.separator)
        
        chunks = []
        current_chunk = []
        current_length = 0
        
        for split in splits:
            split_length = self.length_function(split)
            
            if current_length + split_length > self.chunk_size and current_chunk:
                # í˜„ì¬ ì²­í¬ ì €ì¥
                chunk_text = self.separator.join(current_chunk)
                chunks.append(chunk_text)
                
                # Overlap ì²˜ë¦¬
                overlap_text = chunk_text[-self.chunk_overlap:] if self.chunk_overlap > 0 else ""
                current_chunk = [overlap_text] if overlap_text else []
                current_length = len(overlap_text)
            
            current_chunk.append(split)
            current_length += split_length + len(self.separator)
        
        # ë§ˆì§€ë§‰ ì²­í¬
        if current_chunk:
            chunks.append(self.separator.join(current_chunk))
        
        return chunks
    
    def split_documents(self, documents: List[Document]) -> List[Document]:
        """Document ë¦¬ìŠ¤íŠ¸ ë¶„í• """
        result = []
        for doc in documents:
            chunks = self.split_text(doc.page_content)
            for i, chunk in enumerate(chunks):
                result.append(Document(
                    page_content=chunk,
                    metadata={**doc.metadata, "chunk": i}
                ))
        return result


class RecursiveCharacterTextSplitter:
    """ì¬ê·€ì  ë¬¸ì í…ìŠ¤íŠ¸ ë¶„í• ê¸°"""
    
    def __init__(self, separators: List[str] = None, chunk_size: int = 100,
                 chunk_overlap: int = 20):
        self.separators = separators or ["\n\n", "\n", ". ", " ", ""]
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap
    
    def split_text(self, text: str) -> List[str]:
        """ì¬ê·€ì ìœ¼ë¡œ í…ìŠ¤íŠ¸ ë¶„í• """
        return self._split_text_recursive(text, self.separators)
    
    def _split_text_recursive(self, text: str, separators: List[str]) -> List[str]:
        if not text:
            return []
        
        # í˜„ì¬ êµ¬ë¶„ì
        separator = separators[0] if separators else ""
        remaining_separators = separators[1:] if len(separators) > 1 else []
        
        # êµ¬ë¶„ìë¡œ ë¶„í• 
        if separator:
            splits = text.split(separator)
        else:
            # ë§ˆì§€ë§‰ ìˆ˜ë‹¨: ë¬¸ì ë‹¨ìœ„ ë¶„í• 
            splits = list(text)
        
        chunks = []
        current_chunk = []
        current_length = 0
        
        for split in splits:
            split_length = len(split)
            
            if current_length + split_length > self.chunk_size:
                if current_chunk:
                    chunk_text = separator.join(current_chunk)
                    
                    # ì²­í¬ê°€ ë„ˆë¬´ í¬ë©´ ì¬ê·€ì ìœ¼ë¡œ ë” ë¶„í• 
                    if len(chunk_text) > self.chunk_size and remaining_separators:
                        sub_chunks = self._split_text_recursive(chunk_text, remaining_separators)
                        chunks.extend(sub_chunks)
                    else:
                        chunks.append(chunk_text)
                    
                    # Overlap ì²˜ë¦¬ (ê°„ì†Œí™”)
                    current_chunk = []
                    current_length = 0
            
            current_chunk.append(split)
            current_length += split_length + len(separator)
        
        # ë§ˆì§€ë§‰ ì²­í¬
        if current_chunk:
            chunk_text = separator.join(current_chunk)
            if len(chunk_text) > self.chunk_size and remaining_separators:
                sub_chunks = self._split_text_recursive(chunk_text, remaining_separators)
                chunks.extend(sub_chunks)
            else:
                chunks.append(chunk_text)
        
        return chunks
    
    def split_documents(self, documents: List[Document]) -> List[Document]:
        """Document ë¦¬ìŠ¤íŠ¸ ë¶„í• """
        result = []
        for doc in documents:
            chunks = self.split_text(doc.page_content)
            for i, chunk in enumerate(chunks):
                result.append(Document(
                    page_content=chunk,
                    metadata={**doc.metadata, "chunk": i}
                ))
        return result


def demo_text_splitter():
    """Text Splitter ë°ëª¨"""
    print("\n" + "="*60)
    print("âœ‚ï¸ Text Splitter ë°ëª¨")
    print("="*60)
    
    # ìƒ˜í”Œ í…ìŠ¤íŠ¸
    sample_text = """ì¸ê³µì§€ëŠ¥(AI)ì€ ì»´í“¨í„°ê°€ ì¸ê°„ì˜ ì§€ëŠ¥ì„ ëª¨ë°©í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. 
    
ë¨¸ì‹ ëŸ¬ë‹ì€ AIì˜ í•œ ë¶„ì•¼ì…ë‹ˆë‹¤. ë°ì´í„°ì—ì„œ íŒ¨í„´ì„ í•™ìŠµí•©ë‹ˆë‹¤.
ë”¥ëŸ¬ë‹ì€ ë¨¸ì‹ ëŸ¬ë‹ì˜ í•œ ë°©ë²•ì…ë‹ˆë‹¤. ì‹ ê²½ë§ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

ìì—°ì–´ ì²˜ë¦¬(NLP)ëŠ” ì»´í“¨í„°ê°€ í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.
LLMì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ì•½ìì…ë‹ˆë‹¤. GPTê°€ ëŒ€í‘œì ì¸ ì˜ˆì‹œì…ë‹ˆë‹¤."""
    
    print(f"\n[ì›ë³¸ í…ìŠ¤íŠ¸]")
    print(f"ê¸¸ì´: {len(sample_text)}ì")
    print(sample_text[:100] + "...")
    
    # CharacterTextSplitter
    char_splitter = CharacterTextSplitter(
        separator="\n\n",
        chunk_size=150,
        chunk_overlap=30
    )
    char_chunks = char_splitter.split_text(sample_text)
    
    print(f"\n[CharacterTextSplitter] (separator='\\n\\n', chunk_size=150)")
    print(f"ì²­í¬ ìˆ˜: {len(char_chunks)}")
    for i, chunk in enumerate(char_chunks):
        print(f"  ì²­í¬ {i+1} ({len(chunk)}ì): {chunk[:50]}...")
    
    # RecursiveCharacterTextSplitter
    recursive_splitter = RecursiveCharacterTextSplitter(
        separators=["\n\n", "\n", ". ", " "],
        chunk_size=100,
        chunk_overlap=20
    )
    recursive_chunks = recursive_splitter.split_text(sample_text)
    
    print(f"\n[RecursiveCharacterTextSplitter] (chunk_size=100)")
    print(f"ì²­í¬ ìˆ˜: {len(recursive_chunks)}")
    for i, chunk in enumerate(recursive_chunks):
        print(f"  ì²­í¬ {i+1} ({len(chunk)}ì): {chunk[:50]}...")


# ============================================================
# Part 4: Chunk Overlap ì‹œê°í™”
# ============================================================

def visualize_overlap():
    """Chunk Overlap ì‹œê°í™”"""
    print("\n" + "="*60)
    print("ğŸ”— Chunk Overlap ì‹œê°í™”")
    print("="*60)
    
    text = "ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789"
    
    chunk_size = 12
    overlaps = [0, 3, 6]
    
    for overlap in overlaps:
        print(f"\n[chunk_overlap={overlap}]")
        
        chunks = []
        start = 0
        while start < len(text):
            end = min(start + chunk_size, len(text))
            chunks.append((start, end, text[start:end]))
            start = end - overlap
            if start >= len(text) - overlap:
                break
        
        # ì‹œê°í™”
        print(f"ì›ë³¸: {text}")
        print("-" * (len(text) + 10))
        
        for i, (s, e, chunk) in enumerate(chunks):
            padding = " " * s
            print(f"ì²­í¬{i+1}: {padding}{chunk}")
        
        print(f"ì²­í¬ ìˆ˜: {len(chunks)}")


# ============================================================
# Part 5: Document ë¶„í•  ì›Œí¬í”Œë¡œìš°
# ============================================================

def demo_workflow():
    """ì „ì²´ ì›Œí¬í”Œë¡œìš° ë°ëª¨"""
    print("\n" + "="*60)
    print("ğŸ”„ ì „ì²´ ì›Œí¬í”Œë¡œìš° ë°ëª¨")
    print("="*60)
    
    # 1. ë¬¸ì„œ ë¡œë“œ
    loader = PDFLoader("sample.pdf")
    docs = loader.load()
    print(f"\n1. ë¬¸ì„œ ë¡œë“œ: {len(docs)}ê°œ í˜ì´ì§€")
    
    # 2. í…ìŠ¤íŠ¸ ë¶„í• 
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=50,
        chunk_overlap=10
    )
    chunks = splitter.split_documents(docs)
    print(f"2. í…ìŠ¤íŠ¸ ë¶„í• : {len(chunks)}ê°œ ì²­í¬")
    
    # 3. ê²°ê³¼ í™•ì¸
    print("\n3. ë¶„í•  ê²°ê³¼:")
    for i, chunk in enumerate(chunks[:5]):
        print(f"  ì²­í¬ {i+1}:")
        print(f"    ë‚´ìš©: {chunk.page_content[:40]}...")
        print(f"    ë©”íƒ€ë°ì´í„°: {chunk.metadata}")


# ============================================================
# Part 6: LangChain ì‹¤ì œ ì‚¬ìš© (ì„ íƒì )
# ============================================================

def demo_langchain_splitter():
    """LangChain Text Splitter ì‚¬ìš©"""
    try:
        from langchain_text_splitters import RecursiveCharacterTextSplitter
        
        print("\n" + "="*60)
        print("ğŸš€ LangChain Text Splitter ë°ëª¨")
        print("="*60)
        
        text = "ê¸´ ë¬¸ì„œ ë‚´ìš©ì…ë‹ˆë‹¤. " * 50
        
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=100,
            chunk_overlap=20,
            length_function=len,
            separators=["\n\n", "\n", ". ", " ", ""]
        )
        
        chunks = splitter.split_text(text)
        
        print(f"ì›ë³¸ ê¸¸ì´: {len(text)}")
        print(f"ì²­í¬ ìˆ˜: {len(chunks)}")
        for i, chunk in enumerate(chunks[:3]):
            print(f"  ì²­í¬ {i+1} ({len(chunk)}ì): {chunk[:30]}...")
        
    except ImportError:
        print("\nâš ï¸ langchain-text-splittersê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ì„¤ì¹˜: pip install langchain-text-splitters")


# ============================================================
# ë©”ì¸ í•¨ìˆ˜
# ============================================================

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("="*60)
    print("ğŸ¤– Chapter 04: Document Loaders & Text Splitters ì‹¤ìŠµ")
    print("="*60)
    
    demo_loaders()
    demo_text_splitter()
    visualize_overlap()
    demo_workflow()
    demo_langchain_splitter()
    
    print("\n" + "="*60)
    print("âœ… ì‹¤ìŠµ ì™„ë£Œ!")
    print("="*60)


if __name__ == "__main__":
    main()

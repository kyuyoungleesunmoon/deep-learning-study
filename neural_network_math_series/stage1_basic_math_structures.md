# Stage 1: ì¸ê³µ ì‹ ê²½ë§ í•™ìŠµì—ì„œ ì‚¬ìš©í•˜ëŠ” ê¸°ë³¸ ìˆ˜í•™ êµ¬ì¡° ê°œìš”

## ğŸ“š ëª©ì°¨
1. [ìŠ¤ì¹¼ë¼ (Scalar)](#1-ìŠ¤ì¹¼ë¼-scalar)
2. [ë²¡í„° (Vector)](#2-ë²¡í„°-vector)
3. [í–‰ë ¬ (Matrix)](#3-í–‰ë ¬-matrix)
4. [ì„ í˜• ë³€í™˜ (Linear Transformation)](#4-ì„ í˜•-ë³€í™˜-linear-transformation)
5. [Python ì‹œê°í™”](#5-python-ì‹œê°í™”)

---

## 1. ìŠ¤ì¹¼ë¼ (Scalar)

### 1.1 ì •ì˜
ìŠ¤ì¹¼ë¼ëŠ” í•˜ë‚˜ì˜ ìˆ˜ì¹˜ë¡œ í‘œí˜„ë˜ëŠ” ê°’ì…ë‹ˆë‹¤. í¬ê¸°(magnitude)ë§Œ ê°€ì§€ê³  ë°©í–¥ì€ ì—†ìŠµë‹ˆë‹¤.

### 1.2 ìˆ˜í•™ì  í‘œí˜„
$$
s \in \mathbb{R}
$$

**ê¸°í˜¸ ì„¤ëª…:**
- $s$: ìŠ¤ì¹¼ë¼ ê°’
- $\mathbb{R}$: ì‹¤ìˆ˜ ì§‘í•© (Real numbers)
- $\in$: "ì†í•œë‹¤" (belongs to)

### 1.3 ì‹¤ìƒí™œ ì˜ˆì‹œ
- **ì˜¨ë„**: 25Â°C (ë‹¨ìˆœíˆ í¬ê¸°ë§Œ ë‚˜íƒ€ëƒ„)
- **ëª¸ë¬´ê²Œ**: 70kg
- **ë‚˜ì´**: 30ì„¸
- **ì‹ ê²½ë§ì—ì„œ**: í•™ìŠµë¥ (learning rate), í¸í–¥(bias) ê°’

### 1.4 ìˆ˜ì¹˜ ì˜ˆì œ
```
sâ‚ = 3.14
sâ‚‚ = -2.5
sâ‚ƒ = 0.001
```

---

## 2. ë²¡í„° (Vector)

### 2.1 ì •ì˜
ë²¡í„°ëŠ” ì—¬ëŸ¬ ê°œì˜ ìˆ˜ì¹˜ë¥¼ ìˆœì„œëŒ€ë¡œ ë‚˜ì—´í•œ ê²ƒì…ë‹ˆë‹¤. í¬ê¸°ì™€ ë°©í–¥ì„ ëª¨ë‘ ê°€ì§‘ë‹ˆë‹¤.

### 2.2 ìˆ˜í•™ì  í‘œí˜„

**ì—´ ë²¡í„° (Column Vector):**

$$
\mathbf{v} = \begin{bmatrix} v_1 \\ v_2 \\ \vdots \\ v_n \end{bmatrix} \in \mathbb{R}^n
$$

**í–‰ ë²¡í„° (Row Vector):**

$$
\mathbf{v}^T = \begin{bmatrix} v_1 & v_2 & \cdots & v_n \end{bmatrix}
$$

**ê¸°í˜¸ ì„¤ëª…:**

- $\mathbf{v}$: ë²¡í„° (êµµì€ ê¸€ì”¨ë¡œ í‘œê¸°)
- $v_i$: ë²¡í„°ì˜ $i$ë²ˆì§¸ ì›ì†Œ (element)
- $n$: ë²¡í„°ì˜ ì°¨ì› (dimension)
- $\mathbb{R}^n$: $n$ì°¨ì› ì‹¤ìˆ˜ ê³µê°„
- $\mathbf{v}^T$: ë²¡í„°ì˜ ì „ì¹˜ (transpose)

### 2.3 ì‹¤ìƒí™œ ì˜ˆì‹œ
- **ìœ„ì¹˜**: ì§‘ì˜ ì¢Œí‘œ (ìœ„ë„, ê²½ë„) = [37.5, 127.0]
- **ì†ë„**: ìë™ì°¨ì˜ ì†ë„ (ë™ìª½ 50km/h, ë¶ìª½ 30km/h) = [50, 30]
- **RGB ìƒ‰ìƒ**: ë¹¨ê°•, ì´ˆë¡, íŒŒë‘ = [255, 0, 128]
- **ì‹ ê²½ë§ì—ì„œ**: ì…ë ¥ ë°ì´í„°, íŠ¹ì„±(features), ê°€ì¤‘ì¹˜(weights)

### 2.4 ìˆ˜ì¹˜ ì˜ˆì œ

**2ì°¨ì› ë²¡í„°:**

$$
\mathbf{x} = \begin{bmatrix} 3 \\ 4 \end{bmatrix}
$$

**ë²¡í„°ì˜ í¬ê¸° (Norm):**

$$
\|\mathbf{x}\| = \sqrt{x_1^2 + x_2^2} = \sqrt{3^2 + 4^2} = \sqrt{25} = 5
$$

**ê¸°í˜¸ ì„¤ëª…:**

- $\|\mathbf{x}\|$: ë²¡í„°ì˜ í¬ê¸° (ë˜ëŠ” ë…¸ë¦„, norm)
- $\sqrt{\cdot}$: ì œê³±ê·¼

### 2.5 ë²¡í„° ì—°ì‚°

#### 2.5.1 ë²¡í„° ë§ì…ˆ

$$
\mathbf{a} + \mathbf{b} = \begin{bmatrix} a_1 \\ a_2 \end{bmatrix} + \begin{bmatrix} b_1 \\ b_2 \end{bmatrix} = \begin{bmatrix} a_1 + b_1 \\ a_2 + b_2 \end{bmatrix}
$$

**ì˜ˆì œ:**

$$
\begin{bmatrix} 2 \\ 3 \end{bmatrix} + \begin{bmatrix} 1 \\ 4 \end{bmatrix} = \begin{bmatrix} 3 \\ 7 \end{bmatrix}
$$

#### 2.5.2 ìŠ¤ì¹¼ë¼ ê³± (Scalar Multiplication)

$$
c \cdot \mathbf{v} = c \cdot \begin{bmatrix} v_1 \\ v_2 \end{bmatrix} = \begin{bmatrix} c \cdot v_1 \\ c \cdot v_2 \end{bmatrix}
$$

**ì˜ˆì œ:**

$$
2 \cdot \begin{bmatrix} 3 \\ 4 \end{bmatrix} = \begin{bmatrix} 6 \\ 8 \end{bmatrix}
$$

#### 2.5.3 ë‚´ì  (Dot Product / Inner Product)

$$
\mathbf{a} \cdot \mathbf{b} = a_1 b_1 + a_2 b_2 + \cdots + a_n b_n = \sum_{i=1}^{n} a_i b_i
$$

**ê¸°í˜¸ ì„¤ëª…:**

- $\cdot$: ë‚´ì  ì—°ì‚°ì
- $\sum$: í•© (summation)
- $i=1$ë¶€í„° $n$ê¹Œì§€: ì¸ë±ìŠ¤ì˜ ë²”ìœ„

**ì˜ˆì œ:**

$$
\begin{bmatrix} 2 \\ 3 \end{bmatrix} \cdot \begin{bmatrix} 4 \\ 5 \end{bmatrix} = (2 \times 4) + (3 \times 5) = 8 + 15 = 23
$$

**ì‹¤ìƒí™œ ì˜ë¯¸**: ë‘ ë²¡í„°ê°€ ì–¼ë§ˆë‚˜ ê°™ì€ ë°©í–¥ì„ ê°€ë¦¬í‚¤ëŠ”ì§€ ì¸¡ì •
- ë‚´ì  > 0: ê°™ì€ ë°©í–¥
- ë‚´ì  = 0: ìˆ˜ì§ (ì§êµ)
- ë‚´ì  < 0: ë°˜ëŒ€ ë°©í–¥

---

## 3. í–‰ë ¬ (Matrix)

### 3.1 ì •ì˜
í–‰ë ¬ì€ ìˆ«ìë“¤ì„ 2ì°¨ì› ë°°ì—´ë¡œ ë°°ì¹˜í•œ ê²ƒì…ë‹ˆë‹¤. ì—¬ëŸ¬ ë²¡í„°ë¥¼ ëª¨ì•„ë†“ì€ ê²ƒìœ¼ë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### 3.2 ìˆ˜í•™ì  í‘œí˜„

$$
\mathbf{A} = \begin{bmatrix}
a_{11} & a_{12} & \cdots & a_{1n} \\
a_{21} & a_{22} & \cdots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{m1} & a_{m2} & \cdots & a_{mn}
\end{bmatrix} \in \mathbb{R}^{m \times n}
$$

**ê¸°í˜¸ ì„¤ëª…:**

- $\mathbf{A}$: í–‰ë ¬ (ëŒ€ë¬¸ì êµµì€ ê¸€ì”¨)
- $a_{ij}$: $i$ë²ˆì§¸ í–‰(row), $j$ë²ˆì§¸ ì—´(column)ì˜ ì›ì†Œ
- $m$: í–‰ì˜ ê°œìˆ˜
- $n$: ì—´ì˜ ê°œìˆ˜
- $\mathbb{R}^{m \times n}$: $m \times n$ í¬ê¸°ì˜ ì‹¤ìˆ˜ í–‰ë ¬ ê³µê°„

### 3.3 ì‹¤ìƒí™œ ì˜ˆì‹œ

- **ì´ë¯¸ì§€**: í”½ì…€ì„ í–‰ë ¬ë¡œ í‘œí˜„ (ì˜ˆ: 28x28 ì´ë¯¸ì§€ = 28x28 í–‰ë ¬)
- **í•™ìƒ ì„±ì í‘œ**: í•™ìƒ(í–‰) Ã— ê³¼ëª©(ì—´)
- **ê±°ë¦¬ í–‰ë ¬**: ë„ì‹œ ê°„ ê±°ë¦¬
- **ì‹ ê²½ë§ì—ì„œ**: ê°€ì¤‘ì¹˜ í–‰ë ¬ (ì—¬ëŸ¬ ì…ë ¥ì„ ì—¬ëŸ¬ ì¶œë ¥ìœ¼ë¡œ ë³€í™˜)

### 3.4 ìˆ˜ì¹˜ ì˜ˆì œ

**2Ã—3 í–‰ë ¬:**

$$
\mathbf{A} = \begin{bmatrix}
1 & 2 & 3 \\
4 & 5 & 6
\end{bmatrix}
$$

- 2ê°œì˜ í–‰, 3ê°œì˜ ì—´
- $a_{11} = 1$, $a_{12} = 2$, $a_{23} = 6$

### 3.5 í–‰ë ¬ ì—°ì‚°

#### 3.5.1 í–‰ë ¬ ë§ì…ˆ

$$
\mathbf{A} + \mathbf{B} = \begin{bmatrix}
a_{11} + b_{11} & a_{12} + b_{12} \\
a_{21} + b_{21} & a_{22} + b_{22}
\end{bmatrix}
$$

**ì¡°ê±´**: ë‘ í–‰ë ¬ì˜ í¬ê¸°ê°€ ê°™ì•„ì•¼ í•¨

**ì˜ˆì œ:**

$$
\begin{bmatrix} 1 & 2 \\ 3 & 4 \end{bmatrix} + \begin{bmatrix} 5 & 6 \\ 7 & 8 \end{bmatrix} = \begin{bmatrix} 6 & 8 \\ 10 & 12 \end{bmatrix}
$$

#### 3.5.2 í–‰ë ¬-ë²¡í„° ê³± (Matrix-Vector Multiplication)

$$
\mathbf{A}\mathbf{x} = \begin{bmatrix}
a_{11} & a_{12} \\
a_{21} & a_{22}
\end{bmatrix} \begin{bmatrix} x_1 \\ x_2 \end{bmatrix} = \begin{bmatrix}
a_{11}x_1 + a_{12}x_2 \\
a_{21}x_1 + a_{22}x_2
\end{bmatrix}
$$

**ì˜ˆì œ:**

$$
\begin{bmatrix} 2 & 3 \\ 4 & 5 \end{bmatrix} \begin{bmatrix} 1 \\ 2 \end{bmatrix} = \begin{bmatrix} 2 \cdot 1 + 3 \cdot 2 \\ 4 \cdot 1 + 5 \cdot 2 \end{bmatrix} = \begin{bmatrix} 8 \\ 14 \end{bmatrix}
$$

**í•´ì„**: ê° í–‰ê³¼ ë²¡í„°ì˜ ë‚´ì  ê²°ê³¼ë¥¼ ëª¨ì€ ê²ƒ

#### 3.5.3 í–‰ë ¬ ê³±ì…ˆ (Matrix Multiplication)

$$
\mathbf{C} = \mathbf{A}\mathbf{B}
$$

ì—¬ê¸°ì„œ $c_{ij}$ëŠ” $\mathbf{A}$ì˜ $i$ë²ˆì§¸ í–‰ê³¼ $\mathbf{B}$ì˜ $j$ë²ˆì§¸ ì—´ì˜ ë‚´ì :
$$
c_{ij} = \sum_{k=1}^{p} a_{ik} b_{kj}
$$

**ì¡°ê±´**: $\mathbf{A} \in \mathbb{R}^{m \times p}$, $\mathbf{B} \in \mathbb{R}^{p \times n}$ â†’ $\mathbf{C} \in \mathbb{R}^{m \times n}$

**ì˜ˆì œ:**

$$
\begin{bmatrix} 1 & 2 \\ 3 & 4 \end{bmatrix} \begin{bmatrix} 5 & 6 \\ 7 & 8 \end{bmatrix} = \begin{bmatrix} 1 \cdot 5 + 2 \cdot 7 & 1 \cdot 6 + 2 \cdot 8 \\ 3 \cdot 5 + 4 \cdot 7 & 3 \cdot 6 + 4 \cdot 8 \end{bmatrix} = \begin{bmatrix} 19 & 22 \\ 43 & 50 \end{bmatrix}
$$

---

## 4. ì„ í˜• ë³€í™˜ (Linear Transformation)

### 4.1 ì •ì˜
ì„ í˜• ë³€í™˜ì€ ë²¡í„° ê³µê°„ì˜ ë²¡í„°ë¥¼ ë‹¤ë¥¸ ë²¡í„° ê³µê°„ì˜ ë²¡í„°ë¡œ ë§¤í•‘í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

### 4.2 ìˆ˜í•™ì  í‘œí˜„

$$
\mathbf{y} = \mathbf{A}\mathbf{x} + \mathbf{b}
$$

**ê¸°í˜¸ ì„¤ëª…:**

- $\mathbf{x} \in \mathbb{R}^n$: ì…ë ¥ ë²¡í„°
- $\mathbf{A} \in \mathbb{R}^{m \times n}$: ë³€í™˜ í–‰ë ¬ (ê°€ì¤‘ì¹˜)
- $\mathbf{b} \in \mathbb{R}^m$: í¸í–¥ ë²¡í„° (bias)
- $\mathbf{y} \in \mathbb{R}^m$: ì¶œë ¥ ë²¡í„°

### 4.3 ì„ í˜• ë³€í™˜ì˜ ì„±ì§ˆ

í•¨ìˆ˜ $f(\mathbf{x})$ê°€ ì„ í˜• ë³€í™˜ì´ë ¤ë©´ ë‹¤ìŒ ë‘ ì¡°ê±´ì„ ë§Œì¡±í•´ì•¼ í•©ë‹ˆë‹¤:

**1. ê°€ë²•ì„± (Additivity):**

$$
f(\mathbf{x} + \mathbf{y}) = f(\mathbf{x}) + f(\mathbf{y})
$$

**2. ë™ì°¨ì„± (Homogeneity):**

$$
f(c\mathbf{x}) = c \cdot f(\mathbf{x})
$$

ì—¬ê¸°ì„œ $c$ëŠ” ìŠ¤ì¹¼ë¼

### 4.4 ì‹¤ìƒí™œ ì˜ˆì‹œ

- **í™”ë©´ íšŒì „**: ì´ë¯¸ì§€ë¥¼ 90ë„ íšŒì „ì‹œí‚¤ê¸°
- **í¬ê¸° ì¡°ì •**: ì´ë¯¸ì§€ë¥¼ 2ë°°ë¡œ í™•ëŒ€í•˜ê¸°
- **ì¢Œí‘œ ë³€í™˜**: GPS ì¢Œí‘œë¥¼ í™”ë©´ ì¢Œí‘œë¡œ ë³€í™˜
- **ì‹ ê²½ë§ì—ì„œ**: ì…ë ¥ì¸µì—ì„œ ì€ë‹‰ì¸µìœ¼ë¡œ ë°ì´í„° ë³€í™˜ ($\mathbf{h} = \mathbf{W}\mathbf{x} + \mathbf{b}$)

### 4.5 ìˆ˜ì¹˜ ì˜ˆì œ

2ì°¨ì› ê³µê°„ì—ì„œ íšŒì „ ë³€í™˜ (45ë„ ë°˜ì‹œê³„ë°©í–¥):

**íšŒì „ í–‰ë ¬:**

$$
\mathbf{R} = \begin{bmatrix}
\cos(45Â°) & -\sin(45Â°) \\
\sin(45Â°) & \cos(45Â°)
\end{bmatrix} \approx \begin{bmatrix}
0.707 & -0.707 \\
0.707 & 0.707
\end{bmatrix}
$$

**ì…ë ¥ ë²¡í„°:**

$$
\mathbf{x} = \begin{bmatrix} 1 \\ 0 \end{bmatrix}
$$

**ë³€í™˜ëœ ë²¡í„°:**

$$
\mathbf{y} = \mathbf{R}\mathbf{x} = \begin{bmatrix}
0.707 & -0.707 \\
0.707 & 0.707
\end{bmatrix} \begin{bmatrix} 1 \\ 0 \end{bmatrix} = \begin{bmatrix} 0.707 \\ 0.707 \end{bmatrix}
$$

**í•´ì„**: ì  (1, 0)ì´ 45ë„ íšŒì „í•˜ì—¬ (0.707, 0.707)ë¡œ ì´ë™

### 4.6 ì‹ ê²½ë§ì—ì„œì˜ ì„ í˜• ë³€í™˜

ì‹ ê²½ë§ì˜ ê° ì¸µì€ ì„ í˜• ë³€í™˜ìœ¼ë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

$$
\mathbf{z} = \mathbf{W}\mathbf{x} + \mathbf{b}
$$

**ì˜ˆì œ: 3ê°œ ì…ë ¥ â†’ 2ê°œ ì¶œë ¥**

$$
\begin{bmatrix} z_1 \\ z_2 \end{bmatrix} = \begin{bmatrix}
w_{11} & w_{12} & w_{13} \\
w_{21} & w_{22} & w_{23}
\end{bmatrix} \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix} + \begin{bmatrix} b_1 \\ b_2 \end{bmatrix}
$$

**êµ¬ì²´ì  ê°’:**

$$
\begin{bmatrix} z_1 \\ z_2 \end{bmatrix} = \begin{bmatrix}
0.5 & 0.3 & 0.2 \\
0.7 & 0.4 & 0.6
\end{bmatrix} \begin{bmatrix} 1.0 \\ 2.0 \\ 3.0 \end{bmatrix} + \begin{bmatrix} 0.1 \\ 0.2 \end{bmatrix}
$$

**ê³„ì‚°:**

$$
z_1 = (0.5 \times 1.0) + (0.3 \times 2.0) + (0.2 \times 3.0) + 0.1 = 0.5 + 0.6 + 0.6 + 0.1 = 1.8
$$
$$
z_2 = (0.7 \times 1.0) + (0.4 \times 2.0) + (0.6 \times 3.0) + 0.2 = 0.7 + 0.8 + 1.8 + 0.2 = 3.5
$$

$$
\mathbf{z} = \begin{bmatrix} 1.8 \\ 3.5 \end{bmatrix}
$$

---

## 5. Python ì‹œê°í™”

ë‹¤ìŒì€ ìœ„ì—ì„œ ë°°ìš´ ê°œë…ë“¤ì„ Pythonìœ¼ë¡œ ì‹œê°í™”í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤.

### 5.1 ë²¡í„° ì‹œê°í™” ì½”ë“œ

```python
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import rcParams

# í•œê¸€ í°íŠ¸ ì„¤ì •
rcParams['font.family'] = 'DejaVu Sans'

# ê·¸ë¦¼ í¬ê¸° ì„¤ì •
fig, axes = plt.subplots(2, 2, figsize=(14, 12))

# ========== 1. ë²¡í„° í‘œí˜„ ==========
ax1 = axes[0, 0]
# ì›ì 
origin = [0, 0]
# ë²¡í„° ì •ì˜
v1 = [3, 4]
v2 = [2, -1]

# ë²¡í„° ê·¸ë¦¬ê¸°
ax1.quiver(*origin, *v1, angles='xy', scale_units='xy', scale=1, color='blue', width=0.006, label='v1 = [3, 4]')
ax1.quiver(*origin, *v2, angles='xy', scale_units='xy', scale=1, color='red', width=0.006, label='v2 = [2, -1]')

# ê²©ì ë° ì¶• ì„¤ì •
ax1.set_xlim(-1, 5)
ax1.set_ylim(-2, 5)
ax1.set_aspect('equal')
ax1.grid(True, alpha=0.3)
ax1.axhline(y=0, color='k', linewidth=0.5)
ax1.axvline(x=0, color='k', linewidth=0.5)
ax1.set_xlabel('x', fontsize=12)
ax1.set_ylabel('y', fontsize=12)
ax1.set_title('Vectors in 2D Space', fontsize=14, fontweight='bold')
ax1.legend(fontsize=10)

# ë²¡í„° í¬ê¸° í‘œì‹œ
magnitude_v1 = np.sqrt(v1[0]**2 + v1[1]**2)
ax1.text(1.5, 2.5, f'||v1|| = {magnitude_v1:.2f}', fontsize=10, color='blue')

# ========== 2. ë²¡í„° ë§ì…ˆ ==========
ax2 = axes[0, 1]
a = [2, 3]
b = [1, 4]
c = [a[0] + b[0], a[1] + b[1]]  # ë²¡í„° í•©

ax2.quiver(*origin, *a, angles='xy', scale_units='xy', scale=1, color='blue', width=0.006, label='a = [2, 3]')
ax2.quiver(*a, *b, angles='xy', scale_units='xy', scale=1, color='red', width=0.006, label='b = [1, 4]')
ax2.quiver(*origin, *c, angles='xy', scale_units='xy', scale=1, color='green', width=0.008, label='a + b = [3, 7]', linestyle='--')

ax2.set_xlim(-1, 5)
ax2.set_ylim(-1, 8)
ax2.set_aspect('equal')
ax2.grid(True, alpha=0.3)
ax2.axhline(y=0, color='k', linewidth=0.5)
ax2.axvline(x=0, color='k', linewidth=0.5)
ax2.set_xlabel('x', fontsize=12)
ax2.set_ylabel('y', fontsize=12)
ax2.set_title('Vector Addition', fontsize=14, fontweight='bold')
ax2.legend(fontsize=10)

# ========== 3. ë‚´ì  ì‹œê°í™” ==========
ax3 = axes[1, 0]
v_a = np.array([4, 2])
v_b = np.array([3, 3])
dot_product = np.dot(v_a, v_b)

ax3.quiver(*origin, *v_a, angles='xy', scale_units='xy', scale=1, color='blue', width=0.006, label=f'a = {v_a}')
ax3.quiver(*origin, *v_b, angles='xy', scale_units='xy', scale=1, color='red', width=0.006, label=f'b = {v_b}')

# ê°ë„ ê³„ì‚°
cos_angle = dot_product / (np.linalg.norm(v_a) * np.linalg.norm(v_b))
angle = np.arccos(cos_angle) * 180 / np.pi

ax3.set_xlim(-1, 5)
ax3.set_ylim(-1, 5)
ax3.set_aspect('equal')
ax3.grid(True, alpha=0.3)
ax3.axhline(y=0, color='k', linewidth=0.5)
ax3.axvline(x=0, color='k', linewidth=0.5)
ax3.set_xlabel('x', fontsize=12)
ax3.set_ylabel('y', fontsize=12)
ax3.set_title('Dot Product', fontsize=14, fontweight='bold')
ax3.legend(fontsize=10)
ax3.text(2, 4, f'a Â· b = {dot_product}', fontsize=12, color='purple', fontweight='bold')
ax3.text(2, 3.5, f'angle = {angle:.1f}Â°', fontsize=10, color='purple')

# ========== 4. ì„ í˜• ë³€í™˜ (íšŒì „) ==========
ax4 = axes[1, 1]
# 45ë„ íšŒì „ í–‰ë ¬
theta = np.pi / 4  # 45ë„
R = np.array([[np.cos(theta), -np.sin(theta)],
              [np.sin(theta), np.cos(theta)]])

# ì›ë³¸ ë²¡í„°ë“¤
original_vectors = np.array([[1, 0], [0, 1], [1, 1]]).T
# ë³€í™˜ëœ ë²¡í„°ë“¤
transformed_vectors = R @ original_vectors

# ì›ë³¸ ë²¡í„° ê·¸ë¦¬ê¸°
for i in range(original_vectors.shape[1]):
    ax4.quiver(*origin, *original_vectors[:, i], angles='xy', scale_units='xy', scale=1, 
               color='blue', width=0.005, alpha=0.5, linestyle='--')

# ë³€í™˜ëœ ë²¡í„° ê·¸ë¦¬ê¸°
for i in range(transformed_vectors.shape[1]):
    ax4.quiver(*origin, *transformed_vectors[:, i], angles='xy', scale_units='xy', scale=1, 
               color='red', width=0.006)

ax4.set_xlim(-0.5, 1.5)
ax4.set_ylim(-0.5, 1.5)
ax4.set_aspect('equal')
ax4.grid(True, alpha=0.3)
ax4.axhline(y=0, color='k', linewidth=0.5)
ax4.axvline(x=0, color='k', linewidth=0.5)
ax4.set_xlabel('x', fontsize=12)
ax4.set_ylabel('y', fontsize=12)
ax4.set_title('Linear Transformation (45Â° Rotation)', fontsize=14, fontweight='bold')
ax4.text(0.1, 1.3, 'Blue: Original', fontsize=10, color='blue')
ax4.text(0.1, 1.2, 'Red: Rotated', fontsize=10, color='red')

plt.tight_layout()
plt.savefig('/home/runner/work/deep-learning-study/deep-learning-study/neural_network_math_series/stage1_visualization.png', dpi=300, bbox_inches='tight')
print("Visualization saved to stage1_visualization.png")
plt.show()
```

### 5.2 í–‰ë ¬ ì—°ì‚° ì‹œê°í™” ì½”ë“œ

```python
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import rcParams

# í•œê¸€ í°íŠ¸ ì„¤ì •
rcParams['font.family'] = 'DejaVu Sans'

fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# ========== 1. í–‰ë ¬-ë²¡í„° ê³± ì‹œê°í™” ==========
ax1 = axes[0]
A = np.array([[2, 3], [4, 5]])
x = np.array([1, 2])
y = A @ x

# ì…ë ¥ ë²¡í„°
ax1.quiver(0, 0, x[0], x[1], angles='xy', scale_units='xy', scale=1, 
           color='blue', width=0.008, label=f'x = {x}')
# ì¶œë ¥ ë²¡í„°
ax1.quiver(0, 0, y[0], y[1], angles='xy', scale_units='xy', scale=1, 
           color='red', width=0.008, label=f'Ax = {y}')

ax1.set_xlim(-1, 10)
ax1.set_ylim(-1, 15)
ax1.set_aspect('equal')
ax1.grid(True, alpha=0.3)
ax1.axhline(y=0, color='k', linewidth=0.5)
ax1.axvline(x=0, color='k', linewidth=0.5)
ax1.set_xlabel('x', fontsize=12)
ax1.set_ylabel('y', fontsize=12)
ax1.set_title('Matrix-Vector Multiplication', fontsize=14, fontweight='bold')
ax1.legend(fontsize=11)
ax1.text(4, 12, f'A = {A.tolist()}', fontsize=10, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

# ========== 2. í–‰ë ¬ ê³±ì…ˆ ê²°ê³¼ íˆíŠ¸ë§µ ==========
ax2 = axes[1]
A_mat = np.array([[1, 2], [3, 4]])
B_mat = np.array([[5, 6], [7, 8]])
C_mat = A_mat @ B_mat

im = ax2.imshow(C_mat, cmap='YlOrRd', aspect='auto')
ax2.set_xticks([0, 1])
ax2.set_yticks([0, 1])
ax2.set_xticklabels(['col 0', 'col 1'])
ax2.set_yticklabels(['row 0', 'row 1'])

# ê°’ í‘œì‹œ
for i in range(2):
    for j in range(2):
        text = ax2.text(j, i, f'{C_mat[i, j]}',
                       ha="center", va="center", color="black", fontsize=14, fontweight='bold')

ax2.set_title('Matrix Multiplication Result C = A Ã— B', fontsize=14, fontweight='bold')
plt.colorbar(im, ax=ax2)

# ìˆ˜ì‹ í‘œì‹œ
ax2.text(0.5, -0.3, f'A = {A_mat.tolist()}, B = {B_mat.tolist()}', 
         ha='center', transform=ax2.transAxes, fontsize=10,
         bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))

# ========== 3. ì‹ ê²½ë§ ì„ í˜• ë³€í™˜ ==========
ax3 = axes[2]
# 3ê°œ ì…ë ¥ -> 2ê°œ ì¶œë ¥
W = np.array([[0.5, 0.3, 0.2], [0.7, 0.4, 0.6]])
x_input = np.array([1.0, 2.0, 3.0])
b = np.array([0.1, 0.2])
z_output = W @ x_input + b

# ì‹ ê²½ë§ êµ¬ì¡° ì‹œê°í™”
input_layer_x = 0.2
hidden_layer_x = 0.8

# ì…ë ¥ ë…¸ë“œ
for i in range(3):
    y = 0.2 + i * 0.3
    circle = plt.Circle((input_layer_x, y), 0.05, color='lightblue', ec='black', linewidth=2)
    ax3.add_patch(circle)
    ax3.text(input_layer_x - 0.15, y, f'x{i+1}={x_input[i]}', fontsize=10, ha='right')

# ì¶œë ¥ ë…¸ë“œ
for i in range(2):
    y = 0.35 + i * 0.3
    circle = plt.Circle((hidden_layer_x, y), 0.05, color='lightcoral', ec='black', linewidth=2)
    ax3.add_patch(circle)
    ax3.text(hidden_layer_x + 0.15, y, f'z{i+1}={z_output[i]:.2f}', fontsize=10, ha='left')

# ì—°ê²°ì„  (ê°€ì¤‘ì¹˜)
for i in range(3):
    for j in range(2):
        y_in = 0.2 + i * 0.3
        y_out = 0.35 + j * 0.3
        ax3.plot([input_layer_x + 0.05, hidden_layer_x - 0.05], [y_in, y_out], 
                'gray', alpha=0.3, linewidth=1)

ax3.set_xlim(0, 1)
ax3.set_ylim(0, 1)
ax3.axis('off')
ax3.set_title('Neural Network Linear Transformation', fontsize=14, fontweight='bold')
ax3.text(0.5, 0.05, 'z = Wx + b', fontsize=12, ha='center', 
         bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))

plt.tight_layout()
plt.savefig('/home/runner/work/deep-learning-study/deep-learning-study/neural_network_math_series/stage1_matrix_operations.png', dpi=300, bbox_inches='tight')
print("Matrix operations visualization saved to stage1_matrix_operations.png")
plt.show()
```

### 5.3 ì‹œê°í™” ê²°ê³¼ í•´ì„¤

#### ê·¸ë¦¼ 1: ë²¡í„° ì—°ì‚°
1. **ì¢Œìƒë‹¨ - ë²¡í„° í‘œí˜„**: 2ì°¨ì› ê³µê°„ì—ì„œ ë‘ ë²¡í„°ì˜ ë°©í–¥ê³¼ í¬ê¸°ë¥¼ í™”ì‚´í‘œë¡œ í‘œí˜„
2. **ìš°ìƒë‹¨ - ë²¡í„° ë§ì…ˆ**: í‰í–‰ì‚¬ë³€í˜• ë²•ì¹™ì„ ë³´ì—¬ì¤Œ. ë²¡í„° a ëì ì—ì„œ ì‹œì‘í•˜ëŠ” bì™€ ì›ì ì—ì„œ ì‹œì‘í•˜ëŠ” í•© ë²¡í„°
3. **ì¢Œí•˜ë‹¨ - ë‚´ì **: ë‘ ë²¡í„°ì˜ ë‚´ì  ê°’ê³¼ ì‚¬ì´ê°ì„ ê³„ì‚°í•˜ì—¬ í‘œì‹œ
4. **ìš°í•˜ë‹¨ - ì„ í˜• ë³€í™˜**: 45ë„ íšŒì „ ë³€í™˜ì„ ì ìš©í•œ ë²¡í„°ë“¤ì˜ ë³€í™”

#### ê·¸ë¦¼ 2: í–‰ë ¬ ì—°ì‚°
1. **ì¢Œì¸¡ - í–‰ë ¬-ë²¡í„° ê³±**: ì…ë ¥ ë²¡í„°ê°€ í–‰ë ¬ì— ì˜í•´ ë³€í™˜ë˜ì–´ ë‹¤ë¥¸ ë°©í–¥ê³¼ í¬ê¸°ì˜ ë²¡í„°ë¡œ ë³€í™˜
2. **ì¤‘ì•™ - í–‰ë ¬ ê³±ì…ˆ**: ë‘ í–‰ë ¬ì˜ ê³±ì…ˆ ê²°ê³¼ë¥¼ íˆíŠ¸ë§µìœ¼ë¡œ ì‹œê°í™”
3. **ìš°ì¸¡ - ì‹ ê²½ë§**: 3ê°œ ì…ë ¥ì´ ê°€ì¤‘ì¹˜ í–‰ë ¬ì„ í†µí•´ 2ê°œ ì¶œë ¥ìœ¼ë¡œ ë³€í™˜ë˜ëŠ” ê³¼ì •

---

## í•µì‹¬ ìš”ì•½

### ìˆ˜í•™ êµ¬ì¡°ë³„ ìš”ì•½

| êµ¬ì¡° | ì°¨ì› | í‘œê¸° | ì‹ ê²½ë§ ì—­í•  | ì˜ˆì‹œ |
|------|------|------|------------|------|
| **ìŠ¤ì¹¼ë¼** | 0ì°¨ì› | $s$ | í•™ìŠµë¥ , í¸í–¥ | $0.01$ |
| **ë²¡í„°** | 1ì°¨ì› | $\mathbf{v}$ | ì…ë ¥, íŠ¹ì„±, ê°€ì¤‘ì¹˜ | $[1, 2, 3]$ |
| **í–‰ë ¬** | 2ì°¨ì› | $\mathbf{A}$ | ê°€ì¤‘ì¹˜ í–‰ë ¬ | $$ \begin{bmatrix}1 & 2\\3 & 4\end{bmatrix} $$  |
| **ì„ í˜• ë³€í™˜** | í•¨ìˆ˜ | $\mathbf{y}=\mathbf{Ax}+\mathbf{b}$ | ì¸µ ê°„ ë³€í™˜ | ì…ë ¥â†’ì€ë‹‰ì¸µ |


### ì‹¤ìƒí™œ ë¹„ìœ 
- **ìŠ¤ì¹¼ë¼**: ì˜¨ë„ê³„ì˜ ì˜¨ë„ í•˜ë‚˜
- **ë²¡í„°**: GPS ì¢Œí‘œ (ìœ„ë„, ê²½ë„)
- **í–‰ë ¬**: êµì‹¤ì˜ í•™ìƒ ì„±ì í‘œ (í•™ìƒÃ—ê³¼ëª©)
- **ì„ í˜• ë³€í™˜**: ë²ˆì—­ê¸° (í•œêµ­ì–´ ë¬¸ì¥ â†’ ì˜ì–´ ë¬¸ì¥)

### ì‹ ê²½ë§ ì—°ê²°
ì‹ ê²½ë§ì€ ì´ëŸ¬í•œ ìˆ˜í•™ êµ¬ì¡°ë“¤ì˜ ì¡°í•©ì…ë‹ˆë‹¤:
1. **ì…ë ¥**: ë²¡í„° $\mathbf{x}$
2. **ê°€ì¤‘ì¹˜**: í–‰ë ¬ $\mathbf{W}$
3. **í¸í–¥**: ë²¡í„° $\mathbf{b}$
4. **ë³€í™˜**: $\mathbf{z} = \mathbf{W}\mathbf{x} + \mathbf{b}$ (ì„ í˜• ë³€í™˜)
5. **í™œì„±í™”**: $\mathbf{a} = f(\mathbf{z})$ (ë‹¤ìŒ Stageì—ì„œ ë‹¤ë£° ë‚´ìš©)

---

## ë‹¤ìŒ ë‹¨ê³„ ì˜ˆê³ 

**Stage 2**ì—ì„œëŠ” í¼ì…‰íŠ¸ë¡ ê³¼ ê°€ì¤‘í•© ìˆ˜ì‹ ($z = \mathbf{w} \cdot \mathbf{x} + b$)ì„ ê¹Šì´ ìˆê²Œ ë‹¤ë£° ì˜ˆì •ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ ë°°ìš´ ë²¡í„° ë‚´ì ê³¼ ì„ í˜• ë³€í™˜ì´ ì–´ë–»ê²Œ í¼ì…‰íŠ¸ë¡ ì˜ í•µì‹¬ ì—°ì‚°ì´ ë˜ëŠ”ì§€ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤!

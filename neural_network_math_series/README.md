# 신경망 학습을 이해하기 위한 필수 수학 공식 교육 시리즈

## 📖 시리즈 개요

이 시리즈는 딥러닝 신경망의 수학적 기초를 **처음부터 끝까지 체계적으로** 학습할 수 있도록 설계된 8단계 교육 자료입니다.

### ✨ 특징
- ✅ **LaTeX 수식**: 모든 수학적 개념을 정확한 수식으로 표현
- ✅ **기호 설명**: 모든 수식에 사용된 기호를 상세히 설명
- ✅ **실생활 비유**: 추상적인 개념을 직관적으로 이해할 수 있는 예시 제공
- ✅ **Python 시각화**: Matplotlib/NumPy를 활용한 실행 가능한 코드와 그래프
- ✅ **난이도 조절**: 초심자도 이해할 수 있으면서 전문적인 깊이 유지

---

## 📚 시리즈 구성

### [Stage 1: 기본 수학 구조 개요](./stage1_basic_math_structures.md)
**주제**: 스칼라, 벡터, 행렬, 선형 변환  
**난이도**: ⭐⭐☆☆☆  
**학습 시간**: 45-60분

**핵심 내용:**
- 스칼라, 벡터, 행렬의 정의와 표현
- 벡터 연산 (덧셈, 스칼라 곱, 내적)
- 행렬 연산 (행렬-벡터 곱, 행렬 곱셈)
- 선형 변환의 개념과 신경망에서의 역할

**시각화:**
- 2차원 공간에서 벡터 표현
- 벡터 덧셈과 내적
- 선형 변환 (회전)
- 행렬-벡터 곱 시각화

---

### [Stage 2: 퍼셉트론과 가중합 수식](./stage2_perceptron_weighted_sum.md)
**주제**: z = w·x + b  
**난이도**: ⭐⭐☆☆☆  
**학습 시간**: 50-70분

**핵심 내용:**
- 퍼셉트론의 구조와 동작 원리
- 가중합 수식의 3가지 표현 (스칼라, 시그마, 벡터)
- 가중치와 편향의 역할
- 논리 게이트 (AND) 구현 예제

**시각화:**
- 퍼셉트론 구조 다이어그램
- 결정 경계 (Decision Boundary)
- 가중치/편향 변화에 따른 결정 경계 변화
- 3D 가중합 표면

---

### [Stage 3: 활성화 함수](./stage3_activation_functions.md)
**주제**: Sigmoid, ReLU, Tanh  
**난이도**: ⭐⭐⭐☆☆  
**학습 시간**: 60-80분

**핵심 내용:**
- 활성화 함수의 필요성
- Sigmoid, ReLU, Tanh의 수식과 특성
- 각 함수의 미분
- 활성화 함수 선택 기준

**시각화:**
- 주요 활성화 함수 그래프
- 활성화 함수 비교
- 미분 함수 그래프
- 미분 비교

---

### [Stage 4: 손실 함수](./stage4_loss_functions.md)
**주제**: MSE, Cross-Entropy  
**난이도**: ⭐⭐⭐☆☆  
**학습 시간**: 60-75분

**핵심 내용:**
- 손실 함수의 개념과 역할
- 평균 제곱 오차 (MSE)
- 교차 엔트로피 (Binary & Categorical)
- 손실 함수 선택 기준

**시각화:**
- MSE와 MAE 비교
- Binary Cross-Entropy (y=0, y=1)
- 회귀 문제 예제
- 분류 문제 예제

---

### [Stage 5: 미분과 편미분](./stage5_differentiation.md)
**주제**: Differentiation & Partial Derivatives  
**난이도**: ⭐⭐⭐⭐☆  
**학습 시간**: 70-90분

**핵심 내용:**
- 미분의 정의와 기하학적 의미
- 편미분 개념
- 그래디언트 벡터
- 연쇄 법칙 (Chain Rule)

**시각화:**
- 접선의 기울기
- 증가/감소 판정
- 3D 표면과 편미분
- 그래디언트 벡터장
- 연쇄 법칙 다이어그램

---

### [Stage 6: 경사하강법](./stage6_gradient_descent.md)
**주제**: Gradient Descent  
**난이도**: ⭐⭐⭐⭐☆  
**학습 시간**: 70-85분

**핵심 내용:**
- 경사하강법의 원리
- 수학적 유도
- 학습률의 역할
- Batch/SGD/Mini-batch 비교
- 모멘텀 개념

**시각화:**
- 경사하강법 수렴 경로
- 학습률 비교
- 2D 경사하강법
- 손실 수렴 곡선

---

### [Stage 7: 신경망 학습 (1층 → 다층)](./stage7_neural_network_learning.md)
**주제**: Forward & Backward Propagation  
**난이도**: ⭐⭐⭐⭐⭐  
**학습 시간**: 90-120분

**핵심 내용:**
- 단층 신경망 학습
- 다층 신경망 구조
- 역전파 알고리즘
- 완전한 학습 과정
- NumPy 구현 예제

---

### [Stage 8: 최종 정리](./stage8_final_summary.md)
**주제**: 수식만으로 전 과정 설명  
**난이도**: ⭐⭐⭐⭐⭐  
**학습 시간**: 모든 Stage 복습 포함 4-6시간

**핵심 내용:**
- 기본 구성 요소 수식
- 활성화 함수 수식
- 손실 함수 수식
- 순방향 전파 수식
- 역전파 수식
- 경사하강법 수식
- 완전한 학습 알고리즘
- 구체적 예제 (2-3-1 신경망)
- 최종 통합 수식
- 기호 정리표

---

## 🚀 학습 방법

### 1. 순차적 학습 (추천)
Stage 1부터 Stage 8까지 순서대로 학습하세요. 각 Stage는 이전 Stage의 내용을 기반으로 합니다.

### 2. 각 Stage 학습 단계
1. **이론 읽기**: Markdown 문서의 수식과 설명을 천천히 읽기
2. **시각화 실행**: Python 코드를 직접 실행하여 그래프 확인
3. **예제 풀이**: 제공된 수치 예제를 손으로 계산해보기
4. **실생활 연결**: 비유를 통해 개념을 자신의 언어로 설명해보기

### 3. 복습 방법
- Stage 8의 수식 모음을 참조하여 전체 흐름 복습
- 각 Stage의 "핵심 요약" 섹션 재검토
- Python 코드를 수정하여 다양한 파라미터로 실험

---

## 💻 Python 환경 설정

### 필수 라이브러리
```bash
pip install numpy matplotlib scipy
```

### 시각화 실행
```bash
cd neural_network_math_series
python stage1_visualization.py
python stage2_visualization.py
python stage3_visualization.py
# ... 등
```

---

## 📊 학습 로드맵

```
Start
  ↓
Stage 1: 수학 기초
  ↓
Stage 2: 퍼셉트론
  ↓
Stage 3: 활성화 함수
  ↓
Stage 4: 손실 함수
  ↓
Stage 5: 미분
  ↓
Stage 6: 경사하강법
  ↓
Stage 7: 신경망 학습
  ↓
Stage 8: 최종 정리
  ↓
End (완전한 이해!)
```

---

## 🎯 학습 목표

이 시리즈를 완료하면 다음을 할 수 있습니다:

1. ✅ 신경망의 **모든 수식을 이해하고 설명**할 수 있음
2. ✅ **역전파 알고리즘**을 수식으로 유도할 수 있음
3. ✅ **경사하강법의 원리**를 기하학적으로 설명할 수 있음
4. ✅ 간단한 신경망을 **NumPy로 구현**할 수 있음
5. ✅ 활성화 함수와 손실 함수를 **적절히 선택**할 수 있음
6. ✅ 학습이 잘 안될 때 **수학적 원인을 파악**할 수 있음

---

## 📖 참고 자료

### 책
- Deep Learning (Ian Goodfellow, Yoshua Bengio, Aaron Courville)
- Neural Networks and Deep Learning (Michael Nielsen)
- Pattern Recognition and Machine Learning (Christopher Bishop)

### 온라인 강의
- Andrew Ng - Machine Learning (Coursera)
- 3Blue1Brown - Neural Networks (YouTube)
- MIT 6.S191 - Introduction to Deep Learning

---

## 🤝 기여 및 피드백

이 교육 자료에 대한 의견이나 개선 사항이 있다면 언제든 공유해주세요!

---

## 📝 라이선스

이 교육 자료는 학습 목적으로 자유롭게 사용할 수 있습니다.

---

## 🎓 마지막 한마디

> "수학은 신경망의 언어입니다. 수식을 이해하면 신경망의 모든 것을 이해할 수 있습니다."

**즐거운 학습 되세요! 🚀**

---

**작성일**: 2024년  
**버전**: 1.0  
**총 페이지 수**: 약 100페이지 (모든 Stage 합산)  
**총 수식 수**: 200개 이상  
**총 시각화**: 25개 이상  
**총 예제**: 50개 이상

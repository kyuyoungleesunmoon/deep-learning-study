"""
Stage 2 ì‹œê°í™”: í¼ì…‰íŠ¸ë¡ ê³¼ ê°€ì¤‘í•©
"""
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import rcParams
from mpl_toolkits.mplot3d import Axes3D

# í•œê¸€ í°íŠ¸ ì„¤ì •
rcParams['font.family'] = 'DejaVu Sans'

fig, axes = plt.subplots(2, 2, figsize=(14, 12))

# ========== 1. í¼ì…‰íŠ¸ë¡  êµ¬ì¡° ë‹¤ì´ì–´ê·¸ë¨ ==========
ax1 = axes[0, 0]
ax1.axis('off')

# ì…ë ¥ ë…¸ë“œ
input_x = 0.2
input_y_positions = [0.7, 0.5, 0.3]
input_labels = ['xâ‚', 'xâ‚‚', 'xâ‚ƒ']

for i, (y, label) in enumerate(zip(input_y_positions, input_labels)):
    circle = plt.Circle((input_x, y), 0.04, color='lightblue', ec='black', linewidth=2)
    ax1.add_patch(circle)
    ax1.text(input_x - 0.12, y, label, fontsize=14, ha='right', fontweight='bold')

# ê°€ì¤‘í•© ë…¸ë“œ
sum_x = 0.5
sum_y = 0.5
circle = plt.Circle((sum_x, sum_y), 0.06, color='yellow', ec='black', linewidth=2)
ax1.add_patch(circle)
ax1.text(sum_x, sum_y, 'Î£', fontsize=18, ha='center', va='center', fontweight='bold')

# í™œì„±í™” í•¨ìˆ˜ ë…¸ë“œ
act_x = 0.7
act_y = 0.5
circle = plt.Circle((act_x, act_y), 0.05, color='lightcoral', ec='black', linewidth=2)
ax1.add_patch(circle)
ax1.text(act_x, act_y, 'f', fontsize=14, ha='center', va='center', fontweight='bold')

# ì¶œë ¥ ë…¸ë“œ
output_x = 0.9
output_y = 0.5
circle = plt.Circle((output_x, output_y), 0.04, color='lightgreen', ec='black', linewidth=2)
ax1.add_patch(circle)
ax1.text(output_x + 0.08, output_y, 'y', fontsize=14, ha='left', fontweight='bold')

# ì—°ê²°ì„  (ê°€ì¤‘ì¹˜)
weights = ['wâ‚', 'wâ‚‚', 'wâ‚ƒ']
for i, (y, w_label) in enumerate(zip(input_y_positions, weights)):
    ax1.plot([input_x + 0.04, sum_x - 0.06], [y, sum_y], 'gray', linewidth=2)
    mid_x = (input_x + sum_x) / 2
    mid_y = (y + sum_y) / 2
    ax1.text(mid_x, mid_y + 0.02, w_label, fontsize=10, ha='center', color='red', fontweight='bold')

# í¸í–¥
ax1.plot([sum_x, sum_x], [sum_y - 0.15, sum_y - 0.06], 'gray', linewidth=2)
ax1.text(sum_x, sum_y - 0.18, 'b', fontsize=12, ha='center', color='red', fontweight='bold')

# ì—°ê²°ì„  (í™œì„±í™”)
ax1.arrow(sum_x + 0.06, sum_y, act_x - sum_x - 0.11, 0, head_width=0.02, head_length=0.03, fc='black', ec='black')
ax1.text((sum_x + act_x) / 2, sum_y + 0.05, 'z', fontsize=12, ha='center', color='blue', fontweight='bold')

# ì—°ê²°ì„  (ì¶œë ¥)
ax1.arrow(act_x + 0.05, act_y, output_x - act_x - 0.09, 0, head_width=0.02, head_length=0.03, fc='black', ec='black')

ax1.set_xlim(0, 1)
ax1.set_ylim(0, 1)
ax1.set_title('Perceptron Structure', fontsize=16, fontweight='bold', pad=20)

# ìˆ˜ì‹ í‘œì‹œ
ax1.text(0.5, 0.1, r'z = wâ‚xâ‚ + wâ‚‚xâ‚‚ + wâ‚ƒxâ‚ƒ + b', fontsize=13, ha='center',
         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
ax1.text(0.5, 0.02, r'y = f(z)', fontsize=13, ha='center',
         bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))

# ========== 2. ê²°ì • ê²½ê³„ ì‹œê°í™” (AND ê²Œì´íŠ¸) ==========
ax2 = axes[0, 1]

# AND ê²Œì´íŠ¸ íŒŒë¼ë¯¸í„°
w1, w2 = 0.5, 0.5
b = -0.7

# ë°ì´í„° í¬ì¸íŠ¸
X_and = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y_and = np.array([0, 0, 0, 1])

# ê²°ì • ê²½ê³„: w1*x1 + w2*x2 + b = 0 => x2 = -(w1*x1 + b)/w2
x1_line = np.linspace(-0.5, 1.5, 100)
x2_line = -(w1 * x1_line + b) / w2

# ë°°ê²½ ìƒ‰ì¹ 
xx, yy = np.meshgrid(np.linspace(-0.5, 1.5, 200), np.linspace(-0.5, 1.5, 200))
Z = w1 * xx + w2 * yy + b
ax2.contourf(xx, yy, Z, levels=[-100, 0, 100], colors=['lightcoral', 'lightblue'], alpha=0.3)

# ê²°ì • ê²½ê³„ì„ 
ax2.plot(x1_line, x2_line, 'k-', linewidth=3, label='Decision Boundary')

# ë°ì´í„° í¬ì¸íŠ¸
for i, (x, y) in enumerate(X_and):
    color = 'blue' if y_and[i] == 1 else 'red'
    marker = 'o' if y_and[i] == 1 else 'x'
    label_text = f'Class {y_and[i]}' if (i == 0 or i == 3) else None
    ax2.scatter(x, y, c=color, marker=marker, s=200, edgecolors='black', linewidth=2, label=label_text)

ax2.set_xlim(-0.5, 1.5)
ax2.set_ylim(-0.5, 1.5)
ax2.set_xlabel('xâ‚', fontsize=14)
ax2.set_ylabel('xâ‚‚', fontsize=14)
ax2.set_title('AND Gate Decision Boundary', fontsize=14, fontweight='bold')
ax2.legend(fontsize=10)
ax2.grid(True, alpha=0.3)
ax2.text(0.5, 1.3, f'wâ‚={w1}, wâ‚‚={w2}, b={b}', fontsize=11, ha='center',
        bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))

# ========== 3. ê°€ì¤‘ì¹˜ ë³€í™”ì— ë”°ë¥¸ ê²°ì • ê²½ê³„ ==========
ax3 = axes[1, 0]

# ì—¬ëŸ¬ ê°€ì¤‘ì¹˜ ì„¤ì •
weights_list = [(1, 1, -0.5), (1, 0.5, -0.3), (0.5, 1, -0.3)]
colors = ['red', 'blue', 'green']
labels = ['w=[1,1], b=-0.5', 'w=[1,0.5], b=-0.3', 'w=[0.5,1], b=-0.3']

for (w1, w2, b), color, label in zip(weights_list, colors, labels):
    x1_line = np.linspace(-0.5, 2, 100)
    x2_line = -(w1 * x1_line + b) / w2
    ax3.plot(x1_line, x2_line, linewidth=2, color=color, label=label)

ax3.set_xlim(-0.5, 2)
ax3.set_ylim(-0.5, 2)
ax3.set_xlabel('xâ‚', fontsize=14)
ax3.set_ylabel('xâ‚‚', fontsize=14)
ax3.set_title('Effect of Different Weights on Decision Boundary', fontsize=14, fontweight='bold')
ax3.legend(fontsize=9)
ax3.grid(True, alpha=0.3)

# ========== 4. í¸í–¥ ë³€í™”ì— ë”°ë¥¸ ê²°ì • ê²½ê³„ ==========
ax4 = axes[1, 1]

# ê³ ì •ëœ ê°€ì¤‘ì¹˜, ë‹¤ì–‘í•œ í¸í–¥
w1, w2 = 1, 1
biases = [-1, -0.5, 0, 0.5]
colors = ['red', 'orange', 'blue', 'green']

for b, color in zip(biases, colors):
    x1_line = np.linspace(-0.5, 2, 100)
    x2_line = -(w1 * x1_line + b) / w2
    ax4.plot(x1_line, x2_line, linewidth=2, color=color, label=f'b={b}')

ax4.set_xlim(-0.5, 2)
ax4.set_ylim(-0.5, 2)
ax4.set_xlabel('xâ‚', fontsize=14)
ax4.set_ylabel('xâ‚‚', fontsize=14)
ax4.set_title('Effect of Bias on Decision Boundary', fontsize=14, fontweight='bold')
ax4.legend(fontsize=10)
ax4.grid(True, alpha=0.3)
ax4.text(1, 1.7, 'wâ‚=1, wâ‚‚=1 (fixed)', fontsize=11, ha='center',
        bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))

# í™”ì‚´í‘œë¡œ í¸í–¥ ì¦ê°€ ë°©í–¥ í‘œì‹œ
ax4.annotate('Bias increasing â†’', xy=(0.5, 0.3), xytext=(0.2, 0.8),
            arrowprops=dict(arrowstyle='->', lw=2, color='purple'),
            fontsize=11, color='purple', fontweight='bold')

plt.tight_layout()
plt.savefig('/home/runner/work/deep-learning-study/deep-learning-study/neural_network_math_series/stage2_perceptron_visualization.png', dpi=300, bbox_inches='tight')
print("âœ… Perceptron visualization saved!")
plt.close()

# ========== ì¶”ê°€: 3D ê°€ì¤‘í•© ì‹œê°í™” ==========
fig = plt.figure(figsize=(14, 6))

# ========== 1. 3D ê°€ì¤‘í•© í‰ë©´ ==========
ax1 = fig.add_subplot(121, projection='3d')

# íŒŒë¼ë¯¸í„°
w1, w2, b = 0.8, 0.6, -1.0

# ê·¸ë¦¬ë“œ ìƒì„±
x1 = np.linspace(-2, 2, 30)
x2 = np.linspace(-2, 2, 30)
X1, X2 = np.meshgrid(x1, x2)
Z = w1 * X1 + w2 * X2 + b

# í‰ë©´ ê·¸ë¦¬ê¸°
surf = ax1.plot_surface(X1, X2, Z, cmap='viridis', alpha=0.7, edgecolor='none')

# z=0 í‰ë©´ (ê²°ì • ê²½ê³„)
ax1.plot_surface(X1, X2, np.zeros_like(Z), alpha=0.3, color='red')

ax1.set_xlabel('xâ‚', fontsize=12)
ax1.set_ylabel('xâ‚‚', fontsize=12)
ax1.set_zlabel('z = wâ‚xâ‚ + wâ‚‚xâ‚‚ + b', fontsize=12)
ax1.set_title('3D Weighted Sum Surface', fontsize=14, fontweight='bold')
fig.colorbar(surf, ax=ax1, shrink=0.5)

# ========== 2. ë“±ê³ ì„  í”Œë¡¯ ==========
ax2 = fig.add_subplot(122)

# ë“±ê³ ì„ 
contour = ax2.contour(X1, X2, Z, levels=15, cmap='viridis')
ax2.clabel(contour, inline=True, fontsize=8)

# z=0 ê²°ì • ê²½ê³„ ê°•ì¡°
contour_zero = ax2.contour(X1, X2, Z, levels=[0], colors='red', linewidths=3)
ax2.clabel(contour_zero, inline=True, fontsize=10)

ax2.set_xlabel('xâ‚', fontsize=12)
ax2.set_ylabel('xâ‚‚', fontsize=12)
ax2.set_title('Contour Plot of Weighted Sum', fontsize=14, fontweight='bold')
ax2.grid(True, alpha=0.3)
ax2.text(0, 1.7, f'wâ‚={w1}, wâ‚‚={w2}, b={b}', fontsize=11, ha='center',
        bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.8))

plt.tight_layout()
plt.savefig('/home/runner/work/deep-learning-study/deep-learning-study/neural_network_math_series/stage2_weighted_sum_3d.png', dpi=300, bbox_inches='tight')
print("âœ… 3D weighted sum visualization saved!")
plt.close()

print("\nğŸ‰ All Stage 2 visualizations completed successfully!")

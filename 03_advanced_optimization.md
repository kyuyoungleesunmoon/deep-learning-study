# 고급 최적화 및 정규화 기법 (고급 단계)

## 목차
1. [고급 최적화 알고리즘](#1-고급-최적화-알고리즘)
2. [정규화 기법 (Regularization)](#2-정규화-기법-regularization)
3. [배치 정규화 (Batch Normalization)](#3-배치-정규화-batch-normalization)
4. [고급 신경망 아키텍처](#4-고급-신경망-아키텍처)

---

## 1. 고급 최적화 알고리즘

### 1.1 Adam (Adaptive Moment Estimation)

Adam은 모멘텀과 RMSprop의 장점을 결합한 최적화 알고리즘입니다.

#### 수식
```
m := β₁ m + (1 - β₁) g
v := β₂ v + (1 - β₂) g²
m̂ := m / (1 - β₁ᵗ)
v̂ := v / (1 - β₂ᵗ)
θ := θ - α m̂ / (√v̂ + ε)
```

#### 기호 설명
- `m`: 1차 모멘트 추정 (평균) - first moment estimate (mean)
- `v`: 2차 모멘트 추정 (비중심 분산) - second moment estimate (uncentered variance)
- `g`: 현재 그래디언트 - current gradient, `g = ∂L/∂θ`
- `β₁`: 1차 모멘트 감쇠율 (일반적으로 0.9)
- `β₂`: 2차 모멘트 감쇠율 (일반적으로 0.999)
- `α`: 학습률 (일반적으로 0.001)
- `ε`: 수치 안정성을 위한 작은 상수 (일반적으로 10⁻⁸)
- `t`: 시간 단계 (time step)
- `m̂`, `v̂`: 편향 보정된 모멘트 추정 (bias-corrected estimates)

#### 수치 예제

**초기 설정:**
- θ = 1.0
- α = 0.1
- β₁ = 0.9, β₂ = 0.999
- ε = 10⁻⁸
- m = 0, v = 0

**그래디언트 시퀀스:** [0.5, 0.3, 0.4]

**반복 1 (t=1):**

그래디언트: g = 0.5

1차 모멘트:
```
m = 0.9 × 0 + 0.1 × 0.5 = 0.05
```

2차 모멘트:
```
v = 0.999 × 0 + 0.001 × (0.5)² = 0.001 × 0.25 = 0.00025
```

편향 보정:
```
m̂ = 0.05 / (1 - 0.9¹) = 0.05 / 0.1 = 0.5
v̂ = 0.00025 / (1 - 0.999¹) = 0.00025 / 0.001 = 0.25
```

파라미터 업데이트:
```
θ = 1.0 - 0.1 × 0.5 / (√0.25 + 10⁻⁸)
  = 1.0 - 0.1 × 0.5 / 0.5
  = 1.0 - 0.1
  = 0.9
```

**반복 2 (t=2):**

그래디언트: g = 0.3

1차 모멘트:
```
m = 0.9 × 0.05 + 0.1 × 0.3 = 0.045 + 0.03 = 0.075
```

2차 모멘트:
```
v = 0.999 × 0.00025 + 0.001 × (0.3)²
  = 0.00024975 + 0.00009
  = 0.00033975
```

편향 보정:
```
m̂ = 0.075 / (1 - 0.9²) = 0.075 / 0.19 ≈ 0.395
v̂ = 0.00033975 / (1 - 0.999²) = 0.00033975 / 0.001999 ≈ 0.170
```

파라미터 업데이트:
```
θ = 0.9 - 0.1 × 0.395 / (√0.170 + 10⁻⁸)
  = 0.9 - 0.1 × 0.395 / 0.412
  = 0.9 - 0.096
  ≈ 0.804
```

### 1.2 RMSprop (Root Mean Square Propagation)

#### 수식
```
v := β v + (1 - β) g²
θ := θ - α g / (√v + ε)
```

#### 기호 설명
- `v`: 그래디언트 제곱의 이동 평균 (moving average of squared gradients)
- `β`: 감쇠율 (일반적으로 0.9 또는 0.99)
- `g`: 현재 그래디언트
- `ε`: 수치 안정성 상수

#### 수치 예제

**초기 설정:**
- θ = 1.0, v = 0
- α = 0.1, β = 0.9, ε = 10⁻⁸

**반복 1:** g = 0.5
```
v = 0.9 × 0 + 0.1 × (0.5)² = 0.025
θ = 1.0 - 0.1 × 0.5 / √0.025 = 1.0 - 0.1 × 0.5 / 0.158 = 0.684
```

**반복 2:** g = 0.3
```
v = 0.9 × 0.025 + 0.1 × (0.3)² = 0.0225 + 0.009 = 0.0315
θ = 0.684 - 0.1 × 0.3 / √0.0315 = 0.684 - 0.169 = 0.515
```

### 1.3 AdaGrad (Adaptive Gradient)

#### 수식
```
G := G + g²
θ := θ - α g / (√G + ε)
```

#### 기호 설명
- `G`: 그래디언트 제곱의 누적 합 (accumulated sum of squared gradients)
- 자주 업데이트되는 파라미터는 학습률이 감소

#### 수치 예제

**초기 설정:**
- θ = 1.0, G = 0
- α = 0.5, ε = 10⁻⁸

**반복 1:** g = 0.5
```
G = 0 + (0.5)² = 0.25
θ = 1.0 - 0.5 × 0.5 / √0.25 = 1.0 - 0.5 × 0.5 / 0.5 = 0.5
```

**반복 2:** g = 0.3
```
G = 0.25 + (0.3)² = 0.25 + 0.09 = 0.34
θ = 0.5 - 0.5 × 0.3 / √0.34 = 0.5 - 0.257 = 0.243
```

**반복 3:** g = 0.4
```
G = 0.34 + (0.4)² = 0.34 + 0.16 = 0.5
θ = 0.243 - 0.5 × 0.4 / √0.5 = 0.243 - 0.283 = -0.04
```

**주의:** G가 계속 증가하여 학습률이 너무 작아질 수 있음

---

## 2. 정규화 기법 (Regularization)

### 2.1 L2 정규화 (Ridge Regression)

#### 수식

손실 함수:
```
J = L + (λ/2) Σᵢ wᵢ²
```

그래디언트:
```
∂J/∂w = ∂L/∂w + λw
```

업데이트:
```
w := w - α(∂L/∂w + λw)
  = (1 - αλ)w - α∂L/∂w
```

#### 기호 설명
- `L`: 원래 손실 함수
- `λ`: 정규화 강도 (regularization strength)
- `(1 - αλ)`: 가중치 감쇠 인자 (weight decay factor)

#### 수치 예제

**설정:**
- w = 2.0
- ∂L/∂w = 0.5
- α = 0.1, λ = 0.01

**정규화 없이:**
```
w = 2.0 - 0.1 × 0.5 = 1.95
```

**L2 정규화 사용:**
```
∂J/∂w = 0.5 + 0.01 × 2.0 = 0.5 + 0.02 = 0.52
w = 2.0 - 0.1 × 0.52 = 1.948
```

또는:
```
w = (1 - 0.1 × 0.01) × 2.0 - 0.1 × 0.5
  = 0.999 × 2.0 - 0.05
  = 1.998 - 0.05
  = 1.948
```

### 2.2 L1 정규화 (Lasso Regression)

#### 수식

손실 함수:
```
J = L + λ Σᵢ |wᵢ|
```

그래디언트:
```
∂J/∂w = ∂L/∂w + λ sign(w)
```

여기서:
```
sign(w) = {
    +1  if w > 0
     0  if w = 0
    -1  if w < 0
}
```

#### 기호 설명
- `|w|`: w의 절댓값 (absolute value)
- `sign(w)`: w의 부호 함수 (sign function)
- 특징: 일부 가중치를 정확히 0으로 만듦 (희소성, sparsity)

#### 수치 예제

**설정:**
- w = 2.0
- ∂L/∂w = 0.5
- α = 0.1, λ = 0.1

```
∂J/∂w = 0.5 + 0.1 × sign(2.0) = 0.5 + 0.1 × 1 = 0.6
w = 2.0 - 0.1 × 0.6 = 1.94
```

**w가 작을 때:**
w = 0.05, ∂L/∂w = 0.03
```
∂J/∂w = 0.03 + 0.1 × sign(0.05) = 0.03 + 0.1 = 0.13
w = 0.05 - 0.1 × 0.13 = 0.037
```

여러 반복 후 w → 0 (희소성)

### 2.3 Dropout

#### 수식

학습 시:
```
r ~ Bernoulli(p)
ã = r ⊙ a
```

테스트 시:
```
a_test = p × a
```

#### 기호 설명
- `p`: 유지 확률 (keep probability, 일반적으로 0.5)
- `r`: 이진 마스크 (binary mask), 0 또는 1
- `⊙`: 원소별 곱셈
- `ã`: Dropout이 적용된 활성화

#### 수치 예제

**학습 시 (p = 0.5):**

활성화 값: a = [1.2, 0.8, 1.5, 0.9]

랜덤 마스크: r = [1, 0, 1, 0]

Dropout 적용:
```
ã = [1, 0, 1, 0] ⊙ [1.2, 0.8, 1.5, 0.9]
  = [1.2, 0, 1.5, 0]
```

**테스트 시:**
```
a_test = 0.5 × [1.2, 0.8, 1.5, 0.9]
       = [0.6, 0.4, 0.75, 0.45]
```

또는 **Inverted Dropout** (학습 시 스케일링):
```
학습: ã = (r ⊙ a) / p = [1.2, 0, 1.5, 0] / 0.5 = [2.4, 0, 3.0, 0]
테스트: a_test = a (스케일링 불필요)
```

---

## 3. 배치 정규화 (Batch Normalization)

### 3.1 배치 정규화 수식

#### 순방향 전파
```
μ_B = (1/m) Σᵢ₌₁ᵐ xᵢ
σ²_B = (1/m) Σᵢ₌₁ᵐ (xᵢ - μ_B)²
x̂ᵢ = (xᵢ - μ_B) / √(σ²_B + ε)
yᵢ = γ x̂ᵢ + β
```

#### 기호 설명
- `m`: 미니배치 크기 (mini-batch size)
- `μ_B`: 배치 평균 (batch mean)
- `σ²_B`: 배치 분산 (batch variance)
- `x̂ᵢ`: 정규화된 입력 (normalized input)
- `γ`: 스케일 파라미터 (학습 가능)
- `β`: 이동 파라미터 (학습 가능)
- `ε`: 수치 안정성 상수 (일반적으로 10⁻⁵)

### 3.2 수치 예제

**미니배치:** x = [2.0, 3.0, 4.0, 5.0] (m = 4)
**파라미터:** γ = 1.0, β = 0.0, ε = 10⁻⁵

**Step 1: 평균 계산**
```
μ_B = (2.0 + 3.0 + 4.0 + 5.0) / 4 = 14.0 / 4 = 3.5
```

**Step 2: 분산 계산**
```
σ²_B = [(2.0-3.5)² + (3.0-3.5)² + (4.0-3.5)² + (5.0-3.5)²] / 4
     = [2.25 + 0.25 + 0.25 + 2.25] / 4
     = 5.0 / 4
     = 1.25
```

**Step 3: 정규화**
```
x̂₁ = (2.0 - 3.5) / √(1.25 + 10⁻⁵) = -1.5 / 1.118 ≈ -1.342
x̂₂ = (3.0 - 3.5) / √1.25 = -0.5 / 1.118 ≈ -0.447
x̂₃ = (4.0 - 3.5) / √1.25 = 0.5 / 1.118 ≈ 0.447
x̂₄ = (5.0 - 3.5) / √1.25 = 1.5 / 1.118 ≈ 1.342
```

**Step 4: 스케일 및 이동**
```
y₁ = 1.0 × (-1.342) + 0.0 = -1.342
y₂ = 1.0 × (-0.447) + 0.0 = -0.447
y₃ = 1.0 × 0.447 + 0.0 = 0.447
y₄ = 1.0 × 1.342 + 0.0 = 1.342
```

**검증:**
```
평균(y) = (-1.342 - 0.447 + 0.447 + 1.342) / 4 ≈ 0 ✓
분산(y) ≈ 1 ✓
```

### 3.3 역전파

#### 수식
```
∂L/∂x̂ᵢ = ∂L/∂yᵢ × γ
∂L/∂σ²_B = Σᵢ ∂L/∂x̂ᵢ × (xᵢ - μ_B) × (-1/2)(σ²_B + ε)^(-3/2)
∂L/∂μ_B = Σᵢ ∂L/∂x̂ᵢ × (-1/√(σ²_B + ε))
∂L/∂xᵢ = ∂L/∂x̂ᵢ / √(σ²_B + ε) + ∂L/∂σ²_B × 2(xᵢ - μ_B)/m + ∂L/∂μ_B/m
```

---

## 4. 고급 신경망 아키텍처

### 4.1 합성곱 신경망 (CNN) - 수학적 정의

#### 2D 합성곱 수식
```
(f * g)(i, j) = Σₘ Σₙ f(m, n) × g(i - m, j - n)
```

또는 신경망에서:
```
yᵢⱼ = Σₘ₌₀^(k-1) Σₙ₌₀^(k-1) wₘₙ × xᵢ₊ₘ,ⱼ₊ₙ + b
```

#### 기호 설명
- `f`: 필터/커널 (filter/kernel)
- `g`: 입력 이미지 (input image)
- `*`: 합성곱 연산자 (convolution operator)
- `k`: 커널 크기 (kernel size)
- `w`: 커널 가중치 (kernel weights)
- `b`: 편향 (bias)

#### 수치 예제: 3×3 합성곱

**입력 (5×5):**
```
X = [
  [1, 2, 3, 0, 1],
  [0, 1, 2, 3, 1],
  [1, 0, 1, 2, 0],
  [2, 1, 0, 1, 2],
  [1, 2, 1, 0, 1]
]
```

**커널 (3×3):**
```
K = [
  [1,  0, -1],
  [1,  0, -1],
  [1,  0, -1]
]
```

**출력 계산 (왼쪽 상단):**
```
y₀₀ = (1×1) + (2×0) + (3×-1) +
      (0×1) + (1×0) + (2×-1) +
      (1×1) + (0×0) + (1×-1)
    = 1 + 0 - 3 + 0 + 0 - 2 + 1 + 0 - 1
    = -4
```

**전체 출력 (3×3, 스트라이드=1, 패딩=0):**
```
Y = [
  [-4, -4, -3],
  [-3, -2, -1],
  [-2,  0,  2]
]
```

### 4.2 순환 신경망 (RNN) - 수학적 정의

#### 기본 RNN 수식
```
hₜ = tanh(Wₕₕ hₜ₋₁ + Wₓₕ xₜ + bₕ)
yₜ = Wₕᵧ hₜ + bᵧ
```

#### 기호 설명
- `hₜ`: 시간 t의 은닉 상태 (hidden state at time t)
- `xₜ`: 시간 t의 입력 (input at time t)
- `yₜ`: 시간 t의 출력 (output at time t)
- `Wₕₕ`: 은닉-은닉 가중치 (hidden-to-hidden weights)
- `Wₓₕ`: 입력-은닉 가중치 (input-to-hidden weights)
- `Wₕᵧ`: 은닉-출력 가중치 (hidden-to-output weights)

#### 수치 예제

**설정:**
- 입력 차원: 2
- 은닉 차원: 2
- h₀ = [0, 0]^T

**파라미터:**
```
Wₓₕ = [[0.5, 0.3],    Wₕₕ = [[0.4, 0.2],    bₕ = [0.1, 0.1]^T
       [0.2, 0.4]]            [0.3, 0.5]]
```

**입력 시퀀스:**
```
x₁ = [1.0, 0.5]^T
x₂ = [0.8, 0.6]^T
```

**시간 1:**
```
Wₕₕ h₀ + Wₓₕ x₁ + bₕ
= [[0.4, 0.2], [0.3, 0.5]] × [0, 0]^T + [[0.5, 0.3], [0.2, 0.4]] × [1.0, 0.5]^T + [0.1, 0.1]^T
= [0, 0]^T + [0.5 + 0.15, 0.2 + 0.2]^T + [0.1, 0.1]^T
= [0.75, 0.5]^T

h₁ = tanh([0.75, 0.5]^T) ≈ [0.635, 0.462]^T
```

**시간 2:**
```
Wₕₕ h₁ + Wₓₕ x₂ + bₕ
= [[0.4, 0.2], [0.3, 0.5]] × [0.635, 0.462]^T + [[0.5, 0.3], [0.2, 0.4]] × [0.8, 0.6]^T + [0.1, 0.1]^T
= [0.346, 0.422]^T + [0.58, 0.4]^T + [0.1, 0.1]^T
= [1.026, 0.922]^T

h₂ = tanh([1.026, 0.922]^T) ≈ [0.774, 0.726]^T
```

---

## 요약

### 핵심 개념
1. **Adam**: 모멘텀과 RMSprop 결합, 가장 널리 사용되는 최적화 알고리즘
2. **정규화**: 과적합 방지 (L1, L2, Dropout)
3. **배치 정규화**: 학습 안정화 및 가속화
4. **CNN/RNN**: 특정 데이터 구조에 최적화된 아키텍처

### 수식 체크리스트
- ✓ Adam: `θ := θ - α m̂/(√v̂ + ε)`
- ✓ L2 정규화: `J = L + (λ/2)Σw²`
- ✓ Batch Norm: `y = γ(x - μ)/σ + β`
- ✓ 합성곱: `yᵢⱼ = Σₘₙ wₘₙ × xᵢ₊ₘ,ⱼ₊ₙ`
- ✓ RNN: `hₜ = tanh(Wₕₕhₜ₋₁ + Wₓₕxₜ)`

### 실전 적용
이제 이론을 바탕으로 실제 구현을 통해 개념을 검증하고 심화할 수 있습니다.
